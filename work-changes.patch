diff -ur v0/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java v1/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
--- v0/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java	2025-02-23 19:34:55.706323245 +0300
@@ -25,6 +25,13 @@
 import com.oltpbenchmark.util.SQLUtil;
 import com.oltpbenchmark.util.ScriptRunner;
 import com.oltpbenchmark.util.ThreadUtil;
+import com.zaxxer.hikari.HikariConfig;
+import com.zaxxer.hikari.HikariDataSource;
+import io.micrometer.core.instrument.Gauge;
+import io.micrometer.core.instrument.Metrics;
+import io.micrometer.core.instrument.Timer;
+import io.micrometer.core.instrument.simple.SimpleMeterRegistry;
+
 import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -34,6 +41,9 @@
 import java.sql.Connection;
 import java.sql.DriverManager;
 import java.sql.SQLException;
+import java.time.Duration;
+import java.util.concurrent.Semaphore;
+import java.util.concurrent.atomic.AtomicInteger;
 import java.util.*;
 
 /**
@@ -42,11 +52,48 @@
 public abstract class BenchmarkModule {
     private static final Logger LOG = LoggerFactory.getLogger(BenchmarkModule.class);
 
+    // We use virtual threads. There is a limitted number of c3p0 provided connections.
+    // When c3p0 runs out of connections, it will block until one is available. Block in a way
+    // that carrier threads are blocked. Same time other virtual threads holding connections
+    // might be parked waiting for a carrier thread to be available. This will cause a deadlock.
+    // To avoid this, we use a semaphore to wait for a connection without blocking the carrier thread.
+    private static Semaphore connectionSemaphore = new Semaphore(0);
+
+    private static final Gauge SESSIONS_USED = Gauge.builder("sessions", BenchmarkModule::getUsedConnectionCount)
+            .tag("state", "used")
+            .register(Metrics.globalRegistry);
+
+    private static final Gauge SESSIONS_QUEUE = Gauge.builder("session_queue_length", connectionSemaphore, Semaphore::getQueueLength)
+            .register(Metrics.globalRegistry);
+
+    private static final Timer.Builder GET_SESSION_DURATION = Timer.builder("get_session")
+            .serviceLevelObjectives(
+                    Duration.ofMillis(1),
+                    Duration.ofMillis(2),
+                    Duration.ofMillis(4),
+                    Duration.ofMillis(8),
+                    Duration.ofMillis(16),
+                    Duration.ofMillis(32),
+                    Duration.ofMillis(64),
+                    Duration.ofMillis(128),
+                    Duration.ofMillis(256),
+                    Duration.ofMillis(512),
+                    Duration.ofMillis(1024),
+                    Duration.ofMillis(2048),
+                    Duration.ofMillis(4096),
+                    Duration.ofMillis(8192),
+                    Duration.ofMillis(16384),
+                    Duration.ofMillis(32768),
+                    Duration.ofMillis(65536)
+            )
+            .publishPercentiles();
+
+    private static HikariDataSource dataSource;
 
     /**
      * The workload configuration for this benchmark invocation
      */
-    protected final WorkloadConfiguration workConf;
+    protected static WorkloadConfiguration workConf;
 
     /**
      * These are the variations of the Procedure's Statement SQL
@@ -72,6 +119,27 @@
     public BenchmarkModule(WorkloadConfiguration workConf) {
         this.workConf = workConf;
         this.dialects = new StatementDialects(workConf);
+
+        if (!workConf.getDisableConnectionPool() && dataSource == null) {
+            try {
+                dataSource = new HikariDataSource();
+                dataSource.setJdbcUrl(workConf.getUrl());
+                dataSource.setUsername(workConf.getUsername());
+                dataSource.setPassword(workConf.getPassword());
+
+                dataSource.setMaximumPoolSize(workConf.getMaxConnections());
+
+                dataSource.setMetricRegistry(Metrics.globalRegistry);
+
+                Runtime.getRuntime().addShutdownHook(new Thread(() -> {
+                    dataSource.close();
+                }));
+            } catch (Exception e) {
+                LOG.error("Unable to initialize DataSource: %s", e.toString());
+                throw new RuntimeException("Unable to initialize DataSource", e);
+            }
+        }
+        connectionSemaphore.release(workConf.getMaxConnections());
     }
 
     // --------------------------------------------------------------------------
@@ -79,17 +147,40 @@
     // --------------------------------------------------------------------------
 
     public final Connection makeConnection() throws SQLException {
-
-        if (StringUtils.isEmpty(workConf.getUsername())) {
-            return DriverManager.getConnection(workConf.getUrl());
-        } else {
-            return DriverManager.getConnection(
-                    workConf.getUrl(),
-                    workConf.getUsername(),
-                    workConf.getPassword());
+        long start = System.nanoTime();
+        try {
+            connectionSemaphore.acquire();
+            if (dataSource != null) {
+                return dataSource.getConnection();
+            }
+            if (StringUtils.isEmpty(workConf.getUsername())) {
+                return DriverManager.getConnection(workConf.getUrl());
+            } else {
+                return DriverManager.getConnection(
+                        workConf.getUrl(),
+                        workConf.getUsername(),
+                        workConf.getPassword());
+            }
+        } catch (SQLException e) {
+            connectionSemaphore.release();
+            throw e;
+        } catch (InterruptedException e) {
+            connectionSemaphore.release();
+            throw new SQLException(e);
+        } finally {
+            long end = System.nanoTime();
+            GET_SESSION_DURATION.register(Metrics.globalRegistry).record(Duration.ofNanos(end - start));
         }
     }
 
+    public final void returnConnection() {
+        connectionSemaphore.release();
+    }
+
+    public final static double getUsedConnectionCount() {
+        return workConf.getMaxConnections() - connectionSemaphore.availablePermits();
+    }
+
     // --------------------------------------------------------------------------
     // IMPLEMENTING CLASS INTERFACE
     // --------------------------------------------------------------------------
diff -ur v0/src/main/java/com/oltpbenchmark/api/Loader.java v1/src/main/java/com/oltpbenchmark/api/Loader.java
--- v0/src/main/java/com/oltpbenchmark/api/Loader.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/api/Loader.java	2025-02-23 19:34:55.706323245 +0300
@@ -44,12 +44,14 @@
 
     protected final WorkloadConfiguration workConf;
     protected final double scaleFactor;
+    protected final int startFromId;
     private final Histogram<String> tableSizes = new Histogram<>(true);
 
     public Loader(T benchmark) {
         this.benchmark = benchmark;
         this.workConf = benchmark.getWorkloadConfiguration();
         this.scaleFactor = workConf.getScaleFactor();
+        this.startFromId = workConf.getStartFromId();
     }
 
     /**
diff -ur v0/src/main/java/com/oltpbenchmark/api/LoaderThread.java v1/src/main/java/com/oltpbenchmark/api/LoaderThread.java
--- v0/src/main/java/com/oltpbenchmark/api/LoaderThread.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/api/LoaderThread.java	2025-02-23 19:34:55.706323245 +0300
@@ -49,6 +49,7 @@
             LOG.error(msg, next_ex);
             throw new RuntimeException(ex);
         } finally {
+            benchmarkModule.returnConnection();
             afterLoad();
         }
     }
diff -ur v0/src/main/java/com/oltpbenchmark/api/StatementDialects.java v1/src/main/java/com/oltpbenchmark/api/StatementDialects.java
--- v0/src/main/java/com/oltpbenchmark/api/StatementDialects.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/api/StatementDialects.java	2025-02-23 19:34:55.706323245 +0300
@@ -20,7 +20,6 @@
 import com.oltpbenchmark.WorkloadConfiguration;
 import com.oltpbenchmark.api.dialects.*;
 import com.oltpbenchmark.types.DatabaseType;
-import com.oltpbenchmark.types.State;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.xml.sax.SAXException;
diff -ur v0/src/main/java/com/oltpbenchmark/api/Worker.java v1/src/main/java/com/oltpbenchmark/api/Worker.java
--- v0/src/main/java/com/oltpbenchmark/api/Worker.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/api/Worker.java	2025-02-23 19:34:55.706323245 +0300
@@ -20,30 +20,90 @@
 import com.oltpbenchmark.*;
 import com.oltpbenchmark.api.Procedure.UserAbortException;
 import com.oltpbenchmark.types.DatabaseType;
-import com.oltpbenchmark.types.State;
 import com.oltpbenchmark.types.TransactionStatus;
 import com.oltpbenchmark.util.Histogram;
+import io.micrometer.core.instrument.Gauge;
+import io.micrometer.core.instrument.Counter;
+import io.micrometer.core.instrument.Metrics;
+import io.micrometer.core.instrument.Timer;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import java.sql.Connection;
 import java.sql.SQLException;
-import java.sql.Statement;
+import java.time.Duration;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
 import java.util.Random;
 import java.util.concurrent.atomic.AtomicInteger;
-
-import static com.oltpbenchmark.types.State.MEASURE;
+import java.util.concurrent.ThreadLocalRandom;
 
 public abstract class Worker<T extends BenchmarkModule> implements Runnable {
     private static final Logger LOG = LoggerFactory.getLogger(Worker.class);
     private static final Logger ABORT_LOG = LoggerFactory.getLogger("com.oltpbenchmark.api.ABORT_LOG");
 
-    private WorkloadState workloadState;
-    private LatencyRecord latencies;
-    private final Statement currStatement;
+    private static final AtomicInteger WORKERS_SLEEPING = new AtomicInteger(0);
+    private static final AtomicInteger WORKERS_WORKING = new AtomicInteger(0);
+
+    private static final Gauge WORKERS_SLEEPING_GAUGE = Gauge.builder("workers", WORKERS_SLEEPING, AtomicInteger::get)
+            .tag("state", "sleeping")
+            .register(Metrics.globalRegistry);
+
+    private static final Gauge WORKERS_WORKING_GAUGE = Gauge.builder("workers", WORKERS_WORKING, AtomicInteger::get)
+            .tag("state", "working")
+            .register(Metrics.globalRegistry);
+
+    private static final Counter.Builder TRANSACTIONS = Counter.builder("transactions");
+    private static final Counter.Builder EXECUTIONS = Counter.builder("executions");
+    private static final Counter.Builder ERRORS = Counter.builder("errors");
+    private static final Counter.Builder CONNECTION_ERRORS = Counter.builder("connection_errors");
+
+    private static final Timer.Builder TRANSACTION_DURATION = Timer.builder("transaction")
+            .serviceLevelObjectives(
+                    Duration.ofMillis(1),
+                    Duration.ofMillis(2),
+                    Duration.ofMillis(4),
+                    Duration.ofMillis(8),
+                    Duration.ofMillis(16),
+                    Duration.ofMillis(32),
+                    Duration.ofMillis(64),
+                    Duration.ofMillis(128),
+                    Duration.ofMillis(256),
+                    Duration.ofMillis(512),
+                    Duration.ofMillis(1024),
+                    Duration.ofMillis(2048),
+                    Duration.ofMillis(4096),
+                    Duration.ofMillis(8192),
+                    Duration.ofMillis(16384),
+                    Duration.ofMillis(32768),
+                    Duration.ofMillis(65536)
+            )
+            .publishPercentiles();
+
+    private static final Timer.Builder EXECUTION_DURATION = Timer.builder("execution")
+            .serviceLevelObjectives(
+                    Duration.ofMillis(1),
+                    Duration.ofMillis(2),
+                    Duration.ofMillis(4),
+                    Duration.ofMillis(8),
+                    Duration.ofMillis(16),
+                    Duration.ofMillis(32),
+                    Duration.ofMillis(64),
+                    Duration.ofMillis(128),
+                    Duration.ofMillis(256),
+                    Duration.ofMillis(512),
+                    Duration.ofMillis(1024),
+                    Duration.ofMillis(2048),
+                    Duration.ofMillis(4096),
+                    Duration.ofMillis(8192),
+                    Duration.ofMillis(16384),
+                    Duration.ofMillis(32768),
+                    Duration.ofMillis(65536)
+            )
+            .publishPercentiles();
+
+    private ResultStats resultStats;
 
     // Interval requests used by the monitor
     private final AtomicInteger intervalRequests = new AtomicInteger(0);
@@ -52,6 +112,7 @@
     private final T benchmark;
     protected Connection conn = null;
     protected final WorkloadConfiguration configuration;
+    protected BenchmarkState benchmarkState;
     protected final TransactionTypes transactionTypes;
     protected final Map<TransactionType, Procedure> procedures = new HashMap<>();
     protected final Map<String, Procedure> name_procedures = new HashMap<>();
@@ -64,15 +125,12 @@
     private final Histogram<TransactionType> txnErrors = new Histogram<>();
     private final Histogram<TransactionType> txtRetryDifferent = new Histogram<>();
 
-    private boolean seenDone = false;
-
     public Worker(T benchmark, int id) {
         this.id = id;
         this.benchmark = benchmark;
         this.configuration = this.benchmark.getWorkloadConfiguration();
-        this.workloadState = this.configuration.getWorkloadState();
-        this.currStatement = null;
         this.transactionTypes = this.configuration.getTransTypes();
+        this.resultStats = new ResultStats(this.transactionTypes);
 
         if (!this.configuration.getNewConnectionPerTxn()) {
             try {
@@ -93,6 +151,10 @@
         }
     }
 
+    public void setBenchmarkState(BenchmarkState state) {
+        this.benchmarkState = state;
+    }
+
     /**
      * Get the BenchmarkModule managing this Worker
      */
@@ -120,16 +182,16 @@
         return (this.benchmark.rng());
     }
 
-    public final int getRequests() {
-        return latencies.size();
+    public final long getRequests() {
+        return resultStats.count();
     }
 
     public final int getAndResetIntervalRequests() {
         return intervalRequests.getAndSet(0);
     }
 
-    public final Iterable<LatencyRecord.Sample> getLatencyRecords() {
-        return latencies;
+    public final ResultStats getStats() {
+        return resultStats;
     }
 
     public final Procedure getProcedure(TransactionType type) {
@@ -170,26 +232,13 @@
         return (this.txtRetryDifferent);
     }
 
-    /**
-     * Stop executing the current statement.
-     */
-    synchronized public void cancelStatement() {
-        try {
-            if (this.currStatement != null) {
-                this.currStatement.cancel();
-            }
-        } catch (SQLException e) {
-            LOG.error("Failed to cancel statement: {}", e.getMessage());
-        }
-    }
-
     @Override
     public final void run() {
         Thread t = Thread.currentThread();
         t.setName(this.toString());
 
         // In case of reuse reset the measurements
-        latencies = new LatencyRecord(workloadState.getTestStartNs());
+        resultStats = new ResultStats(this.transactionTypes);
 
         // Invoke initialize callback
         try {
@@ -199,180 +248,103 @@
         }
 
         // wait for start
-        workloadState.blockForStart();
+        benchmarkState.blockForStart();
 
-        while (true) {
-
-            // PART 1: Init and check if done
-
-            State preState = workloadState.getGlobalState();
-
-            // Do nothing
-            if (preState == State.DONE) {
-                if (!seenDone) {
-                    // This is the first time we have observed that the
-                    // test is done notify the global test state, then
-                    // continue applying load
-                    seenDone = true;
-                    workloadState.signalDone();
-                    break;
-                }
-            }
-
-            // PART 2: Wait for work
-
-            // Sleep if there's nothing to do.
-            workloadState.stayAwake();
-
-            Phase prePhase = workloadState.getCurrentPhase();
-            if (prePhase == null) {
-                continue;
+        // Additional delay to avoid starting all threads simultaneously
+        final int warmup = configuration.getWarmupTime();
+        if (warmup > 0) {
+            int maxDelayMs = (int)(1000 * warmup * 2 / 3);
+            int delayMs = ThreadLocalRandom.current().nextInt(maxDelayMs);
+            LOG.debug("Worker {} will sleep for {} s before starting", id, (int)(delayMs / 1000));
+            try {
+                Thread.sleep(delayMs);
+                LOG.debug("Worker {} thread started", id);
+            } catch (InterruptedException e) {
+                LOG.error("Worker {} pre-start sleep interrupted", id, e);
             }
+        }
 
-            // Grab some work and update the state, in case it changed while we
-            // waited.
-
-            SubmittedProcedure pieceOfWork = workloadState.fetchWork();
-
-            prePhase = workloadState.getCurrentPhase();
-            if (prePhase == null) {
-                continue;
+        while (benchmarkState.isWorkingOrMeasuring()) {
+            SubmittedProcedure pieceOfWork = benchmarkState.fetchWork();
+            if (pieceOfWork == null) {
+                LOG.debug("Worker {} thread got null work", id);
+                break;
             }
 
-            preState = workloadState.getGlobalState();
+            TransactionType transactionType;
+            try {
+                transactionType = transactionTypes.getType(pieceOfWork.getType());
 
-            switch (preState) {
-                case DONE, EXIT, LATENCY_COMPLETE -> {
-                    // Once a latency run is complete, we wait until the next
-                    // phase or until DONE.
-                    LOG.warn("preState is {}? will continue...", preState);
-                    continue;
-                }
-                default -> {
+                // just sanity check
+                if (transactionType.equals(TransactionType.INVALID)) {
+                    LOG.error("Worker {} thread got invalid work", id);
+                    throw new IndexOutOfBoundsException("Invalid transaction type");
                 }
-                // Do nothing
+            } catch (IndexOutOfBoundsException e) {
+                LOG.error("Worker {} thread tried executing disabled phase!", id);
+                throw e;
             }
 
-            // PART 3: Execute work
-
-            TransactionType transactionType = getTransactionType(pieceOfWork, prePhase, preState, workloadState);
-
-            if (!transactionType.equals(TransactionType.INVALID)) {
-
-                // TODO: Measuring latency when not rate limited is ... a little
-                // weird because if you add more simultaneous clients, you will
-                // increase latency (queue delay) but we do this anyway since it is
-                // useful sometimes
-
-                // Wait before transaction if specified
-                long preExecutionWaitInMillis = getPreExecutionWaitInMillis(transactionType);
-
-                if (preExecutionWaitInMillis > 0) {
-                    try {
-                        LOG.debug("{} will sleep for {} ms before executing", transactionType.getName(), preExecutionWaitInMillis);
+            long preExecutionWaitInMillis = getPreExecutionWaitInMillis(transactionType);
+            if (preExecutionWaitInMillis > 0) {
+                try {
+                    LOG.debug("Worker {}: {} will sleep for {} ms before executing",
+                        id, transactionType.getName(), preExecutionWaitInMillis);
 
-                        Thread.sleep(preExecutionWaitInMillis);
-                    } catch (InterruptedException e) {
-                        LOG.error("Pre-execution sleep interrupted", e);
-                    }
+                    WORKERS_SLEEPING.incrementAndGet();
+                    Thread.sleep(preExecutionWaitInMillis);
+                    WORKERS_SLEEPING.decrementAndGet();
+                    LOG.debug("Worker {} woke up to execute {}", id, transactionType.getName());
+                } catch (InterruptedException e) {
+                    LOG.error("Worker {} pre-execution sleep interrupted", id, e);
                 }
+            }
 
-                long start = System.nanoTime();
-
-                doWork(configuration.getDatabaseType(), transactionType);
-
-                long end = System.nanoTime();
-
-                // PART 4: Record results
+            WORKERS_WORKING.incrementAndGet();
+            long start = System.nanoTime();
 
-                State postState = workloadState.getGlobalState();
+            TransactionStatus status = doWork(configuration.getDatabaseType(), transactionType);
 
-                switch (postState) {
-                    case MEASURE:
-                        // Non-serial measurement. Only measure if the state both
-                        // before and after was MEASURE, and the phase hasn't
-                        // changed, otherwise we're recording results for a query
-                        // that either started during the warmup phase or ended
-                        // after the timer went off.
-                        Phase postPhase = workloadState.getCurrentPhase();
-
-                        if (postPhase == null) {
-                            // Need a null check on postPhase since current phase being null is used in WorkloadState
-                            // and ThreadBench as the indication that the benchmark is over. However, there's a race
-                            // condition with postState not being changed from MEASURE to DONE yet, so we entered the
-                            // switch. In this scenario, just break from the switch.
-                            break;
-                        }
-                        if (preState == MEASURE && postPhase.getId() == prePhase.getId()) {
-                            latencies.addLatency(transactionType.getId(), start, end, this.id, prePhase.getId());
-                            intervalRequests.incrementAndGet();
-                        }
-                        if (prePhase.isLatencyRun()) {
-                            workloadState.startColdQuery();
-                        }
-                        break;
-                    case COLD_QUERY:
-                        // No recording for cold runs, but next time we will since
-                        // it'll be a hot run.
-                        if (preState == State.COLD_QUERY) {
-                            workloadState.startHotQuery();
-                        }
-                        break;
-                    default:
-                        // Do nothing
-                }
+            long end = System.nanoTime();
+            WORKERS_WORKING.decrementAndGet();
 
+            TRANSACTIONS.tag("type", "any").register(Metrics.globalRegistry).increment();
+            TRANSACTIONS.tag("type", transactionType.getName()).register(Metrics.globalRegistry).increment();
+            TRANSACTION_DURATION.tag("type", "any").register(Metrics.globalRegistry)
+                    .record(Duration.ofNanos(end - start));
+            TRANSACTION_DURATION.tag("type", transactionType.getName()).register(Metrics.globalRegistry)
+                    .record(Duration.ofNanos(end - start));
+
+            if (benchmarkState.isMeasuring()) {
+                boolean isSuccess = status == TransactionStatus.SUCCESS ||
+                    status == TransactionStatus.USER_ABORTED;
+                resultStats.addLatency(
+                    transactionType.getId(),
+                    start,
+                    end,
+                    isSuccess);
+                intervalRequests.incrementAndGet();
+            }
 
-                // wait after transaction if specified
-                long postExecutionWaitInMillis = getPostExecutionWaitInMillis(transactionType);
-
-                if (postExecutionWaitInMillis > 0) {
-                    try {
-                        LOG.debug("{} will sleep for {} ms after executing", transactionType.getName(), postExecutionWaitInMillis);
+            long postExecutionWaitInMillis = getPostExecutionWaitInMillis(transactionType);
+            if (postExecutionWaitInMillis > 0) {
+                try {
+                    LOG.debug("Worker {} {} will sleep for {} ms after executing",
+                        id, transactionType.getName(), postExecutionWaitInMillis);
 
-                        Thread.sleep(postExecutionWaitInMillis);
-                    } catch (InterruptedException e) {
-                        LOG.error("Post-execution sleep interrupted", e);
-                    }
+                    WORKERS_SLEEPING.incrementAndGet();
+                    Thread.sleep(postExecutionWaitInMillis);
+                    WORKERS_SLEEPING.decrementAndGet();
+                } catch (InterruptedException e) {
+                    LOG.error("Worker {} post-execution sleep interrupted", id, e);
                 }
             }
-
-            workloadState.finishedWork();
         }
 
-        LOG.debug("worker calling teardown");
+        LOG.debug("Worker {} calling teardown", id);
 
         tearDown();
-    }
-
-    private TransactionType getTransactionType(SubmittedProcedure pieceOfWork, Phase phase, State state, WorkloadState workloadState) {
-        TransactionType type = TransactionType.INVALID;
-
-        try {
-            type = transactionTypes.getType(pieceOfWork.getType());
-        } catch (IndexOutOfBoundsException e) {
-            if (phase.isThroughputRun()) {
-                LOG.error("Thread tried executing disabled phase!");
-                throw e;
-            }
-            if (phase.getId() == workloadState.getCurrentPhase().getId()) {
-                switch (state) {
-                    case WARMUP -> {
-                        // Don't quit yet: we haven't even begun!
-                        LOG.info("[Serial] Resetting serial for phase.");
-                        phase.resetSerial();
-                    }
-                    case COLD_QUERY, MEASURE -> {
-                        // The serial phase is over. Finish the run early.
-                        LOG.info("[Serial] Updating workload state to {}.", State.LATENCY_COMPLETE);
-                        workloadState.signalLatencyComplete();
-                    }
-                    default -> throw e;
-                }
-            }
-        }
-
-        return type;
+        benchmarkState.workerFinished();
     }
 
     /**
@@ -383,86 +355,121 @@
      * @param databaseType TODO
      * @param transactionType TODO
      */
-    protected final void doWork(DatabaseType databaseType, TransactionType transactionType) {
+    protected final TransactionStatus doWork(DatabaseType databaseType, TransactionType transactionType) {
+        TransactionStatus status = TransactionStatus.UNKNOWN;
 
         try {
+            // TODO: we might need backoff for retries
+
             int retryCount = 0;
             int maxRetryCount = configuration.getMaxRetries();
 
-            while (retryCount < maxRetryCount && this.workloadState.getGlobalState() != State.DONE) {
-
-                TransactionStatus status = TransactionStatus.UNKNOWN;
+            while (retryCount <= maxRetryCount && this.benchmarkState.isWorkingOrMeasuring()) {
+                status = TransactionStatus.UNKNOWN;
 
                 if (this.conn == null) {
                     try {
+                        LOG.debug("Worker {} opening a new connection", id);
                         this.conn = this.benchmark.makeConnection();
                         this.conn.setAutoCommit(false);
                         this.conn.setTransactionIsolation(this.configuration.getIsolationMode());
                     } catch (SQLException ex) {
-                        if (LOG.isDebugEnabled()) {
-                            LOG.debug(String.format("%s failed to open a connection...", this));
-                        }
+                        LOG.debug("Worker {} failed to open a connection: {}", id, ex);
                         retryCount++;
+
+                        CONNECTION_ERRORS.tag("type", "any")
+                                .register(Metrics.globalRegistry).increment();
+                        CONNECTION_ERRORS.tag("type", String.valueOf(ex.getErrorCode()))
+                                .register(Metrics.globalRegistry).increment();
+
                         continue;
                     }
                 }
 
+                long start = System.nanoTime();
                 try {
-
-                    if (LOG.isDebugEnabled()) {
-                        LOG.debug(String.format("%s %s attempting...", this, transactionType));
-                    }
+                    LOG.debug("Worker {} is attempting {}", id, transactionType);
 
                     status = this.executeWork(conn, transactionType);
 
-                    if (LOG.isDebugEnabled()) {
-                        LOG.debug(String.format("%s %s completed with status [%s]...", this, transactionType, status.name()));
-                    }
-
-                    if (LOG.isDebugEnabled()) {
-                        LOG.debug(String.format("%s %s committing...", this, transactionType));
-                    }
+                    LOG.debug("Worker {} completed {} with status {} and going to commit",
+                        id, transactionType, status.name());
 
                     conn.commit();
-
                     break;
-
                 } catch (UserAbortException ex) {
-                    conn.rollback();
+                    // TODO: probably check exception and retry if possible
+                    try {
+                        conn.rollback();
+                        status = TransactionStatus.USER_ABORTED;
+                    } catch (Exception e) {
+                        LOG.warn(
+                            "Worker {} failed to rollback transaction after UserAbortException ({}): {}",
+                            id, ex.toString(), e.toString());
 
-                    ABORT_LOG.debug(String.format("%s Aborted", transactionType), ex);
+                        status = TransactionStatus.ERROR;
+                    }
 
-                    status = TransactionStatus.USER_ABORTED;
+                    ABORT_LOG.debug("{} Aborted", transactionType, ex);
 
                     break;
-
                 } catch (SQLException ex) {
-                    conn.rollback();
+                    int errorCode = ex.getErrorCode();
+
+                    ERRORS.tag("type", "any")
+                            .register(Metrics.globalRegistry).increment();
+                    ERRORS.tag("type", String.valueOf(errorCode))
+                            .register(Metrics.globalRegistry).increment();
+
+                    try {
+                        LOG.debug("Worker {} rolled back transaction {}", id, transactionType);
+                        conn.rollback();
+                    } catch (Exception e) {
+                        LOG.warn(
+                            "Worker {} failed to rollback transaction after SQLException ({}): {}",
+                            id, ex.toString(), e.toString());
+                    }
 
                     if (isRetryable(ex)) {
-                        LOG.debug(String.format("Retryable SQLException occurred during [%s]... current retry attempt [%d], max retry attempts [%d], sql state [%s], error code [%d].", transactionType, retryCount, maxRetryCount, ex.getSQLState(), ex.getErrorCode()), ex);
+                        LOG.debug(
+                            "Worker {} Retryable SQLException occurred during [{}]... current retry attempt [{}], max retry attempts [{}], sql state [{}], error code [{}].",
+                            id, transactionType, retryCount, maxRetryCount, ex.getSQLState(), ex.getErrorCode(), ex);
 
                         status = TransactionStatus.RETRY;
 
                         retryCount++;
                     } else {
-                        LOG.warn(String.format("SQLException occurred during [%s] and will not be retried... sql state [%s], error code [%d].", transactionType, ex.getSQLState(), ex.getErrorCode()), ex);
+                        LOG.warn(
+                            "Worker {} SQLException occurred during [{}] and will not be retried... sql state [{}], error code [{}].",
+                            id, transactionType, ex.getSQLState(), ex.getErrorCode(), ex);
 
                         status = TransactionStatus.ERROR;
 
                         break;
                     }
-
                 } finally {
                     if (this.configuration.getNewConnectionPerTxn() && this.conn != null) {
                         try {
+                            LOG.debug("Worker {} closing connection", id);
                             this.conn.close();
                             this.conn = null;
+                            this.benchmark.returnConnection();
                         } catch (SQLException e) {
-                            LOG.error("Connection couldn't be closed.", e);
+                            LOG.error("Worker {} connection couldn't be closed.", id, e);
+                            throw new RuntimeException("Failed to close connection", e);
                         }
                     }
 
+                    long end = System.nanoTime();
+
+                    EXECUTION_DURATION.tag("type", "any").register(Metrics.globalRegistry)
+                            .record(Duration.ofNanos(end - start));
+                    EXECUTION_DURATION.tag("type", status.toString()).register(Metrics.globalRegistry)
+                            .record(Duration.ofNanos(end - start));
+
+                    EXECUTIONS.tag("type", "any").register(Metrics.globalRegistry).increment();
+                    EXECUTIONS.tag("type", status.toString()).register(Metrics.globalRegistry).increment();
+
                     switch (status) {
                         case UNKNOWN -> this.txnUnknown.put(transactionType);
                         case SUCCESS -> this.txnSuccess.put(transactionType);
@@ -471,16 +478,15 @@
                         case RETRY_DIFFERENT -> this.txtRetryDifferent.put(transactionType);
                         case ERROR -> this.txnErrors.put(transactionType);
                     }
-
                 }
-
             }
-        } catch (SQLException ex) {
-            String msg = String.format("Unexpected SQLException in '%s' when executing '%s' on [%s]", this, transactionType, databaseType.name());
-
-            throw new RuntimeException(msg, ex);
+        } catch (RuntimeException ex) {
+            LOG.error("Worker {} Unexpected RuntimeException when executing '%s' on [%s]: %s",
+                id, transactionType, databaseType.name(), ex.toString(), ex);
+            throw ex;
         }
 
+        return status;
     }
 
     private boolean isRetryable(SQLException ex) {
@@ -488,7 +494,7 @@
         String sqlState = ex.getSQLState();
         int errorCode = ex.getErrorCode();
 
-        LOG.debug("sql state [{}] and error code [{}]", sqlState, errorCode);
+        LOG.debug("Worker {} sql state [{}] and error code [{}]", id, sqlState, errorCode);
 
         if (sqlState == null) {
             return false;
@@ -538,16 +544,14 @@
         if (!this.configuration.getNewConnectionPerTxn() && this.conn != null) {
             try {
                 conn.close();
+                this.conn = null;
+                this.benchmark.returnConnection();
             } catch (SQLException e) {
-                LOG.error("Connection couldn't be closed.", e);
+                LOG.error("Worker {} connection couldn't be closed.", id, e);
             }
         }
     }
 
-    public void initializeState() {
-        this.workloadState = this.configuration.getWorkloadState();
-    }
-
     protected long getPreExecutionWaitInMillis(TransactionType type) {
         return 0;
     }
diff -ur v0/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java v1/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java
--- v0/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java	2025-02-23 19:35:48.930799455 +0300
+++ v1/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java	2025-02-23 19:34:55.702323209 +0300
@@ -71,48 +71,29 @@
             numWarehouses = 1;
         }
 
-        int numTerminals = workConf.getTerminals();
+        final int startWarehouseId = workConf.getStartFromId();
 
-        // We distribute terminals evenly across the warehouses
-        // Eg. if there are 10 terminals across 7 warehouses, they
-        // are distributed as
-        // 1, 1, 2, 1, 2, 1, 2
-        final double terminalsPerWarehouse = (double) numTerminals / numWarehouses;
-        int workerId = 0;
-
-        for (int w = 0; w < numWarehouses; w++) {
-            // Compute the number of terminals in *this* warehouse
-            int lowerTerminalId = (int) (w * terminalsPerWarehouse);
-            int upperTerminalId = (int) ((w + 1) * terminalsPerWarehouse);
-            // protect against double rounding errors
-            int w_id = w + 1;
-            if (w_id == numWarehouses) {
-                upperTerminalId = numTerminals;
-            }
-            int numWarehouseTerminals = upperTerminalId - lowerTerminalId;
+        final int numTerminals = workConf.getTerminals();
 
-            if (LOG.isDebugEnabled()) {
-                LOG.debug(String.format("w_id %d = %d terminals [lower=%d / upper%d]", w_id, numWarehouseTerminals, lowerTerminalId, upperTerminalId));
-            }
+        final int terminalsPerWarehouse = (int) numTerminals / numWarehouses;
+
+        assert (terminalsPerWarehouse == 10); // according TPC-C
+
+        final int lowerDistrictId = 1;
+        final int upperDistrictId = terminalsPerWarehouse;
+
+        int terminalIndex = 0;
+        int workerId = startWarehouseId / numWarehouses * numTerminals;
 
-            final double districtsPerTerminal = TPCCConfig.configDistPerWhse / (double) numWarehouseTerminals;
-            for (int terminalId = 0; terminalId < numWarehouseTerminals; terminalId++) {
-                int lowerDistrictId = (int) (terminalId * districtsPerTerminal);
-                int upperDistrictId = (int) ((terminalId + 1) * districtsPerTerminal);
-                if (terminalId + 1 == numWarehouseTerminals) {
-                    upperDistrictId = TPCCConfig.configDistPerWhse;
-                }
-                lowerDistrictId += 1;
+        for (int w = startWarehouseId - 1; w < numWarehouses + startWarehouseId - 1; w++) {
+            final int w_id = w + 1;
 
+            for (int terminalId = 0; terminalId < terminalsPerWarehouse; terminalId++) {
                 TPCCWorker terminal = new TPCCWorker(this, workerId++, w_id, lowerDistrictId, upperDistrictId, numWarehouses);
-                terminals[lowerTerminalId + terminalId] = terminal;
+                terminals[terminalIndex++] = terminal;
             }
-
         }
 
-
         return Arrays.asList(terminals);
     }
-
-
 }
diff -ur v0/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java v1/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java
--- v0/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java	2025-02-23 19:34:55.706323245 +0300
@@ -22,6 +22,7 @@
 import com.oltpbenchmark.api.LoaderThread;
 import com.oltpbenchmark.benchmarks.tpcc.pojo.*;
 import com.oltpbenchmark.catalog.Table;
+import com.oltpbenchmark.util.ThreadLocalRandomGenerator;
 import com.oltpbenchmark.util.SQLUtil;
 
 import java.sql.*;
@@ -51,23 +52,25 @@
 
         // ITEM
         // This will be invoked first and executed in a single thread.
-        threads.add(new LoaderThread(this.benchmark) {
-            @Override
-            public void load(Connection conn) {
-                loadItems(conn, TPCCConfig.configItemCount);
-            }
-
-            @Override
-            public void afterLoad() {
-                itemLatch.countDown();
-            }
-        });
+        if (this.startFromId == 1) {
+            threads.add(new LoaderThread(this.benchmark) {
+                @Override
+                public void load(Connection conn) {
+                    loadItems(conn, TPCCConfig.configItemCount);
+                }
+
+                @Override
+                public void afterLoad() {
+                    itemLatch.countDown();
+                }
+            });
+        }
 
         // WAREHOUSES
         // We use a separate thread per warehouse. Each thread will load
         // all of the tables that depend on that warehouse. They all have
         // to wait until the ITEM table is loaded first though.
-        for (int w = 1; w <= numWarehouses; w++) {
+        for (int w = this.startFromId; w <= startFromId + numWarehouses - 1; w++) {
             final int w_id = w;
             LoaderThread t = new LoaderThread(this.benchmark) {
                 @Override
diff -ur v0/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCUtil.java v1/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCUtil.java
--- v0/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCUtil.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCUtil.java	2025-02-23 19:34:55.706323245 +0300
@@ -19,7 +19,7 @@
 package com.oltpbenchmark.benchmarks.tpcc;
 
 import com.oltpbenchmark.benchmarks.tpcc.pojo.Customer;
-import com.oltpbenchmark.util.RandomGenerator;
+import com.oltpbenchmark.util.ThreadLocalRandomGenerator;
 
 import java.sql.ResultSet;
 import java.sql.SQLException;
@@ -59,7 +59,7 @@
         return c;
     }
 
-    private static final RandomGenerator ran = new RandomGenerator(0);
+    private static final ThreadLocalRandomGenerator ran = new ThreadLocalRandomGenerator();
 
     public static String randomStr(int strLen) {
         if (strLen > 1) {
diff -ur v0/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCWorker.java v1/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCWorker.java
--- v0/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCWorker.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCWorker.java	2025-02-23 19:34:55.706323245 +0300
@@ -53,7 +53,6 @@
         this.terminalDistrictLowerID = terminalDistrictLowerID;
         this.terminalDistrictUpperID = terminalDistrictUpperID;
 
-
         this.numWarehouses = numWarehouses;
     }
 
diff -ur v0/src/main/java/com/oltpbenchmark/BenchmarkState.java v1/src/main/java/com/oltpbenchmark/BenchmarkState.java
--- v0/src/main/java/com/oltpbenchmark/BenchmarkState.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/BenchmarkState.java	2025-02-23 19:34:55.678322992 +0300
@@ -17,32 +17,46 @@
 
 package com.oltpbenchmark;
 
-import com.oltpbenchmark.types.State;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicReference;
+import java.util.concurrent.CountDownLatch;
 
+// shared between controlling ThreadBench thread and worker threads
 public final class BenchmarkState {
+    public enum State {
+        WARMUP, MEASURE, DONE, EXIT, ERROR
+    }
 
     private static final Logger LOG = LoggerFactory.getLogger(BenchmarkState.class);
 
+    private final WorkloadConfiguration workloadConf;
     private final long testStartNs;
     private final CountDownLatch startBarrier;
     private final AtomicInteger notDoneCount;
-    private volatile State state = State.WARMUP;
+
+    private final AtomicReference<State> state = new AtomicReference<>(State.WARMUP);
 
     /**
      * @param numThreads number of threads involved in the test: including the
      *                   master thread.
      */
-    public BenchmarkState(int numThreads) {
-        startBarrier = new CountDownLatch(numThreads);
-        notDoneCount = new AtomicInteger(numThreads);
+    public BenchmarkState(int numThreads, WorkloadConfiguration workloadConf) {
+        this.workloadConf = workloadConf;
+        this.startBarrier = new CountDownLatch(numThreads);
+        this.notDoneCount = new AtomicInteger(numThreads);
+
+        this.testStartNs = System.nanoTime();
+    }
 
+    public SubmittedProcedure fetchWork() {
+        if (getState() == State.EXIT || getState() == State.DONE) {
+            return null;
+        }
 
-        testStartNs = System.nanoTime();
+        return new SubmittedProcedure(workloadConf.getPhase().chooseTransaction());
     }
 
     // Protected by this
@@ -52,9 +66,7 @@
     }
 
     public State getState() {
-        synchronized (this) {
-            return state;
-        }
+        return state.get();
     }
 
     /**
@@ -62,8 +74,6 @@
      * entered.
      */
     public void blockForStart() {
-
-
         startBarrier.countDown();
         try {
             startBarrier.await();
@@ -73,54 +83,45 @@
     }
 
     public void startMeasure() {
-        state = State.MEASURE;
+        state.set(State.MEASURE);
     }
 
-    public void startColdQuery() {
-        state = State.COLD_QUERY;
+    public void signalError() {
+        notDoneCount.decrementAndGet();
+        state.set(State.ERROR);
     }
 
-    public void startHotQuery() {
-        state = State.MEASURE;
+    public boolean isError() {
+        return getState() == State.ERROR;
     }
 
-    public void signalLatencyComplete() {
-        state = State.LATENCY_COMPLETE;
+    public boolean isWorkingOrMeasuring() {
+        return getState() == State.WARMUP || getState() == State.MEASURE;
     }
 
-    public void ackLatencyComplete() {
-        state = State.MEASURE;
+    public boolean isMeasuring() {
+        return getState() == State.MEASURE;
     }
 
-    public void signalError() {
-        // A thread died, decrement the count and set error state
+    public void workerFinished() {
         notDoneCount.decrementAndGet();
-        state = State.ERROR;
-    }
-
-    public void startCoolDown() {
-        state = State.DONE;
-
-        // The master thread must also signal that it is done
-        signalDone();
     }
 
-    /**
-     * Notify that this thread has entered the done state.
-     */
-    public int signalDone() {
-
-        int current = notDoneCount.decrementAndGet();
+    public void stopWorkers() {
+        int waitCount = notDoneCount.decrementAndGet();
+        if (waitCount > 0) {
+            LOG.debug(String.format("%d workers are not done. Waiting until they finish", waitCount));
+        }
 
-        if (LOG.isDebugEnabled()) {
-            LOG.debug(String.format("%d workers are not done. Waiting until they finish", current));
+        if (getState() != State.ERROR) {
+            // might be a minor race here, but not a problem
+            state.set(State.DONE);
         }
-        if (current == 0) {
-            // We are the last thread to notice that we are done: wake any
-            // blocked workers
-            this.state = State.EXIT;
+
+        while (notDoneCount.get() > 0) {
+            Thread.yield();
         }
-        return current;
-    }
 
+        LOG.debug("Workers stopped");
+    }
 }
\ В конце файла нет новой строки
diff -ur v0/src/main/java/com/oltpbenchmark/DBWorkload.java v1/src/main/java/com/oltpbenchmark/DBWorkload.java
--- v0/src/main/java/com/oltpbenchmark/DBWorkload.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/DBWorkload.java	2025-02-23 19:34:55.678322992 +0300
@@ -24,6 +24,12 @@
 import com.oltpbenchmark.api.Worker;
 import com.oltpbenchmark.types.DatabaseType;
 import com.oltpbenchmark.util.*;
+import io.micrometer.core.instrument.Metrics;
+import io.micrometer.core.instrument.Tags;
+import io.micrometer.prometheus.PrometheusConfig;
+import io.micrometer.prometheus.PrometheusMeterRegistry;
+import io.prometheus.client.exporter.HTTPServer;
+
 import org.apache.commons.cli.*;
 import org.apache.commons.collections4.map.ListOrderedMap;
 import org.apache.commons.configuration2.HierarchicalConfiguration;
@@ -41,7 +47,10 @@
 import java.io.File;
 import java.io.IOException;
 import java.io.PrintStream;
+import java.net.InetSocketAddress;
 import java.sql.SQLException;
+import java.text.DecimalFormat;
+import java.text.ParseException;
 import java.util.*;
 
 public class DBWorkload {
@@ -49,8 +58,12 @@
 
     private static final String SINGLE_LINE = StringUtil.repeat("=", 70);
 
-    private static final String RATE_DISABLED = "disabled";
-    private static final String RATE_UNLIMITED = "unlimited";
+    // FIXME: TPC-C only hack
+    private static int newOrderTxnId = -1;
+    private static int numWarehouses = 10;
+    private static int time = 0;
+
+    private static Boolean useRealThreads = false;
 
     /**
      * @param args
@@ -87,6 +100,15 @@
             intervalMonitor = Integer.parseInt(argsLine.getOptionValue("im"));
         }
 
+        int startFromId = 1;
+        if (argsLine.hasOption("sf")) {
+            startFromId = Integer.parseInt(argsLine.getOptionValue("sf"));
+        }
+
+        if (argsLine.hasOption("rt")) {
+            useRealThreads = true;
+        }
+
         // -------------------------------------------------------------------
         // GET PLUGIN LIST
         // -------------------------------------------------------------------
@@ -94,7 +116,17 @@
         String targetBenchmarks = argsLine.getOptionValue("b");
 
         String[] targetList = targetBenchmarks.split(",");
-        List<BenchmarkModule> benchList = new ArrayList<>();
+        if (targetList.length == 0) {
+            throw new ParseException("No benchmarks specified", 1);
+        }
+
+        if (targetList.length > 1) {
+            throw new ParseException("Only one benchmark can be specified when exporting dialects", 1);
+        }
+
+        if (!targetList[0].equals("tpcc")) {
+            throw new ParseException("Only TPC-C benchmark is supported", 1);
+        }
 
         // Use this list for filtering of the output
         List<TransactionType> activeTXTypes = new ArrayList<>();
@@ -105,308 +137,267 @@
 
         // Load the configuration for each benchmark
         int lastTxnId = 0;
-        for (String plugin : targetList) {
-            String pluginTest = "[@bench='" + plugin + "']";
-
-            // ----------------------------------------------------------------
-            // BEGIN LOADING WORKLOAD CONFIGURATION
-            // ----------------------------------------------------------------
-
-            WorkloadConfiguration wrkld = new WorkloadConfiguration();
-            wrkld.setBenchmarkName(plugin);
-            wrkld.setXmlConfig(xmlConfig);
-
-            // Pull in database configuration
-            wrkld.setDatabaseType(DatabaseType.get(xmlConfig.getString("type")));
-            wrkld.setDriverClass(xmlConfig.getString("driver"));
-            wrkld.setUrl(xmlConfig.getString("url"));
-            wrkld.setUsername(xmlConfig.getString("username"));
-            wrkld.setPassword(xmlConfig.getString("password"));
-            wrkld.setRandomSeed(xmlConfig.getInt("randomSeed", -1));
-            wrkld.setBatchSize(xmlConfig.getInt("batchsize", 128));
-            wrkld.setMaxRetries(xmlConfig.getInt("retries", 3));
-            wrkld.setNewConnectionPerTxn(xmlConfig.getBoolean("newConnectionPerTxn", false));
-
-            int terminals = xmlConfig.getInt("terminals[not(@bench)]", 0);
-            terminals = xmlConfig.getInt("terminals" + pluginTest, terminals);
-            wrkld.setTerminals(terminals);
-
-            if (xmlConfig.containsKey("loaderThreads")) {
-                int loaderThreads = xmlConfig.getInt("loaderThreads");
-                wrkld.setLoaderThreads(loaderThreads);
-            }
-
-            String isolationMode = xmlConfig.getString("isolation[not(@bench)]", "TRANSACTION_SERIALIZABLE");
-            wrkld.setIsolationMode(xmlConfig.getString("isolation" + pluginTest, isolationMode));
-            wrkld.setScaleFactor(xmlConfig.getDouble("scalefactor", 1.0));
-            wrkld.setDataDir(xmlConfig.getString("datadir", "."));
-            wrkld.setDDLPath(xmlConfig.getString("ddlpath", null));
+        final String plugin = "tpcc";
+        String pluginTest = "[@bench='" + plugin + "']";
 
-            double selectivity = -1;
-            try {
-                selectivity = xmlConfig.getDouble("selectivity");
-                wrkld.setSelectivity(selectivity);
-            } catch (NoSuchElementException nse) {
-                // Nothing to do here !
-            }
-
-            // ----------------------------------------------------------------
-            // CREATE BENCHMARK MODULE
-            // ----------------------------------------------------------------
-
-            String classname = pluginConfig.getString("/plugin[@name='" + plugin + "']");
-
-            if (classname == null) {
-                throw new ParseException("Plugin " + plugin + " is undefined in config/plugin.xml");
-            }
-
-            BenchmarkModule bench = ClassUtil.newInstance(classname, new Object[]{wrkld}, new Class<?>[]{WorkloadConfiguration.class});
-            Map<String, Object> initDebug = new ListOrderedMap<>();
-            initDebug.put("Benchmark", String.format("%s {%s}", plugin.toUpperCase(), classname));
-            initDebug.put("Configuration", configFile);
-            initDebug.put("Type", wrkld.getDatabaseType());
-            initDebug.put("Driver", wrkld.getDriverClass());
-            initDebug.put("URL", wrkld.getUrl());
-            initDebug.put("Isolation", wrkld.getIsolationString());
-            initDebug.put("Batch Size", wrkld.getBatchSize());
-            initDebug.put("Scale Factor", wrkld.getScaleFactor());
-            initDebug.put("Terminals", wrkld.getTerminals());
-            initDebug.put("New Connection Per Txn", wrkld.getNewConnectionPerTxn());
-
-            if (selectivity != -1) {
-                initDebug.put("Selectivity", selectivity);
-            }
-
-            LOG.info("{}\n\n{}", SINGLE_LINE, StringUtil.formatMaps(initDebug));
-            LOG.info(SINGLE_LINE);
-
-            // ----------------------------------------------------------------
-            // LOAD TRANSACTION DESCRIPTIONS
-            // ----------------------------------------------------------------
-            int numTxnTypes = xmlConfig.configurationsAt("transactiontypes" + pluginTest + "/transactiontype").size();
-            if (numTxnTypes == 0 && targetList.length == 1) {
-                //if it is a single workload run, <transactiontypes /> w/o attribute is used
-                pluginTest = "[not(@bench)]";
-                numTxnTypes = xmlConfig.configurationsAt("transactiontypes" + pluginTest + "/transactiontype").size();
-            }
+        // ----------------------------------------------------------------
+        // BEGIN LOADING WORKLOAD CONFIGURATION
+        // ----------------------------------------------------------------
+
+        WorkloadConfiguration wrkld = new WorkloadConfiguration();
+        wrkld.setBenchmarkName(plugin);
+        wrkld.setXmlConfig(xmlConfig);
+
+        // Pull in database configuration
+        wrkld.setDatabaseType(DatabaseType.get(xmlConfig.getString("type")));
+        wrkld.setDriverClass(xmlConfig.getString("driver"));
+        wrkld.setUrl(xmlConfig.getString("url"));
+        wrkld.setUsername(xmlConfig.getString("username"));
+        wrkld.setPassword(xmlConfig.getString("password"));
+        wrkld.setRandomSeed(xmlConfig.getInt("randomSeed", -1));
+        wrkld.setBatchSize(xmlConfig.getInt("batchsize", 128));
+        wrkld.setMaxRetries(xmlConfig.getInt("retries", 3));
+        wrkld.setMaxConnections(xmlConfig.getInt("maxConnections", wrkld.getMaxConnections()));
+        wrkld.setNewConnectionPerTxn(xmlConfig.getBoolean("newConnectionPerTxn", false));
+        wrkld.setDisableConnectionPool(xmlConfig.getBoolean("disableConnectionPool", false));
+
+        int terminals = xmlConfig.getInt("terminals[not(@bench)]", 0);
+        terminals = xmlConfig.getInt("terminals" + pluginTest, terminals);
+        wrkld.setTerminals(terminals);
+        wrkld.setStartFrom(startFromId);
+
+        if (xmlConfig.containsKey("loaderThreads")) {
+            int loaderThreads = xmlConfig.getInt("loaderThreads");
+            wrkld.setLoaderThreads(loaderThreads);
+        }
+
+        String isolationMode = xmlConfig.getString("isolation[not(@bench)]", "TRANSACTION_SERIALIZABLE");
+        wrkld.setIsolationMode(xmlConfig.getString("isolation" + pluginTest, isolationMode));
+
+        double scaleFactor = xmlConfig.getDouble("scalefactor", 1.0);
+        numWarehouses = (int) scaleFactor;
+        wrkld.setScaleFactor(scaleFactor);
+
+        wrkld.setDataDir(xmlConfig.getString("datadir", "."));
+        wrkld.setDDLPath(xmlConfig.getString("ddlpath", null));
+
+        double selectivity = -1;
+        try {
+            selectivity = xmlConfig.getDouble("selectivity");
+            wrkld.setSelectivity(selectivity);
+        } catch (NoSuchElementException nse) {
+            // Nothing to do here !
+        }
+
+        // ----------------------------------------------------------------
+        // CREATE BENCHMARK MODULE
+        // ----------------------------------------------------------------
+
+        String classname = pluginConfig.getString("/plugin[@name='" + plugin + "']");
+
+        if (classname == null) {
+            throw new ParseException("Plugin " + plugin + " is undefined in config/plugin.xml", 1);
+        }
+
+        BenchmarkModule benchmark = ClassUtil.newInstance(classname, new Object[]{wrkld}, new Class<?>[]{WorkloadConfiguration.class});
+        Map<String, Object> initDebug = new ListOrderedMap<>();
+        initDebug.put("Benchmark", String.format("%s {%s}", plugin.toUpperCase(), classname));
+        initDebug.put("Configuration", configFile);
+        initDebug.put("Type", wrkld.getDatabaseType());
+        initDebug.put("Driver", wrkld.getDriverClass());
+        initDebug.put("URL", wrkld.getUrl());
+        initDebug.put("Isolation", wrkld.getIsolationString());
+        initDebug.put("Batch Size", wrkld.getBatchSize());
+        initDebug.put("Scale Factor", wrkld.getScaleFactor());
+        initDebug.put("Terminals", wrkld.getTerminals());
+        initDebug.put("New Connection Per Txn", wrkld.getNewConnectionPerTxn());
 
+        if (selectivity != -1) {
+            initDebug.put("Selectivity", selectivity);
+        }
 
-            List<TransactionType> ttypes = new ArrayList<>();
-            ttypes.add(TransactionType.INVALID);
-            int txnIdOffset = lastTxnId;
-            for (int i = 1; i <= numTxnTypes; i++) {
-                String key = "transactiontypes" + pluginTest + "/transactiontype[" + i + "]";
-                String txnName = xmlConfig.getString(key + "/name");
-
-                // Get ID if specified; else increment from last one.
-                int txnId = i;
-                if (xmlConfig.containsKey(key + "/id")) {
-                    txnId = xmlConfig.getInt(key + "/id");
-                }
-
-                long preExecutionWait = 0;
-                if (xmlConfig.containsKey(key + "/preExecutionWait")) {
-                    preExecutionWait = xmlConfig.getLong(key + "/preExecutionWait");
-                }
+        LOG.info("{}\n\n{}", SINGLE_LINE, StringUtil.formatMaps(initDebug));
+        LOG.info(SINGLE_LINE);
 
-                long postExecutionWait = 0;
-                if (xmlConfig.containsKey(key + "/postExecutionWait")) {
-                    postExecutionWait = xmlConfig.getLong(key + "/postExecutionWait");
-                }
+        // ----------------------------------------------------------------
+        // LOAD TRANSACTION DESCRIPTIONS
+        // ----------------------------------------------------------------
+        int numTxnTypes = xmlConfig.configurationsAt("transactiontypes" + pluginTest + "/transactiontype").size();
+        if (numTxnTypes == 0 && targetList.length == 1) {
+            //if it is a single workload run, <transactiontypes /> w/o attribute is used
+            pluginTest = "[not(@bench)]";
+            numTxnTypes = xmlConfig.configurationsAt("transactiontypes" + pluginTest + "/transactiontype").size();
+        }
 
-                TransactionType tmpType = bench.initTransactionType(txnName, txnId + txnIdOffset, preExecutionWait, postExecutionWait);
 
-                // Keep a reference for filtering
-                activeTXTypes.add(tmpType);
+        List<TransactionType> ttypes = new ArrayList<>();
+        ttypes.add(TransactionType.INVALID);
+        int txnIdOffset = lastTxnId;
+        for (int i = 1; i <= numTxnTypes; i++) {
+            String key = "transactiontypes" + pluginTest + "/transactiontype[" + i + "]";
+            String txnName = xmlConfig.getString(key + "/name");
+            if (txnName.equals("NewOrder")) {
+                newOrderTxnId = i + txnIdOffset;
+            }
 
-                // Add a ref for the active TTypes in this benchmark
-                ttypes.add(tmpType);
-                lastTxnId = i;
-            }
-
-            // Wrap the list of transactions and save them
-            TransactionTypes tt = new TransactionTypes(ttypes);
-            wrkld.setTransTypes(tt);
-            LOG.debug("Using the following transaction types: {}", tt);
-
-            // Read in the groupings of transactions (if any) defined for this
-            // benchmark
-            int numGroupings = xmlConfig.configurationsAt("transactiontypes" + pluginTest + "/groupings/grouping").size();
-            LOG.debug("Num groupings: {}", numGroupings);
-            for (int i = 1; i < numGroupings + 1; i++) {
-                String key = "transactiontypes" + pluginTest + "/groupings/grouping[" + i + "]";
-
-                // Get the name for the grouping and make sure it's valid.
-                String groupingName = xmlConfig.getString(key + "/name").toLowerCase();
-                if (!groupingName.matches("^[a-z]\\w*$")) {
-                    LOG.error(String.format("Grouping name \"%s\" is invalid." + " Must begin with a letter and contain only" + " alphanumeric characters.", groupingName));
-                    System.exit(-1);
-                } else if (groupingName.equals("all")) {
-                    LOG.error("Grouping name \"all\" is reserved." + " Please pick a different name.");
-                    System.exit(-1);
-                }
+            // Get ID if specified; else increment from last one.
+            int txnId = i;
+            if (xmlConfig.containsKey(key + "/id")) {
+                txnId = xmlConfig.getInt(key + "/id");
+            }
 
-                // Get the weights for this grouping and make sure that there
-                // is an appropriate number of them.
-                List<String> groupingWeights = Arrays.asList(xmlConfig.getString(key + "/weights").split("\\s*,\\s*"));
-                if (groupingWeights.size() != numTxnTypes) {
-                    LOG.error(String.format("Grouping \"%s\" has %d weights," + " but there are %d transactions in this" + " benchmark.", groupingName, groupingWeights.size(), numTxnTypes));
-                    System.exit(-1);
-                }
+            long preExecutionWait = 0;
+            if (xmlConfig.containsKey(key + "/preExecutionWait")) {
+                preExecutionWait = xmlConfig.getLong(key + "/preExecutionWait");
+            }
 
-                LOG.debug("Creating grouping with name, weights: {}, {}", groupingName, groupingWeights);
+            long postExecutionWait = 0;
+            if (xmlConfig.containsKey(key + "/postExecutionWait")) {
+                postExecutionWait = xmlConfig.getLong(key + "/postExecutionWait");
             }
 
+            TransactionType tmpType = benchmark.initTransactionType(txnName, txnId + txnIdOffset, preExecutionWait, postExecutionWait);
 
-            benchList.add(bench);
+            // Keep a reference for filtering
+            activeTXTypes.add(tmpType);
 
-            // ----------------------------------------------------------------
-            // WORKLOAD CONFIGURATION
-            // ----------------------------------------------------------------
+            // Add a ref for the active TTypes in this benchmark
+            ttypes.add(tmpType);
+            lastTxnId = i;
+        }
 
-            int size = xmlConfig.configurationsAt("/works/work").size();
-            for (int i = 1; i < size + 1; i++) {
-                final HierarchicalConfiguration<ImmutableNode> work = xmlConfig.configurationAt("works/work[" + i + "]");
-                List<String> weight_strings;
+        // Wrap the list of transactions and save them
+        TransactionTypes tt = new TransactionTypes(ttypes);
+        wrkld.setTransTypes(tt);
+        LOG.debug("Using the following transaction types: {}", tt);
 
-                // use a workaround if there are multiple workloads or single
-                // attributed workload
-                if (targetList.length > 1 || work.containsKey("weights[@bench]")) {
-                    weight_strings = Arrays.asList(work.getString("weights" + pluginTest).split("\\s*,\\s*"));
-                } else {
-                    weight_strings = Arrays.asList(work.getString("weights[not(@bench)]").split("\\s*,\\s*"));
-                }
+        // Read in the groupings of transactions (if any) defined for this
+        // benchmark
+        int numGroupings = xmlConfig.configurationsAt("transactiontypes" + pluginTest + "/groupings/grouping").size();
+        LOG.debug("Num groupings: {}", numGroupings);
+        for (int i = 1; i < numGroupings + 1; i++) {
+            String key = "transactiontypes" + pluginTest + "/groupings/grouping[" + i + "]";
 
-                int rate = 1;
-                boolean rateLimited = true;
-                boolean disabled = false;
-                boolean timed;
-
-                // can be "disabled", "unlimited" or a number
-                String rate_string;
-                rate_string = work.getString("rate[not(@bench)]", "");
-                rate_string = work.getString("rate" + pluginTest, rate_string);
-                if (rate_string.equals(RATE_DISABLED)) {
-                    disabled = true;
-                } else if (rate_string.equals(RATE_UNLIMITED)) {
-                    rateLimited = false;
-                } else if (rate_string.isEmpty()) {
-                    LOG.error(String.format("Please specify the rate for phase %d and workload %s", i, plugin));
-                    System.exit(-1);
-                } else {
-                    try {
-                        rate = Integer.parseInt(rate_string);
-                        if (rate < 1) {
-                            LOG.error("Rate limit must be at least 1. Use unlimited or disabled values instead.");
-                            System.exit(-1);
-                        }
-                    } catch (NumberFormatException e) {
-                        LOG.error(String.format("Rate string must be '%s', '%s' or a number", RATE_DISABLED, RATE_UNLIMITED));
-                        System.exit(-1);
-                    }
-                }
-                Phase.Arrival arrival = Phase.Arrival.REGULAR;
-                String arrive = work.getString("@arrival", "regular");
-                if (arrive.equalsIgnoreCase("POISSON")) {
-                    arrival = Phase.Arrival.POISSON;
-                }
+            // Get the name for the grouping and make sure it's valid.
+            String groupingName = xmlConfig.getString(key + "/name").toLowerCase();
+            if (!groupingName.matches("^[a-z]\\w*$")) {
+                LOG.error(String.format("Grouping name \"%s\" is invalid." + " Must begin with a letter and contain only" + " alphanumeric characters.", groupingName));
+                System.exit(-1);
+            } else if (groupingName.equals("all")) {
+                LOG.error("Grouping name \"all\" is reserved." + " Please pick a different name.");
+                System.exit(-1);
+            }
 
-                // We now have the option to run all queries exactly once in
-                // a serial (rather than random) order.
-                boolean serial = Boolean.parseBoolean(work.getString("serial", Boolean.FALSE.toString()));
+            // Get the weights for this grouping and make sure that there
+            // is an appropriate number of them.
+            List<String> groupingWeights = Arrays.asList(xmlConfig.getString(key + "/weights").split("\\s*,\\s*"));
+            if (groupingWeights.size() != numTxnTypes) {
+                LOG.error(String.format("Grouping \"%s\" has %d weights," + " but there are %d transactions in this" + " benchmark.", groupingName, groupingWeights.size(), numTxnTypes));
+                System.exit(-1);
+            }
 
+            LOG.debug("Creating grouping with name, weights: {}, {}", groupingName, groupingWeights);
+        }
 
-                int activeTerminals;
-                activeTerminals = work.getInt("active_terminals[not(@bench)]", terminals);
-                activeTerminals = work.getInt("active_terminals" + pluginTest, activeTerminals);
-                // If using serial, we should have only one terminal
-                if (serial && activeTerminals != 1) {
-                    LOG.warn("Serial ordering is enabled, so # of active terminals is clamped to 1.");
-                    activeTerminals = 1;
-                }
-                if (activeTerminals > terminals) {
-                    LOG.error(String.format("Configuration error in work %d: " + "Number of active terminals is bigger than the total number of terminals", i));
-                    System.exit(-1);
-                }
 
-                int time = work.getInt("/time", 0);
-                int warmup = work.getInt("/warmup", 0);
-                timed = (time > 0);
-                if (!timed) {
-                    if (serial) {
-                        LOG.info("Timer disabled for serial run; will execute" + " all queries exactly once.");
-                    } else {
-                        LOG.error("Must provide positive time bound for" + " non-serial executions. Either provide" + " a valid time or enable serial mode.");
-                        System.exit(-1);
-                    }
-                } else if (serial) {
-                    LOG.info("Timer enabled for serial run; will run queries" + " serially in a loop until the timer expires.");
-                }
-                if (warmup < 0) {
-                    LOG.error("Must provide non-negative time bound for" + " warmup.");
-                    System.exit(-1);
-                }
+        // ----------------------------------------------------------------
+        // WORKLOAD CONFIGURATION
+        // ----------------------------------------------------------------
 
-                ArrayList<Double> weights = new ArrayList<>();
+        int size = xmlConfig.configurationsAt("/works/work").size();
+        if (size != 1) {
+            LOG.error("Only one work is allowed");
+            System.exit(-1);
+        }
 
-                double totalWeight = 0;
+        for (int i = 1; i < size + 1; i++) {
+            final HierarchicalConfiguration<ImmutableNode> work = xmlConfig.configurationAt("works/work[" + i + "]");
+            List<String> weight_strings;
 
-                for (String weightString : weight_strings) {
-                    double weight = Double.parseDouble(weightString);
-                    totalWeight += weight;
-                    weights.add(weight);
-                }
+            // use a workaround if there are multiple workloads or single
+            // attributed workload
+            if (targetList.length > 1 || work.containsKey("weights[@bench]")) {
+                weight_strings = Arrays.asList(work.getString("weights" + pluginTest).split("\\s*,\\s*"));
+            } else {
+                weight_strings = Arrays.asList(work.getString("weights[not(@bench)]").split("\\s*,\\s*"));
+            }
 
-                long roundedWeight = Math.round(totalWeight);
+            Phase.Arrival arrival = Phase.Arrival.REGULAR;
+            String arrive = work.getString("@arrival", "regular");
+            if (arrive.equalsIgnoreCase("POISSON")) {
+                arrival = Phase.Arrival.POISSON;
+            }
 
-                if (roundedWeight != 100) {
-                    LOG.warn("rounded weight [{}] does not equal 100.  Original weight is [{}]", roundedWeight, totalWeight);
-                }
+            int activeTerminals;
+            activeTerminals = work.getInt("active_terminals[not(@bench)]", terminals);
+            activeTerminals = work.getInt("active_terminals" + pluginTest, activeTerminals);
 
+            if (activeTerminals > terminals) {
+                LOG.error(String.format("Configuration error in work %d: " + "Number of active terminals is bigger than the total number of terminals", i));
+                System.exit(-1);
+            }
 
-                wrkld.addPhase(i, time, warmup, rate, weights, rateLimited, disabled, serial, timed, activeTerminals, arrival);
+            time = work.getInt("/time", 0);
+            int warmup = work.getInt("/warmup", 0);
+            boolean timed = (time > 0);
+            if (!timed) {
+                LOG.error("Must provide positive time bound executions.");
+                System.exit(-1);
+            }
+            if (warmup < 0) {
+                LOG.error("Must provide non-negative time bound for" + " warmup.");
+                System.exit(-1);
             }
 
-            // CHECKING INPUT PHASES
-            int j = 0;
-            for (Phase p : wrkld.getPhases()) {
-                j++;
-                if (p.getWeightCount() != numTxnTypes) {
-                    LOG.error(String.format("Configuration files is inconsistent, phase %d contains %d weights but you defined %d transaction types", j, p.getWeightCount(), numTxnTypes));
-                    if (p.isSerial()) {
-                        LOG.error("However, note that since this a serial phase, the weights are irrelevant (but still must be included---sorry).");
-                    }
-                    System.exit(-1);
-                }
+            wrkld.setWarmupTime(warmup);
+            ArrayList<Double> weights = new ArrayList<>();
+
+            double totalWeight = 0;
+
+            for (String weightString : weight_strings) {
+                double weight = Double.parseDouble(weightString);
+                totalWeight += weight;
+                weights.add(weight);
             }
 
-            // Generate the dialect map
-            wrkld.init();
+            long roundedWeight = Math.round(totalWeight);
 
+            if (roundedWeight != 100) {
+                LOG.warn("rounded weight [{}] does not equal 100.  Original weight is [{}]", roundedWeight, totalWeight);
+            }
 
+            wrkld.setPhase(i, time, warmup, weights, timed, activeTerminals, arrival);
         }
 
+        Phase phase = wrkld.getPhase();
+        if (phase.getWeightCount() != numTxnTypes) {
+            LOG.error(String.format("Configuration files is inconsistent: contains %d weights but you defined %d transaction types", phase.getWeightCount(), numTxnTypes));
+            System.exit(-1);
+        }
 
-        // Export StatementDialects
-        if (isBooleanOptionSet(argsLine, "dialects-export")) {
-            BenchmarkModule bench = benchList.get(0);
-            if (bench.getStatementDialects() != null) {
-                LOG.info("Exporting StatementDialects for {}", bench);
-                String xml = bench.getStatementDialects().export(bench.getWorkloadConfiguration().getDatabaseType(), bench.getProcedures().values());
-                LOG.debug(xml);
-                System.exit(0);
-            }
-            throw new RuntimeException("No StatementDialects is available for " + bench);
+        // Generate the dialect map
+        wrkld.init();
+
+        int monitoringPort = xmlConfig.getInt("monitoringPort", 0);
+        if (monitoringPort > 0) {
+            LOG.info("Start prometeus metric collector on port {}", monitoringPort);
+            PrometheusMeterRegistry prometheusRegistry = new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);
+            HTTPServer server = new HTTPServer(
+                    new InetSocketAddress(monitoringPort),
+                    prometheusRegistry.getPrometheusRegistry(),
+                    true);
+            LOG.info("Started {}", server);
+            Metrics.addRegistry(prometheusRegistry);
+            String instance = xmlConfig.getString("monitoringName", "benchbase");
+            Metrics.globalRegistry.config().commonTags(Tags.of("instance", instance));
         }
 
         // Create the Benchmark's Database
         if (isBooleanOptionSet(argsLine, "create")) {
             try {
-                for (BenchmarkModule benchmark : benchList) {
-                    LOG.info("Creating new {} database...", benchmark.getBenchmarkName().toUpperCase());
-                    runCreator(benchmark);
-                    LOG.info("Finished creating new {} database...", benchmark.getBenchmarkName().toUpperCase());
-                }
+                LOG.info("Creating new {} database...", benchmark.getBenchmarkName().toUpperCase());
+                runCreator(benchmark);
+                LOG.info("Finished creating new {} database...", benchmark.getBenchmarkName().toUpperCase());
             } catch (Throwable ex) {
                 LOG.error("Unexpected error when creating benchmark database tables.", ex);
                 System.exit(1);
@@ -415,21 +406,16 @@
             LOG.debug("Skipping creating benchmark database tables");
         }
 
-        // Refresh the catalog.
-        for (BenchmarkModule benchmark : benchList) {
-            benchmark.refreshCatalog();
-        }
+        benchmark.refreshCatalog();
 
         // Clear the Benchmark's Database
         if (isBooleanOptionSet(argsLine, "clear")) {
             try {
-                for (BenchmarkModule benchmark : benchList) {
-                    LOG.info("Clearing {} database...", benchmark.getBenchmarkName().toUpperCase());
-                    benchmark.refreshCatalog();
-                    benchmark.clearDatabase();
-                    benchmark.refreshCatalog();
-                    LOG.info("Finished clearing {} database...", benchmark.getBenchmarkName().toUpperCase());
-                }
+                LOG.info("Clearing {} database...", benchmark.getBenchmarkName().toUpperCase());
+                benchmark.refreshCatalog();
+                benchmark.clearDatabase();
+                benchmark.refreshCatalog();
+                LOG.info("Finished clearing {} database...", benchmark.getBenchmarkName().toUpperCase());
             } catch (Throwable ex) {
                 LOG.error("Unexpected error when clearing benchmark database tables.", ex);
                 System.exit(1);
@@ -441,11 +427,9 @@
         // Execute Loader
         if (isBooleanOptionSet(argsLine, "load")) {
             try {
-                for (BenchmarkModule benchmark : benchList) {
-                    LOG.info("Loading data into {} database...", benchmark.getBenchmarkName().toUpperCase());
-                    runLoader(benchmark);
-                    LOG.info("Finished loading data into {} database...", benchmark.getBenchmarkName().toUpperCase());
-                }
+                LOG.info("Loading data into {} database...", benchmark.getBenchmarkName().toUpperCase());
+                runLoader(benchmark);
+                LOG.info("Finished loading data into {} database...", benchmark.getBenchmarkName().toUpperCase());
             } catch (Throwable ex) {
                 LOG.error("Unexpected error when loading benchmark database records.", ex);
                 System.exit(1);
@@ -459,7 +443,8 @@
         if (isBooleanOptionSet(argsLine, "execute")) {
             // Bombs away!
             try {
-                Results r = runWorkload(benchList, intervalMonitor);
+                Results r = runWorkload(benchmark, intervalMonitor);
+                printToplineResults(r);
                 writeOutputs(r, activeTXTypes, argsLine, xmlConfig);
                 writeHistograms(r);
 
@@ -491,8 +476,9 @@
         options.addOption("s", "sample", true, "Sampling window");
         options.addOption("im", "interval-monitor", true, "Throughput Monitoring Interval in milliseconds");
         options.addOption("d", "directory", true, "Base directory for the result files, default is current directory");
-        options.addOption(null, "dialects-export", true, "Export benchmark SQL to a dialects file");
         options.addOption("jh", "json-histograms", true, "Export histograms to JSON file");
+        options.addOption("sf", "start-from-id", true, "Start from a specific scale instance id");
+        options.addOption("rt", "real-threads", false, "Use real threads");
         return options;
     }
 
@@ -568,20 +554,12 @@
 
         String baseFileName = name + "_" + TimeUtil.getCurrentTimeString();
 
-        int windowSize = Integer.parseInt(argsLine.getOptionValue("s", "5"));
-
-        String rawFileName = baseFileName + ".raw.csv";
+        String rawFileName = baseFileName + ".raw.json";
         try (PrintStream ps = new PrintStream(FileUtil.joinPath(outputDirectory, rawFileName))) {
             LOG.info("Output Raw data into file: {}", rawFileName);
             rw.writeRaw(activeTXTypes, ps);
         }
 
-        String sampleFileName = baseFileName + ".samples.csv";
-        try (PrintStream ps = new PrintStream(FileUtil.joinPath(outputDirectory, sampleFileName))) {
-            LOG.info("Output samples into file: {}", sampleFileName);
-            rw.writeSamples(ps);
-        }
-
         String summaryFileName = baseFileName + ".summary.json";
         try (PrintStream ps = new PrintStream(FileUtil.joinPath(outputDirectory, summaryFileName))) {
             LOG.info("Output summary data into file: {}", summaryFileName);
@@ -607,20 +585,6 @@
             LOG.info("Output benchmark config into file: {}", configFileName);
             rw.writeConfig(ps);
         }
-
-        String resultsFileName = baseFileName + ".results.csv";
-        try (PrintStream ps = new PrintStream(FileUtil.joinPath(outputDirectory, resultsFileName))) {
-            LOG.info("Output results into file: {} with window size {}", resultsFileName, windowSize);
-            rw.writeResults(windowSize, ps);
-        }
-
-        for (TransactionType t : activeTXTypes) {
-            String fileName = baseFileName + ".results." + t.getName() + ".csv";
-            try (PrintStream ps = new PrintStream(FileUtil.joinPath(outputDirectory, fileName))) {
-                rw.writeResults(windowSize, ps, t);
-            }
-        }
-
     }
 
     private static void runCreator(BenchmarkModule bench) throws SQLException, IOException {
@@ -633,24 +597,39 @@
         bench.loadDatabase();
     }
 
-    private static Results runWorkload(List<BenchmarkModule> benchList, int intervalMonitor) throws IOException {
+    private static Results runWorkload(BenchmarkModule benchmark, int intervalMonitor) throws IOException {
         List<Worker<?>> workers = new ArrayList<>();
         List<WorkloadConfiguration> workConfs = new ArrayList<>();
-        for (BenchmarkModule bench : benchList) {
-            LOG.info("Creating {} virtual terminals...", bench.getWorkloadConfiguration().getTerminals());
-            workers.addAll(bench.makeWorkers());
 
-            int num_phases = bench.getWorkloadConfiguration().getNumberOfPhases();
-            LOG.info(String.format("Launching the %s Benchmark with %s Phase%s...", bench.getBenchmarkName().toUpperCase(), num_phases, (num_phases > 1 ? "s" : "")));
-            workConfs.add(bench.getWorkloadConfiguration());
+        LOG.info("Creating {} virtual terminals...", benchmark.getWorkloadConfiguration().getTerminals());
+        workers.addAll(benchmark.makeWorkers());
 
-        }
-        Results r = ThreadBench.runRateLimitedBenchmark(workers, workConfs, intervalMonitor);
-        LOG.info(SINGLE_LINE);
-        LOG.info("Rate limited reqs/s: {}", r);
+        LOG.info(String.format("Launching the %s Benchmark", benchmark.getBenchmarkName().toUpperCase()));
+        WorkloadConfiguration workConf = benchmark.getWorkloadConfiguration();
+
+        Results r = ThreadBench.runBenchmark(workers, workConf, intervalMonitor, useRealThreads);
         return r;
     }
 
+    private static void printToplineResults(Results r) {
+        long numNewOrderTransactions = r.getStats().getSuccessCount(newOrderTxnId);
+
+        double tpmc = 1.0 * numNewOrderTransactions * 60 / time;
+        double efficiency = 1.0 * tpmc * 100 / numWarehouses / 12.86;
+        DecimalFormat df = new DecimalFormat();
+        df.setMaximumFractionDigits(2);
+        String resultOut = "\n"
+                + "================RESULTS================\n"
+                + String.format("%18s | %18d\n", "Time, s", time)
+                + String.format("%18s | %18d\n", "NewOrders", numNewOrderTransactions)
+                + String.format("%18s | %18.2f\n", "TPM-C", tpmc)
+                + String.format("%18s | %17.2f%%\n", "Efficiency", efficiency)
+                + String.format("reqs/s: %s\n", r);
+
+        LOG.info(SINGLE_LINE);
+        LOG.info(resultOut);
+    }
+
     private static void printUsage(Options options) {
         HelpFormatter hlpfrmt = new HelpFormatter();
         hlpfrmt.printHelp("benchbase", options);
diff -ur v0/src/main/java/com/oltpbenchmark/distributions/ZipfianGenerator.java v1/src/main/java/com/oltpbenchmark/distributions/ZipfianGenerator.java
--- v0/src/main/java/com/oltpbenchmark/distributions/ZipfianGenerator.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/distributions/ZipfianGenerator.java	2025-02-23 19:34:55.706323245 +0300
@@ -22,6 +22,8 @@
 
 import java.util.Random;
 
+import java.util.concurrent.locks.ReentrantLock;
+
 /**
  * A generator of a zipfian distribution. It produces a sequence of items, such that some items are more popular than others, according
  * to a zipfian distribution. When you construct an instance of this class, you specify the number of items in the set to draw from, either
@@ -47,6 +49,8 @@
 
     final Random rng;
 
+    private final ReentrantLock lock = new ReentrantLock();
+
     /**
      * Number of items.
      */
@@ -237,7 +241,8 @@
         if (itemcount != countforzeta) {
 
             //have to recompute zetan and eta, since they depend on itemcount
-            synchronized (this) {
+            try {
+                lock.lock();
                 if (itemcount > countforzeta) {
                     //System.err.println("WARNING: Incrementally recomputing Zipfian distribtion. (itemcount="+itemcount+" countforzeta="+countforzeta+")");
 
@@ -257,6 +262,8 @@
                     zetan = zeta(itemcount, theta);
                     eta = (1 - Math.pow(2.0 / items, 1 - theta)) / (1 - zeta2theta / zetan);
                 }
+            } finally {
+                lock.unlock();
             }
         }
 
Только в v0/src/main/java/com/oltpbenchmark: DistributionStatistics.java
Только в v0/src/main/java/com/oltpbenchmark: LatencyRecord.java
diff -ur v0/src/main/java/com/oltpbenchmark/Phase.java v1/src/main/java/com/oltpbenchmark/Phase.java
--- v0/src/main/java/com/oltpbenchmark/Phase.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/Phase.java	2025-02-23 19:34:55.678322992 +0300
@@ -21,79 +21,48 @@
 
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Random;
+
+import java.util.concurrent.ThreadLocalRandom;
 
 public class Phase {
     public enum Arrival {
         REGULAR, POISSON,
     }
 
-    private final Random gen = new Random();
     private final String benchmarkName;
     private final int id;
     private final int time;
     private final int warmupTime;
-    private final int rate;
     private final Arrival arrival;
 
-
-    private final boolean rateLimited;
-    private final boolean disabled;
-    private final boolean serial;
     private final boolean timed;
     private final List<Double> weights;
+    private final int totalWeight;
     private final int weightCount;
     private final int activeTerminals;
-    private int nextSerial;
-
 
-    Phase(String benchmarkName, int id, int t, int wt, int r, List<Double> weights, boolean rateLimited, boolean disabled, boolean serial, boolean timed, int activeTerminals, Arrival a) {
+    Phase(String benchmarkName, int id, int t, int wt, List<Double> weights, boolean timed, int activeTerminals, Arrival a) {
         this.benchmarkName = benchmarkName;
         this.id = id;
         this.time = t;
         this.warmupTime = wt;
-        this.rate = r;
         this.weights = weights;
         this.weightCount = this.weights.size();
-        this.rateLimited = rateLimited;
-        this.disabled = disabled;
-        this.serial = serial;
         this.timed = timed;
-        this.nextSerial = 1;
         this.activeTerminals = activeTerminals;
         this.arrival = a;
-    }
-
-
-
-    public boolean isRateLimited() {
-        return rateLimited;
-    }
-
-    public boolean isDisabled() {
-        return disabled;
-    }
 
-    public boolean isSerial() {
-        return serial;
+        double total = 0;
+        for (Double d : weights) {
+            total += d;
+        }
+        this.totalWeight = (int)total;
     }
 
     public boolean isTimed() {
         return timed;
     }
 
-    public boolean isLatencyRun() {
-        return !timed && serial;
-    }
-
-    public boolean isThroughputRun() {
-        return !isLatencyRun();
-    }
-
-    public void resetSerial() {
-        this.nextSerial = 1;
-    }
-
     public int getActiveTerminals() {
         return activeTerminals;
     }
@@ -114,10 +83,6 @@
         return warmupTime;
     }
 
-    public int getRate() {
-        return rate;
-    }
-
     public Arrival getArrival() {
         return arrival;
     }
@@ -127,68 +92,18 @@
     }
 
     /**
-     * Computes the sum of weights. Usually needs to add up to 100%
-     *
-     * @return The total weight
-     */
-    public double totalWeight() {
-        double total = 0.0;
-        for (Double d : weights) {
-            total += d;
-        }
-        return total;
-    }
-
-    /**
      * This simply computes the next transaction by randomly selecting one based
      * on the weights of this phase.
      *
      * @return
      */
     public int chooseTransaction() {
-        return chooseTransaction(false);
-    }
-
-    public int chooseTransaction(boolean isColdQuery) {
-        if (isDisabled()) {
-            return -1;
-        }
-
-        if (isSerial()) {
-            int ret;
-            synchronized (this) {
-                ret = this.nextSerial;
-
-                // Serial runs should not execute queries with non-positive
-                // weights.
-                while (ret <= this.weightCount && weights.get(ret - 1) <= 0.0) {
-                    ret = ++this.nextSerial;
-                }
-
-                // If it's a cold execution, then we don't want to advance yet,
-                // since the hot run needs to execute the same query.
-                if (!isColdQuery) {
-
-                    // throughput) run, so we loop through the list multiple
-                    // times. Note that we do the modulus before the increment
-                    // so that we end up in the range [1,num_weights]
-                    if (isTimed()) {
-
-                        this.nextSerial %= this.weightCount;
-                    }
-
-                    ++this.nextSerial;
-                }
-            }
-            return ret;
-        } else {
-            int randomPercentage = gen.nextInt((int) totalWeight()) + 1;
-            double weight = 0.0;
-            for (int i = 0; i < this.weightCount; i++) {
-                weight += weights.get(i);
-                if (randomPercentage <= weight) {
-                    return i + 1;
-                }
+        int randomPercentage = ThreadLocalRandom.current().nextInt(totalWeight) + 1;
+        double weight = 0.0;
+        for (int i = 0; i < this.weightCount; i++) {
+            weight += weights.get(i);
+            if (randomPercentage <= weight) {
+                return i + 1;
             }
         }
 
@@ -201,22 +116,11 @@
     public String currentPhaseString() {
         List<String> inner = new ArrayList<>();
         inner.add("[Workload=" + benchmarkName.toUpperCase() + "]");
-        if (isDisabled()) {
-            inner.add("[Disabled=true]");
-        } else {
-            if (isLatencyRun()) {
-                inner.add("[Serial=true]");
-                inner.add("[Time=n/a]");
-            } else {
-                inner.add("[Serial=" + isSerial() + "]");
-                inner.add("[Time=" + time + "]");
-            }
-            inner.add("[WarmupTime=" + warmupTime + "]");
-            inner.add("[Rate=" + (isRateLimited() ? rate : "unlimited") + "]");
-            inner.add("[Arrival=" + arrival + "]");
-            inner.add("[Ratios=" + getWeights() + "]");
-            inner.add("[ActiveWorkers=" + getActiveTerminals() + "]");
-        }
+        inner.add("[Time=" + time + "]");
+        inner.add("[WarmupTime=" + warmupTime + "]");
+        inner.add("[Arrival=" + arrival + "]");
+        inner.add("[Ratios=" + getWeights() + "]");
+        inner.add("[ActiveWorkers=" + getActiveTerminals() + "]");
 
         return StringUtil.bold("PHASE START") + " :: " + StringUtil.join(" ", inner);
     }
diff -ur v0/src/main/java/com/oltpbenchmark/Results.java v1/src/main/java/com/oltpbenchmark/Results.java
--- v0/src/main/java/com/oltpbenchmark/Results.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/Results.java	2025-02-23 19:34:55.678322992 +0300
@@ -18,7 +18,7 @@
 
 package com.oltpbenchmark;
 
-import com.oltpbenchmark.LatencyRecord.Sample;
+import com.oltpbenchmark.ResultStats;
 import com.oltpbenchmark.api.TransactionType;
 import com.oltpbenchmark.util.Histogram;
 
@@ -29,9 +29,8 @@
 public final class Results {
 
     private final long nanoseconds;
-    private final int measuredRequests;
-    private final DistributionStatistics distributionStatistics;
-    private final List<LatencyRecord.Sample> latencySamples;
+    private final long measuredRequests;
+    private final ResultStats resultStats;
     private final Histogram<TransactionType> unknown = new Histogram<>(false);
     private final Histogram<TransactionType> success = new Histogram<>(true);
     private final Histogram<TransactionType> abort = new Histogram<>(false);
@@ -40,22 +39,10 @@
     private final Histogram<TransactionType> retryDifferent = new Histogram<>(false);
     private final Map<TransactionType, Histogram<String>> abortMessages = new HashMap<>();
 
-    public Results(long nanoseconds, int measuredRequests, DistributionStatistics distributionStatistics, final List<LatencyRecord.Sample> latencySamples) {
+    public Results(long nanoseconds, long measuredRequests, ResultStats resultStats) {
         this.nanoseconds = nanoseconds;
         this.measuredRequests = measuredRequests;
-        this.distributionStatistics = distributionStatistics;
-
-        if (distributionStatistics == null) {
-            this.latencySamples = null;
-        } else {
-            // defensive copy
-            this.latencySamples = List.copyOf(latencySamples);
-
-        }
-    }
-
-    public DistributionStatistics getDistributionStatistics() {
-        return distributionStatistics;
+        this.resultStats = resultStats;
     }
 
     public Histogram<TransactionType> getSuccess() {
@@ -94,15 +81,15 @@
         return (double) success.getSampleCount() / (double) nanoseconds * 1e9;
     }
 
-    public List<Sample> getLatencySamples() {
-        return latencySamples;
+    public ResultStats getStats() {
+        return resultStats;
     }
 
     public long getNanoseconds() {
         return nanoseconds;
     }
 
-    public int getMeasuredRequests() {
+    public long getMeasuredRequests() {
         return measuredRequests;
     }
 
Только в v1/src/main/java/com/oltpbenchmark: ResultStats.java
diff -ur v0/src/main/java/com/oltpbenchmark/ThreadBench.java v1/src/main/java/com/oltpbenchmark/ThreadBench.java
--- v0/src/main/java/com/oltpbenchmark/ThreadBench.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/ThreadBench.java	2025-02-23 19:34:55.678322992 +0300
@@ -17,11 +17,9 @@
 
 package com.oltpbenchmark;
 
-import com.oltpbenchmark.LatencyRecord.Sample;
 import com.oltpbenchmark.api.BenchmarkModule;
 import com.oltpbenchmark.api.TransactionType;
 import com.oltpbenchmark.api.Worker;
-import com.oltpbenchmark.types.State;
 import com.oltpbenchmark.util.StringUtil;
 import org.apache.commons.collections4.map.ListOrderedMap;
 import org.slf4j.Logger;
@@ -32,48 +30,51 @@
 public class ThreadBench implements Thread.UncaughtExceptionHandler {
     private static final Logger LOG = LoggerFactory.getLogger(ThreadBench.class);
 
-    private final BenchmarkState testState;
+    private final BenchmarkState benchmarkState;
     private final List<? extends Worker<? extends BenchmarkModule>> workers;
     private final ArrayList<Thread> workerThreads;
-    private final List<WorkloadConfiguration> workConfs;
-    private final ArrayList<LatencyRecord.Sample> samples = new ArrayList<>();
+    private final WorkloadConfiguration workConf;
+    private final ResultStats resultStats;
     private final int intervalMonitor;
+    private final Boolean useRealThreads;
 
     private ThreadBench(List<? extends Worker<? extends BenchmarkModule>> workers,
-            List<WorkloadConfiguration> workConfs, int intervalMonitoring) {
+            WorkloadConfiguration workConf, int intervalMonitoring, Boolean useRealThreads) {
         this.workers = workers;
-        this.workConfs = workConfs;
+        this.workConf = workConf;
         this.workerThreads = new ArrayList<>(workers.size());
         this.intervalMonitor = intervalMonitoring;
-        this.testState = new BenchmarkState(workers.size() + 1);
+        this.benchmarkState = new BenchmarkState(workers.size() + 1, workConf);
+        this.resultStats = new ResultStats();
+        this.useRealThreads = useRealThreads;
+
+        for (Worker<?> worker : workers) {
+            worker.setBenchmarkState(this.benchmarkState);
+        }
     }
 
-    public static Results runRateLimitedBenchmark(List<Worker<? extends BenchmarkModule>> workers,
-            List<WorkloadConfiguration> workConfs, int intervalMonitoring) {
-        ThreadBench bench = new ThreadBench(workers, workConfs, intervalMonitoring);
-        return bench.runRateLimitedMultiPhase();
+    public static Results runBenchmark(List<Worker<? extends BenchmarkModule>> workers,
+            WorkloadConfiguration workConf, int intervalMonitoring, Boolean useRealThreads) {
+        ThreadBench bench = new ThreadBench(workers, workConf, intervalMonitoring, useRealThreads);
+        return bench.runBenchmark();
     }
 
     private void createWorkerThreads() {
-
         for (Worker<?> worker : workers) {
-            worker.initializeState();
-            Thread thread = new Thread(worker);
+            Thread thread;
+            if (useRealThreads) {
+                thread = new Thread(worker);
+            } else {
+                thread = Thread.ofVirtual().unstarted(worker);
+            }
             thread.setUncaughtExceptionHandler(this);
             thread.start();
             this.workerThreads.add(thread);
         }
     }
 
-    private void interruptWorkers() {
-        for (Worker<?> worker : workers) {
-            worker.cancelStatement();
-        }
-    }
-
-    private int finalizeWorkers(ArrayList<Thread> workerThreads) throws InterruptedException {
-
-        int requests = 0;
+    private long finalizeWorkers(ArrayList<Thread> workerThreads) throws InterruptedException {
+        long requests = 0;
 
         new WatchDogThread().start();
 
@@ -101,55 +102,15 @@
         return requests;
     }
 
-    private Results runRateLimitedMultiPhase() {
-        List<WorkloadState> workStates = new ArrayList<>();
-
-        for (WorkloadConfiguration workState : this.workConfs) {
-            workState.initializeState(testState);
-            workStates.add(workState.getWorkloadState());
-        }
-
+    private Results runBenchmark() {
         this.createWorkerThreads();
 
-        // long measureStart = start;
-
-        long start = System.nanoTime();
-        long warmupStart = System.nanoTime();
-        long warmup = warmupStart;
-        long measureEnd = -1;
-        // used to determine the longest sleep interval
-        int lowestRate = Integer.MAX_VALUE;
-
-        Phase phase = null;
-
-        for (WorkloadState workState : workStates) {
-            workState.switchToNextPhase();
-            phase = workState.getCurrentPhase();
-            LOG.info(phase.currentPhaseString());
-            if (phase.getRate() < lowestRate) {
-                lowestRate = phase.getRate();
-            }
-        }
-
-        // Change testState to cold query if execution is serial, since we don't
-        // have a warm-up phase for serial execution but execute a cold and a
-        // measured query in sequence.
-        if (phase != null && phase.isLatencyRun()) {
-            synchronized (testState) {
-                testState.startColdQuery();
-            }
-        }
-
-        long intervalNs = getInterval(lowestRate, phase.getArrival());
-
-        long nextInterval = start + intervalNs;
-        int nextToAdd = 1;
-        int rateFactor;
-
-        boolean resetQueues = true;
+        Phase phase = this.workConf.getPhase();
+        LOG.info(phase.currentPhaseString());
 
-        long delta = phase.getTime() * 1000000000L;
-        boolean lastEntry = false;
+        final long start = System.nanoTime();
+        final long warmupStart = start;
+        final long warmupEnd = warmupStart + phase.getWarmupTime() * 1000000000L;
 
         // Initialize the Monitor
         if (this.intervalMonitor > 0) {
@@ -157,170 +118,49 @@
         }
 
         // Allow workers to start work.
-        testState.blockForStart();
+        benchmarkState.blockForStart();
 
-        // Main Loop
-        while (true) {
-            // posting new work... and resetting the queue in case we have new
-            // portion of the workload...
-
-            for (WorkloadState workState : workStates) {
-                if (workState.getCurrentPhase() != null) {
-                    rateFactor = workState.getCurrentPhase().getRate() / lowestRate;
-                } else {
-                    rateFactor = 1;
-                }
-                workState.addToQueue(nextToAdd * rateFactor, resetQueues);
-            }
-            resetQueues = false;
-
-            // Wait until the interval expires, which may be "don't wait"
-            long now = System.nanoTime();
-            if (phase != null) {
-                warmup = warmupStart + phase.getWarmupTime() * 1000000000L;
-            }
-            long diff = nextInterval - now;
-            while (diff > 0) { // this can wake early: sleep multiple times to avoid that
-                long ms = diff / 1000000;
-                diff = diff % 1000000;
+        final long warmupS = (warmupEnd - warmupStart) / 1000000000;
+        if (warmupS > 0) {
+            LOG.info("{} :: Warming up for {}s", StringUtil.bold("WARMUP"), warmupS);
+            while (System.nanoTime() < warmupEnd) {
                 try {
-                    Thread.sleep(ms, (int) diff);
+                    Thread.sleep(1000);
                 } catch (InterruptedException e) {
                     throw new RuntimeException(e);
                 }
-                now = System.nanoTime();
-                diff = nextInterval - now;
-            }
-
-            boolean phaseComplete = false;
-            if (phase != null) {
-                if (phase.isLatencyRun())
-                // Latency runs (serial run through each query) have their own
-                // state to mark completion
-                {
-                    phaseComplete = testState.getState() == State.LATENCY_COMPLETE;
-                } else {
-                    phaseComplete = testState.getState() == State.MEASURE
-                            && (start + delta <= now);
-                }
             }
+        }
 
-            // Go to next phase if this one is complete or enter if error was thrown
-            boolean errorThrown = testState.getState() == State.ERROR;
-            if ((phaseComplete || errorThrown) && !lastEntry) {
-                // enters here after each phase of the test
-                // reset the queues so that the new phase is not affected by the
-                // queue of the previous one
-                resetQueues = true;
-
-                // Fetch a new Phase
-                synchronized (testState) {
-                    if (phase.isLatencyRun()) {
-                        testState.ackLatencyComplete();
-                    }
-                    for (WorkloadState workState : workStates) {
-                        synchronized (workState) {
-                            workState.switchToNextPhase();
-                            lowestRate = Integer.MAX_VALUE;
-                            phase = workState.getCurrentPhase();
-                            interruptWorkers();
-                            if (phase == null && !lastEntry) {
-                                // Last phase
-                                lastEntry = true;
-                                testState.startCoolDown();
-                                measureEnd = now;
-                                LOG.info("{} :: Waiting for all terminals to finish ..", StringUtil.bold("TERMINATE"));
-                            } else if (phase != null) {
-                                // Reset serial execution parameters.
-                                if (phase.isLatencyRun()) {
-                                    phase.resetSerial();
-                                    testState.startColdQuery();
-                                }
-                                LOG.info(phase.currentPhaseString());
-                                if (phase.getRate() < lowestRate) {
-                                    lowestRate = phase.getRate();
-                                }
-                            }
-                        }
-                    }
-                    if (phase != null) {
-                        // update frequency in which we check according to
-                        // wakeup
-                        // speed
-                        // intervalNs = (long) (1000000000. / (double)
-                        // lowestRate + 0.5);
-                        delta += phase.getTime() * 1000000000L;
-                    }
-                }
-            }
+        final long stopAt = System.nanoTime() + phase.getTime() * 1000000000L;
+        benchmarkState.startMeasure();
 
-            // Compute the next interval
-            // and how many messages to deliver
-            if (phase != null) {
-                intervalNs = 0;
-                nextToAdd = 0;
-                do {
-                    intervalNs += getInterval(lowestRate, phase.getArrival());
-                    nextToAdd++;
-                } while ((-diff) > intervalNs && !lastEntry);
-                nextInterval += intervalNs;
-            }
+        LOG.info("{} :: Warmup complete, starting measurements.", StringUtil.bold("MEASURE"));
 
-            // Update the test state appropriately
-            State state = testState.getState();
-            if (state == State.WARMUP && now >= warmup) {
-                synchronized (testState) {
-                    if (phase != null && phase.isLatencyRun()) {
-                        testState.startColdQuery();
-                    } else {
-                        testState.startMeasure();
-                    }
-                    interruptWorkers();
-                }
-                start = now;
-                LOG.info("{} :: Warmup complete, starting measurements.", StringUtil.bold("MEASURE"));
-                // measureEnd = measureStart + measureSeconds * 1000000000L;
-
-                // For serial executions, we want to do every query exactly
-                // once, so we need to restart in case some of the queries
-                // began during the warmup phase.
-                // If we're not doing serial executions, this function has no
-                // effect and is thus safe to call regardless.
-                phase.resetSerial();
-            } else if (state == State.EXIT) {
-                // All threads have noticed the done, meaning all measured
-                // requests have definitely finished.
-                // Time to quit.
-                break;
+        // Main Loop
+        while (benchmarkState.isWorkingOrMeasuring() && System.nanoTime() < stopAt) {
+            try {
+                Thread.sleep(1000);
+            } catch (InterruptedException e) {
+                throw new RuntimeException(e);
             }
         }
 
+        final long measureEnd = System.nanoTime();
+        benchmarkState.stopWorkers();
+
         try {
-            int requests = finalizeWorkers(this.workerThreads);
+            long requests = finalizeWorkers(this.workerThreads);
 
-            // Combine all the latencies together in the most disgusting way
-            // possible: sorting!
             for (Worker<?> w : workers) {
-                for (LatencyRecord.Sample sample : w.getLatencyRecords()) {
-                    samples.add(sample);
-                }
+                resultStats.add(w.getStats());
             }
-            Collections.sort(samples);
 
-            // Compute stats on all the latencies
-            int[] latencies = new int[samples.size()];
-            for (int i = 0; i < samples.size(); ++i) {
-                latencies[i] = samples.get(i).getLatencyMicrosecond();
-            }
-            DistributionStatistics stats = DistributionStatistics.computeStatistics(latencies);
-
-            Results results = new Results(measureEnd - start, requests, stats, samples);
+            Results results = new Results(measureEnd - start, requests, resultStats);
 
             // Compute transaction histogram
             Set<TransactionType> txnTypes = new HashSet<>();
-            for (WorkloadConfiguration workConf : workConfs) {
-                txnTypes.addAll(workConf.getTransTypes());
-            }
+            txnTypes.addAll(workConf.getTransTypes());
             txnTypes.remove(TransactionType.INVALID);
 
             results.getUnknown().putAll(txnTypes, 0);
@@ -345,146 +185,16 @@
         }
     }
 
-    private long getInterval(int lowestRate, Phase.Arrival arrival) {
-        // TODO Auto-generated method stub
-        if (arrival == Phase.Arrival.POISSON) {
-            return (long) ((-Math.log(1 - Math.random()) / lowestRate) * 1000000000.);
-        } else {
-            return (long) (1000000000. / (double) lowestRate + 0.5);
-        }
-    }
-
     @Override
     public void uncaughtException(Thread t, Throwable e) {
         // Here we handle the case in which one of our worker threads died
-        LOG.error(e.getMessage(), e);
+        LOG.error("Uncaught exception: {}", e.getMessage(), e);
         // We do not continue with the experiment. Instead, bypass rest of
         // phases that were left in the test and signal error state.
         // The rest of the workflow to finish the experiment remains the same,
         // and partial metrics will be reported (i.e., until failure happened).
-        synchronized (testState) {
-            for (WorkloadConfiguration workConf : this.workConfs) {
-                synchronized (workConf.getWorkloadState()) {
-                    WorkloadState workState = workConf.getWorkloadState();
-                    Phase phase = workState.getCurrentPhase();
-                    while (phase != null) {
-                        workState.switchToNextPhase();
-                        phase = workState.getCurrentPhase();
-                    }
-                }
-            }
-            testState.signalError();
-        }
-    }
-
-    public static final class TimeBucketIterable implements Iterable<DistributionStatistics> {
-        private final Iterable<Sample> samples;
-        private final int windowSizeSeconds;
-        private final TransactionType transactionType;
-
-        /**
-         * @param samples
-         * @param windowSizeSeconds
-         * @param transactionType   Allows to filter transactions by type
-         */
-        public TimeBucketIterable(Iterable<Sample> samples, int windowSizeSeconds, TransactionType transactionType) {
-            this.samples = samples;
-            this.windowSizeSeconds = windowSizeSeconds;
-            this.transactionType = transactionType;
-        }
-
-        @Override
-        public Iterator<DistributionStatistics> iterator() {
-            return new TimeBucketIterator(samples.iterator(), windowSizeSeconds, transactionType);
-        }
-    }
-
-    private static final class TimeBucketIterator implements Iterator<DistributionStatistics> {
-        private final Iterator<Sample> samples;
-        private final int windowSizeSeconds;
-        private final TransactionType txType;
-
-        private Sample sample;
-        private long nextStartNanosecond;
-
-        private DistributionStatistics next;
-
-        /**
-         * @param samples
-         * @param windowSizeSeconds
-         * @param txType            Allows to filter transactions by type
-         */
-        public TimeBucketIterator(Iterator<LatencyRecord.Sample> samples, int windowSizeSeconds,
-                TransactionType txType) {
-            this.samples = samples;
-            this.windowSizeSeconds = windowSizeSeconds;
-            this.txType = txType;
-
-            if (samples.hasNext()) {
-                sample = samples.next();
-                // TODO: To be totally correct, we would want this to be the
-                // timestamp of the start
-                // of the measurement interval. In most cases this won't matter.
-                nextStartNanosecond = sample.getStartNanosecond();
-                calculateNext();
-            }
-        }
-
-        private void calculateNext() {
 
-            // Collect all samples in the time window
-            ArrayList<Integer> latencies = new ArrayList<>();
-            long endNanoseconds = nextStartNanosecond + (windowSizeSeconds * 1000000000L);
-            while (sample != null && sample.getStartNanosecond() < endNanoseconds) {
-
-                // Check if a TX Type filter is set, in the default case,
-                // INVALID TXType means all should be reported, if a filter is
-                // set, only this specific transaction
-                if (txType.equals(TransactionType.INVALID) || txType.getId() == sample.getTransactionType()) {
-                    latencies.add(sample.getLatencyMicrosecond());
-                }
-
-                if (samples.hasNext()) {
-                    sample = samples.next();
-                } else {
-                    sample = null;
-                }
-            }
-
-            // Set up the next time window
-
-            nextStartNanosecond = endNanoseconds;
-
-            int[] l = new int[latencies.size()];
-            for (int i = 0; i < l.length; ++i) {
-                l[i] = latencies.get(i);
-            }
-
-            next = DistributionStatistics.computeStatistics(l);
-        }
-
-        @Override
-        public boolean hasNext() {
-            return next != null;
-        }
-
-        @Override
-        public DistributionStatistics next() {
-            if (next == null) {
-                throw new NoSuchElementException();
-            }
-            DistributionStatistics out = next;
-            next = null;
-            if (sample != null) {
-                calculateNext();
-            }
-            return out;
-        }
-
-        @Override
-        public void remove() {
-            throw new UnsupportedOperationException("unsupported");
-        }
+        benchmarkState.signalError();
     }
 
     private class WatchDogThread extends Thread {
@@ -538,10 +248,8 @@
 
                 // Compute the last throughput
                 long measuredRequests = 0;
-                synchronized (testState) {
-                    for (Worker<?> w : workers) {
-                        measuredRequests += w.getAndResetIntervalRequests();
-                    }
+                for (Worker<?> w : workers) {
+                    measuredRequests += w.getAndResetIntervalRequests();
                 }
                 double seconds = this.intervalMonitor / 1000d;
                 double tps = (double) measuredRequests / seconds;
@@ -549,5 +257,4 @@
             }
         }
     }
-
 }
Только в v0/src/main/java/com/oltpbenchmark/types: State.java
diff -ur v0/src/main/java/com/oltpbenchmark/util/Histogram.java v1/src/main/java/com/oltpbenchmark/util/Histogram.java
--- v0/src/main/java/com/oltpbenchmark/util/Histogram.java	2025-02-23 19:35:48.938799526 +0300
+++ v1/src/main/java/com/oltpbenchmark/util/Histogram.java	2025-02-23 19:34:55.710323281 +0300
@@ -29,6 +29,8 @@
 import java.util.*;
 import java.util.Map.Entry;
 
+import java.util.concurrent.locks.ReentrantLock;
+
 /**
  * A very nice and simple generic Histogram
  *
@@ -38,6 +40,8 @@
 public class Histogram<X extends Comparable<X>> implements JSONSerializable {
     private static final Logger LOG = LoggerFactory.getLogger(Histogram.class);
 
+    private final ReentrantLock lock = new ReentrantLock();
+
     private static final String MARKER = "*";
     private static final Integer MAX_CHARS = 80;
     private static final Integer MAX_VALUE_LENGTH = 80;
@@ -110,7 +114,8 @@
     public void setKeepZeroEntries(boolean flag) {
         // When this option is disabled, we need to remove all of the zeroed entries
         if (!flag && this.keep_zero_entries) {
-            synchronized (this) {
+            try {
+                lock.lock();
                 Iterator<X> it = this.histogram.keySet().iterator();
                 int ctr = 0;
                 while (it.hasNext()) {
@@ -124,6 +129,8 @@
                 if (ctr > 0) {
                     LOG.debug("Removed {} zero entries from histogram", ctr);
                 }
+            } finally {
+                lock.unlock();
             }
         }
         this.keep_zero_entries = flag;
@@ -173,7 +180,7 @@
         }
 
         // New Min/Max Counts
-        // The reason we have to loop through and check every time is that our 
+        // The reason we have to loop through and check every time is that our
         // value may be the current min/max count and thus it may or may not still
         // be after the count is changed
         this.max_count = 0;
diff -ur v0/src/main/java/com/oltpbenchmark/util/ResultWriter.java v1/src/main/java/com/oltpbenchmark/util/ResultWriter.java
--- v0/src/main/java/com/oltpbenchmark/util/ResultWriter.java	2025-02-23 19:35:48.938799526 +0300
+++ v1/src/main/java/com/oltpbenchmark/util/ResultWriter.java	2025-02-23 19:34:55.710323281 +0300
@@ -17,8 +17,7 @@
 
 package com.oltpbenchmark.util;
 
-import com.oltpbenchmark.DistributionStatistics;
-import com.oltpbenchmark.LatencyRecord;
+import com.oltpbenchmark.ResultStats;
 import com.oltpbenchmark.Results;
 import com.oltpbenchmark.ThreadBench;
 import com.oltpbenchmark.api.TransactionType;
@@ -106,7 +105,6 @@
         summaryMap.put("DBMS Type", dbType);
         summaryMap.put("DBMS Version", collector.collectVersion());
         summaryMap.put("Benchmark Type", benchType);
-        summaryMap.put("Latency Distribution", results.getDistributionStatistics().toMap());
         summaryMap.put("Throughput (requests/second)", results.requestsPerSecondThroughput());
         summaryMap.put("Goodput (requests/second)", results.requestsPerSecondGoodput());
         for (String field : BENCHMARK_KEY_FIELD) {
@@ -115,117 +113,7 @@
         os.println(JSONUtil.format(JSONUtil.toJSONString(summaryMap)));
     }
 
-    public void writeResults(int windowSizeSeconds, PrintStream out) {
-        writeResults(windowSizeSeconds, out, TransactionType.INVALID);
-    }
-
-    public void writeResults(int windowSizeSeconds, PrintStream out, TransactionType txType) {
-        String[] header = {
-                "Time (seconds)",
-                "Throughput (requests/second)",
-                "Average Latency (millisecond)",
-                "Minimum Latency (millisecond)",
-                "25th Percentile Latency (millisecond)",
-                "Median Latency (millisecond)",
-                "75th Percentile Latency (millisecond)",
-                "90th Percentile Latency (millisecond)",
-                "95th Percentile Latency (millisecond)",
-                "99th Percentile Latency (millisecond)",
-                "Maximum Latency (millisecond)",
-                "tp (req/s) scaled"
-        };
-        out.println(StringUtil.join(",", header));
-        int i = 0;
-        for (DistributionStatistics s : new ThreadBench.TimeBucketIterable(results.getLatencySamples(), windowSizeSeconds, txType)) {
-            out.printf("%d,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f\n",
-                    i * windowSizeSeconds,
-                    (double) s.getCount() / windowSizeSeconds,
-                    s.getAverage() / MILLISECONDS_FACTOR,
-                    s.getMinimum() / MILLISECONDS_FACTOR,
-                    s.get25thPercentile() / MILLISECONDS_FACTOR,
-                    s.getMedian() / MILLISECONDS_FACTOR,
-                    s.get75thPercentile() / MILLISECONDS_FACTOR,
-                    s.get90thPercentile() / MILLISECONDS_FACTOR,
-                    s.get95thPercentile() / MILLISECONDS_FACTOR,
-                    s.get99thPercentile() / MILLISECONDS_FACTOR,
-                    s.getMaximum() / MILLISECONDS_FACTOR,
-                    MILLISECONDS_FACTOR / s.getAverage());
-            i += 1;
-        }
-    }
-
-    public void writeSamples(PrintStream out) {
-        writeSamples(1, out, TransactionType.INVALID);
-    }
-
-    public void writeSamples(int windowSizeSeconds, PrintStream out, TransactionType txType) {
-        String[] header = {
-                "Time (seconds)",
-                "Requests",
-                "Throughput (requests/second)",
-                "Minimum Latency (microseconds)",
-                "25th Percentile Latency (microseconds)",
-                "Median Latency (microseconds)",
-                "Average Latency (microseconds)",
-                "75th Percentile Latency (microseconds)",
-                "90th Percentile Latency (microseconds)",
-                "95th Percentile Latency (microseconds)",
-                "99th Percentile Latency (microseconds)",
-                "Maximum Latency (microseconds)"
-        };
-        out.println(StringUtil.join(",", header));
-        int i = 0;
-        for (DistributionStatistics s : new ThreadBench.TimeBucketIterable(results.getLatencySamples(), windowSizeSeconds, txType)) {
-            out.printf("%d,%d,%.3f,%d,%d,%d,%d,%d,%d,%d,%d,%d\n",
-                    i * windowSizeSeconds,
-                    s.getCount(),
-                    (double) s.getCount() / windowSizeSeconds,
-                    (int) s.getMinimum(),
-                    (int) s.get25thPercentile(),
-                    (int) s.getMedian(),
-                    (int) s.getAverage(),
-                    (int) s.get75thPercentile(),
-                    (int) s.get90thPercentile(),
-                    (int) s.get95thPercentile(),
-                    (int) s.get99thPercentile(),
-                    (int) s.getMaximum());
-            i += 1;
-        }
-    }
-
     public void writeRaw(List<TransactionType> activeTXTypes, PrintStream out) {
-
-        // This is needed because nanTime does not guarantee offset... we
-        // ground it (and round it) to ms from 1970-01-01 like currentTime
-        double x = ((double) System.nanoTime() / (double) 1000000000);
-        double y = ((double) System.currentTimeMillis() / (double) 1000);
-        double offset = x - y;
-
-        // long startNs = latencySamples.get(0).startNs;
-        String[] header = {
-                "Transaction Type Index",
-                "Transaction Name",
-                "Start Time (microseconds)",
-                "Latency (microseconds)",
-                "Worker Id (start number)",
-                "Phase Id (index in config file)"
-        };
-        out.println(StringUtil.join(",", header));
-        for (LatencyRecord.Sample s : results.getLatencySamples()) {
-            double startUs = ((double) s.getStartNanosecond() / (double) 1000000000);
-            String[] row = {
-                    Integer.toString(s.getTransactionType()),
-                    // Important!
-                    // The TxnType offsets start at 1!
-                    activeTXTypes.get(s.getTransactionType() - 1).getName(),
-                    String.format("%10.6f", startUs - offset),
-                    Integer.toString(s.getLatencyMicrosecond()),
-                    Integer.toString(s.getWorkerId()),
-                    Integer.toString(s.getPhaseId()),
-            };
-            out.println(StringUtil.join(",", row));
-        }
+        out.println(results.getStats().toJson());
     }
-
-
 }
Только в v1/src/main/java/com/oltpbenchmark/util: ThreadLocalRandomGenerator.java
diff -ur v0/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java v1/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
--- v0/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java	2025-02-23 19:35:48.934799491 +0300
+++ v1/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java	2025-02-23 19:34:55.678322992 +0300
@@ -29,22 +29,24 @@
 
 public class WorkloadConfiguration {
 
-    private final List<Phase> phases = new ArrayList<>();
+    private Phase phase = null;
     private DatabaseType databaseType;
     private String benchmarkName;
     private String url;
     private String username;
     private String password;
     private String driverClass;
+    private int maxConnections = 100;
     private int batchSize;
     private int maxRetries;
     private int randomSeed = -1;
     private double scaleFactor = 1.0;
     private double selectivity = -1.0;
     private int terminals;
+    private int startFromId = 1;
     private int loaderThreads = ThreadUtil.availableProcessors();
+    private int warmupTime = 0;
     private XMLConfiguration xmlConfig = null;
-    private WorkloadState workloadState;
     private TransactionTypes transTypes = null;
     private int isolationMode = Connection.TRANSACTION_SERIALIZABLE;
     private String dataDir = null;
@@ -56,6 +58,8 @@
      */
     private boolean newConnectionPerTxn = false;
 
+    private boolean disableConnectionPooling = false;
+
     public String getBenchmarkName() {
         return benchmarkName;
     }
@@ -64,10 +68,6 @@
         this.benchmarkName = benchmarkName;
     }
 
-    public WorkloadState getWorkloadState() {
-        return workloadState;
-    }
-
     public DatabaseType getDatabaseType() {
         return databaseType;
     }
@@ -108,6 +108,14 @@
         this.driverClass = driverClass;
     }
 
+    public int getMaxConnections() {
+        return maxConnections;
+    }
+
+    public void setMaxConnections(int maxConnections) {
+        this.maxConnections = maxConnections;
+    }
+
     public int getBatchSize() {
         return batchSize;
     }
@@ -141,19 +149,17 @@
         this.newConnectionPerTxn = newConnectionPerTxn;
     }
 
-    /**
-     * Initiate a new benchmark and workload state
-     */
-    public void initializeState(BenchmarkState benchmarkState) {
-        this.workloadState = new WorkloadState(benchmarkState, phases, terminals);
+    public boolean getDisableConnectionPool() {
+        return disableConnectionPooling;
     }
 
-    public void addPhase(int id, int time, int warmup, int rate, List<Double> weights, boolean rateLimited, boolean disabled, boolean serial, boolean timed, int active_terminals, Phase.Arrival arrival) {
-        phases.add(new Phase(benchmarkName, id, time, warmup, rate, weights, rateLimited, disabled, serial, timed, active_terminals, arrival));
+    public void setDisableConnectionPool(boolean disableConnectionPooling) {
+        this.disableConnectionPooling = disableConnectionPooling;
     }
 
-
-
+    public void setPhase(int id, int time, int warmup, List<Double> weights, boolean timed, int active_terminals, Phase.Arrival arrival) {
+        this.phase = new Phase(benchmarkName, id, time, warmup, weights, timed, active_terminals, arrival);
+    }
 
     /**
      * The number of loader threads that the framework is allowed to use.
@@ -168,6 +174,14 @@
         this.loaderThreads = loaderThreads;
     }
 
+    public int getWarmupTime() {
+        return this.warmupTime;
+    }
+
+    public void setWarmupTime(int time) {
+        this.warmupTime = time;
+    }
+
     public double getSelectivity() {
         return this.selectivity;
     }
@@ -210,15 +224,6 @@
     }
 
     /**
-     * Return the number of phases specified in the config file
-     *
-     * @return
-     */
-    public int getNumberOfPhases() {
-        return phases.size();
-    }
-
-    /**
      * Return the directory in which we can find the data files (for example, CSV
      * files) for loading the database.
      */
@@ -267,6 +272,14 @@
         this.terminals = terminals;
     }
 
+    public int getStartFromId() {
+        return startFromId;
+    }
+
+    public void setStartFrom(int startFromId) {
+        this.startFromId = startFromId;
+    }
+
     public TransactionTypes getTransTypes() {
         return transTypes;
     }
@@ -275,8 +288,8 @@
         this.transTypes = transTypes;
     }
 
-    public List<Phase> getPhases() {
-        return phases;
+    public Phase getPhase() {
+        return this.phase;
     }
 
     public XMLConfiguration getXmlConfig() {
@@ -325,7 +338,7 @@
     @Override
     public String toString() {
         return "WorkloadConfiguration{" +
-               "phases=" + phases +
+               "phase=" + phase +
                ", databaseType=" + databaseType +
                ", benchmarkName='" + benchmarkName + '\'' +
                ", url='" + url + '\'' +
@@ -338,7 +351,6 @@
                ", selectivity=" + selectivity +
                ", terminals=" + terminals +
                ", loaderThreads=" + loaderThreads +
-               ", workloadState=" + workloadState +
                ", transTypes=" + transTypes +
                ", isolationMode=" + isolationMode +
                ", dataDir='" + dataDir + '\'' +
Только в v0/src/main/java/com/oltpbenchmark: WorkloadState.java
diff -ur v0/src/main/resources/log4j.properties v1/src/main/resources/log4j.properties
--- v0/src/main/resources/log4j.properties	2025-02-23 19:35:48.862798848 +0300
+++ v1/src/main/resources/log4j.properties	2025-02-23 19:34:55.630322563 +0300
@@ -10,7 +10,6 @@
 log4j.logger.com.oltpbenchmark=INFO
 log4j.logger.com.oltpbenchmark.DBWorkload=INFO
 log4j.logger.com.oltpbenchmark.ThreadBench=INFO
-log4j.logger.com.oltpbenchmark.DistributionStatistics=INFO
 log4j.logger.com.oltpbenchmark.api.BenchmarkModule=INFO
 log4j.logger.com.oltpbenchmark.api.Loader=INFO
 log4j.logger.com.oltpbenchmark.api.Worker=INFO
