From 4efe5567225953c8f8f87294e897ac6f6d01e91b Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Tue, 13 Jun 2023 19:04:33 +0200
Subject: [PATCH 01/32] Speedup everything by using thread local random
 generator

---
 .../benchmarks/tpcc/TPCCLoader.java           |   1 +
 .../benchmarks/tpcc/TPCCUtil.java             |   4 +-
 .../util/ThreadLocalRandomGenerator.java      | 124 ++++++++++++++++++
 3 files changed, 127 insertions(+), 2 deletions(-)
 create mode 100644 src/main/java/com/oltpbenchmark/util/ThreadLocalRandomGenerator.java

diff --git a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java
index daaabc7b..9b19f960 100644
--- a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java
+++ b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java
@@ -22,6 +22,7 @@
 import com.oltpbenchmark.api.LoaderThread;
 import com.oltpbenchmark.benchmarks.tpcc.pojo.*;
 import com.oltpbenchmark.catalog.Table;
+import com.oltpbenchmark.util.ThreadLocalRandomGenerator;
 import com.oltpbenchmark.util.SQLUtil;
 
 import java.sql.*;
diff --git a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCUtil.java b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCUtil.java
index 70e594cb..0a5defc2 100644
--- a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCUtil.java
+++ b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCUtil.java
@@ -19,7 +19,7 @@
 package com.oltpbenchmark.benchmarks.tpcc;
 
 import com.oltpbenchmark.benchmarks.tpcc.pojo.Customer;
-import com.oltpbenchmark.util.RandomGenerator;
+import com.oltpbenchmark.util.ThreadLocalRandomGenerator;
 
 import java.sql.ResultSet;
 import java.sql.SQLException;
@@ -59,7 +59,7 @@ public static Customer newCustomerFromResults(ResultSet rs)
         return c;
     }
 
-    private static final RandomGenerator ran = new RandomGenerator(0);
+    private static final ThreadLocalRandomGenerator ran = new ThreadLocalRandomGenerator();
 
     public static String randomStr(int strLen) {
         if (strLen > 1) {
diff --git a/src/main/java/com/oltpbenchmark/util/ThreadLocalRandomGenerator.java b/src/main/java/com/oltpbenchmark/util/ThreadLocalRandomGenerator.java
new file mode 100644
index 00000000..25e3dd80
--- /dev/null
+++ b/src/main/java/com/oltpbenchmark/util/ThreadLocalRandomGenerator.java
@@ -0,0 +1,124 @@
+/*
+ * Copyright 2023 by YDB Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+
+ package com.oltpbenchmark.util;
+
+ import java.util.concurrent.ThreadLocalRandom;
+
+ public class ThreadLocalRandomGenerator {
+
+     /**
+      * Constructor
+      *
+      * @param seed
+      */
+     public ThreadLocalRandomGenerator() {
+     }
+
+     /**
+      * Returns a random int value between minimum and maximum (inclusive)
+      *
+      * @param minimum
+      * @param maximum
+      * @returns a int in the range [minimum, maximum]. Note that this is inclusive.
+      */
+     public int number(int minimum, int maximum) {
+
+         int range_size = maximum - minimum + 1;
+         int value = ThreadLocalRandom.current().nextInt(range_size);
+         value += minimum;
+
+         return value;
+     }
+
+     /**
+      * Returns a random long value between minimum and maximum (inclusive)
+      *
+      * @param minimum
+      * @param maximum
+      * @return
+      */
+     public long number(long minimum, long maximum) {
+
+         long range_size = (maximum - minimum) + 1;
+
+         // error checking and 2^x checking removed for simplicity.
+         long bits, val;
+         do {
+             bits = (ThreadLocalRandom.current().nextLong() << 1) >>> 1;
+             val = bits % range_size;
+         }
+         while (bits - val + range_size < 0L);
+         val += minimum;
+
+
+         return val;
+     }
+
+     /**
+      * @param decimal_places
+      * @param minimum
+      * @param maximum
+      * @return
+      */
+     public double fixedPoint(int decimal_places, double minimum, double maximum) {
+
+
+         int multiplier = 1;
+         for (int i = 0; i < decimal_places; ++i) {
+             multiplier *= 10;
+         }
+
+         int int_min = (int) (minimum * multiplier + 0.5);
+         int int_max = (int) (maximum * multiplier + 0.5);
+
+         return (double) this.number(int_min, int_max) / (double) multiplier;
+     }
+
+     /**
+      * @returns a random alphabetic string with length in range [minimum_length, maximum_length].
+      */
+     public String astring(int minimum_length, int maximum_length) {
+         return randomString(minimum_length, maximum_length, 'a', 26);
+     }
+
+
+     /**
+      * @returns a random numeric string with length in range [minimum_length, maximum_length].
+      */
+     public String nstring(int minimum_length, int maximum_length) {
+         return randomString(minimum_length, maximum_length, '0', 10);
+     }
+
+     /**
+      * @param minimum_length
+      * @param maximum_length
+      * @param base
+      * @param numCharacters
+      * @return
+      */
+     private String randomString(int minimum_length, int maximum_length, char base, int numCharacters) {
+         int length = number(minimum_length, maximum_length);
+         byte baseByte = (byte) base;
+         byte[] bytes = new byte[length];
+         for (int i = 0; i < length; ++i) {
+             bytes[i] = (byte) (baseByte + number(0, numCharacters - 1));
+         }
+         return new String(bytes);
+     }
+ }
\ No newline at end of file

From c11c070b0a107170e8c24bbbbfef3251428a950f Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Tue, 8 Aug 2023 18:51:32 +0200
Subject: [PATCH 02/32] add TPC-C result footer and calc only successful
 transactions

---
 .../java/com/oltpbenchmark/DBWorkload.java    | 45 +++++++++++++++++--
 .../java/com/oltpbenchmark/LatencyRecord.java | 15 ++++++-
 .../java/com/oltpbenchmark/api/Worker.java    | 18 ++++++--
 3 files changed, 70 insertions(+), 8 deletions(-)

diff --git a/src/main/java/com/oltpbenchmark/DBWorkload.java b/src/main/java/com/oltpbenchmark/DBWorkload.java
index 3a7f87aa..9a4fe37c 100644
--- a/src/main/java/com/oltpbenchmark/DBWorkload.java
+++ b/src/main/java/com/oltpbenchmark/DBWorkload.java
@@ -42,6 +42,8 @@
 import java.io.IOException;
 import java.io.PrintStream;
 import java.sql.SQLException;
+import java.text.DecimalFormat;
+import java.text.ParseException;
 import java.util.*;
 
 public class DBWorkload {
@@ -52,6 +54,11 @@ public class DBWorkload {
     private static final String RATE_DISABLED = "disabled";
     private static final String RATE_UNLIMITED = "unlimited";
 
+    // FIXME: TPC-C only hack
+    private static int newOrderTxnId = -1;
+    private static int numWarehouses = 10;
+    private static int time = 0;
+
     /**
      * @param args
      * @throws Exception
@@ -138,7 +145,11 @@ public static void main(String[] args) throws Exception {
 
             String isolationMode = xmlConfig.getString("isolation[not(@bench)]", "TRANSACTION_SERIALIZABLE");
             wrkld.setIsolationMode(xmlConfig.getString("isolation" + pluginTest, isolationMode));
-            wrkld.setScaleFactor(xmlConfig.getDouble("scalefactor", 1.0));
+
+            double scaleFactor = xmlConfig.getDouble("scalefactor", 1.0);
+            numWarehouses = (int) scaleFactor;
+            wrkld.setScaleFactor(scaleFactor);
+
             wrkld.setDataDir(xmlConfig.getString("datadir", "."));
             wrkld.setDDLPath(xmlConfig.getString("ddlpath", null));
 
@@ -157,7 +168,7 @@ public static void main(String[] args) throws Exception {
             String classname = pluginConfig.getString("/plugin[@name='" + plugin + "']");
 
             if (classname == null) {
-                throw new ParseException("Plugin " + plugin + " is undefined in config/plugin.xml");
+                throw new ParseException("Plugin " + plugin + " is undefined in config/plugin.xml", 1);
             }
 
             BenchmarkModule bench = ClassUtil.newInstance(classname, new Object[]{wrkld}, new Class<?>[]{WorkloadConfiguration.class});
@@ -197,6 +208,9 @@ public static void main(String[] args) throws Exception {
             for (int i = 1; i <= numTxnTypes; i++) {
                 String key = "transactiontypes" + pluginTest + "/transactiontype[" + i + "]";
                 String txnName = xmlConfig.getString(key + "/name");
+                if (txnName.equals("NewOrder")) {
+                    newOrderTxnId = i + txnIdOffset;
+                }
 
                 // Get ID if specified; else increment from last one.
                 int txnId = i;
@@ -329,7 +343,7 @@ public static void main(String[] args) throws Exception {
                     System.exit(-1);
                 }
 
-                int time = work.getInt("/time", 0);
+                time = work.getInt("/time", 0);
                 int warmup = work.getInt("/warmup", 0);
                 timed = (time > 0);
                 if (!timed) {
@@ -460,6 +474,7 @@ public static void main(String[] args) throws Exception {
             // Bombs away!
             try {
                 Results r = runWorkload(benchList, intervalMonitor);
+                printToplineResults(r);
                 writeOutputs(r, activeTXTypes, argsLine, xmlConfig);
                 writeHistograms(r);
 
@@ -651,6 +666,30 @@ private static Results runWorkload(List<BenchmarkModule> benchList, int interval
         return r;
     }
 
+    private static void printToplineResults(Results r) {
+        long numNewOrderTransactions = 0;
+        for (LatencyRecord.Sample sample : r.getLatencySamples()) {
+            if (sample.getTransactionType() == newOrderTxnId && sample.isSuccess()) {
+                ++numNewOrderTransactions;
+            }
+        }
+
+        double tpmc = 1.0 * numNewOrderTransactions * 60 / time;
+        double efficiency = 1.0 * tpmc * 100 / numWarehouses / 12.86;
+        DecimalFormat df = new DecimalFormat();
+        df.setMaximumFractionDigits(2);
+        String resultOut = "\n"
+                + "================RESULTS================\n"
+                + String.format("%18s | %18d\n", "Time, s", time)
+                + String.format("%18s | %18d\n", "NewOrders", numNewOrderTransactions)
+                + String.format("%18s | %18.2f\n", "TPM-C", tpmc)
+                + String.format("%18s | %17.2f%%\n", "Efficiency", efficiency)
+                + String.format("Rate limited reqs/s: %s\n", r);
+
+        LOG.info(SINGLE_LINE);
+        LOG.info(resultOut);
+    }
+
     private static void printUsage(Options options) {
         HelpFormatter hlpfrmt = new HelpFormatter();
         hlpfrmt.printHelp("benchbase", options);
diff --git a/src/main/java/com/oltpbenchmark/LatencyRecord.java b/src/main/java/com/oltpbenchmark/LatencyRecord.java
index 0525d23f..3afb6093 100644
--- a/src/main/java/com/oltpbenchmark/LatencyRecord.java
+++ b/src/main/java/com/oltpbenchmark/LatencyRecord.java
@@ -50,7 +50,10 @@ public LatencyRecord(long startNanosecond) {
     }
 
     public void addLatency(int transType, long startNanosecond, long endNanosecond, int workerId, int phaseId) {
+        addLatency(transType, startNanosecond, endNanosecond, workerId, phaseId, true);
+    }
 
+    public void addLatency(int transType, long startNanosecond, long endNanosecond, int workerId, int phaseId, boolean isSuccess) {
 
         if (nextIndex == ALLOC_SIZE) {
             allocateChunk();
@@ -62,7 +65,7 @@ public void addLatency(int transType, long startNanosecond, long endNanosecond,
         int latencyMicroseconds = (int) ((endNanosecond - startNanosecond + 500) / 1000);
 
 
-        chunk[nextIndex] = new Sample(transType, startOffsetNanosecond, latencyMicroseconds, workerId, phaseId);
+        chunk[nextIndex] = new Sample(transType, startOffsetNanosecond, latencyMicroseconds, workerId, phaseId, isSuccess);
         ++nextIndex;
 
         lastNanosecond += startOffsetNanosecond;
@@ -94,13 +97,19 @@ public static final class Sample implements Comparable<Sample> {
         private final int latencyMicrosecond;
         private final int workerId;
         private final int phaseId;
+        private final boolean isSuccess;
 
         public Sample(int transactionType, long startNanosecond, int latencyMicrosecond, int workerId, int phaseId) {
+            this(transactionType, startNanosecond, latencyMicrosecond, workerId, phaseId, true);
+        }
+
+        public  Sample(int transactionType, long startNanosecond, int latencyMicrosecond, int workerId, int phaseId, boolean isSuccess) {
             this.transactionType = transactionType;
             this.startNanosecond = startNanosecond;
             this.latencyMicrosecond = latencyMicrosecond;
             this.workerId = workerId;
             this.phaseId = phaseId;
+            this.isSuccess = isSuccess;
         }
 
         public int getTransactionType() {
@@ -123,6 +132,10 @@ public int getPhaseId() {
             return phaseId;
         }
 
+        public boolean isSuccess() {
+            return isSuccess;
+        }
+
         @Override
         public int compareTo(Sample other) {
             long diff = this.startNanosecond - other.startNanosecond;
diff --git a/src/main/java/com/oltpbenchmark/api/Worker.java b/src/main/java/com/oltpbenchmark/api/Worker.java
index f1cdf68e..8c706b49 100644
--- a/src/main/java/com/oltpbenchmark/api/Worker.java
+++ b/src/main/java/com/oltpbenchmark/api/Worker.java
@@ -279,7 +279,7 @@ public final void run() {
 
                 long start = System.nanoTime();
 
-                doWork(configuration.getDatabaseType(), transactionType);
+                TransactionStatus status = doWork(configuration.getDatabaseType(), transactionType);
 
                 long end = System.nanoTime();
 
@@ -304,7 +304,15 @@ public final void run() {
                             break;
                         }
                         if (preState == MEASURE && postPhase.getId() == prePhase.getId()) {
-                            latencies.addLatency(transactionType.getId(), start, end, this.id, prePhase.getId());
+                            boolean isSuccess = status == TransactionStatus.SUCCESS ||
+                                status == TransactionStatus.USER_ABORTED;
+                            latencies.addLatency(
+                                transactionType.getId(),
+                                start,
+                                end,
+                                this.id,
+                                prePhase.getId(),
+                                isSuccess);
                             intervalRequests.incrementAndGet();
                         }
                         if (prePhase.isLatencyRun()) {
@@ -383,7 +391,8 @@ private TransactionType getTransactionType(SubmittedProcedure pieceOfWork, Phase
      * @param databaseType TODO
      * @param transactionType TODO
      */
-    protected final void doWork(DatabaseType databaseType, TransactionType transactionType) {
+    protected final TransactionStatus doWork(DatabaseType databaseType, TransactionType transactionType) {
+        TransactionStatus status = TransactionStatus.UNKNOWN;
 
         try {
             int retryCount = 0;
@@ -391,7 +400,7 @@ protected final void doWork(DatabaseType databaseType, TransactionType transacti
 
             while (retryCount < maxRetryCount && this.workloadState.getGlobalState() != State.DONE) {
 
-                TransactionStatus status = TransactionStatus.UNKNOWN;
+                status = TransactionStatus.UNKNOWN;
 
                 if (this.conn == null) {
                     try {
@@ -481,6 +490,7 @@ protected final void doWork(DatabaseType databaseType, TransactionType transacti
             throw new RuntimeException(msg, ex);
         }
 
+        return status;
     }
 
     private boolean isRetryable(SQLException ex) {

From 6855af44796a83dc88d1fb2da8a1ea5a4aab2127 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Fri, 11 Aug 2023 11:28:50 +0200
Subject: [PATCH 03/32] avoid starting all threads simultaneously

---
 .../java/com/oltpbenchmark/DBWorkload.java    |  1 +
 .../oltpbenchmark/WorkloadConfiguration.java  |  9 +++++++++
 .../java/com/oltpbenchmark/api/Worker.java    | 19 +++++++++++++++++++
 3 files changed, 29 insertions(+)

diff --git a/src/main/java/com/oltpbenchmark/DBWorkload.java b/src/main/java/com/oltpbenchmark/DBWorkload.java
index 9a4fe37c..0371729a 100644
--- a/src/main/java/com/oltpbenchmark/DBWorkload.java
+++ b/src/main/java/com/oltpbenchmark/DBWorkload.java
@@ -361,6 +361,7 @@ public static void main(String[] args) throws Exception {
                     System.exit(-1);
                 }
 
+                wrkld.setWarmupTime(warmup);
                 ArrayList<Double> weights = new ArrayList<>();
 
                 double totalWeight = 0;
diff --git a/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java b/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
index fb76076f..d05e64ea 100644
--- a/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
+++ b/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
@@ -43,6 +43,7 @@ public class WorkloadConfiguration {
     private double selectivity = -1.0;
     private int terminals;
     private int loaderThreads = ThreadUtil.availableProcessors();
+    private int warmupTime = 0;
     private XMLConfiguration xmlConfig = null;
     private WorkloadState workloadState;
     private TransactionTypes transTypes = null;
@@ -168,6 +169,14 @@ public void setLoaderThreads(int loaderThreads) {
         this.loaderThreads = loaderThreads;
     }
 
+    public int getWarmupTime() {
+        return this.warmupTime;
+    }
+
+    public void setWarmupTime(int time) {
+        this.warmupTime = time;
+    }
+
     public double getSelectivity() {
         return this.selectivity;
     }
diff --git a/src/main/java/com/oltpbenchmark/api/Worker.java b/src/main/java/com/oltpbenchmark/api/Worker.java
index 8c706b49..e4f8e2d6 100644
--- a/src/main/java/com/oltpbenchmark/api/Worker.java
+++ b/src/main/java/com/oltpbenchmark/api/Worker.java
@@ -33,6 +33,7 @@
 import java.util.Map;
 import java.util.Map.Entry;
 import java.util.Random;
+import java.util.concurrent.ThreadLocalRandom;
 import java.util.concurrent.atomic.AtomicInteger;
 
 import static com.oltpbenchmark.types.State.MEASURE;
@@ -201,6 +202,8 @@ public final void run() {
         // wait for start
         workloadState.blockForStart();
 
+        boolean firstDelay = true;
+
         while (true) {
 
             // PART 1: Init and check if done
@@ -224,6 +227,22 @@ public final void run() {
             // Sleep if there's nothing to do.
             workloadState.stayAwake();
 
+            if (firstDelay) {
+                firstDelay = false;
+                int warmup = configuration.getWarmupTime();
+
+                // Additional delay to avoid starting all threads simultaneously
+                if (warmup > 0) {
+                    long maxDelay = 2000 * warmup / 3;
+                    try {
+                        Thread.sleep(ThreadLocalRandom.current().nextLong(maxDelay));
+                        LOG.debug("Thread started");
+                    } catch (InterruptedException e) {
+                        LOG.error("Pre-start sleep interrupted", e);
+                    }
+                }
+            }
+
             Phase prePhase = workloadState.getCurrentPhase();
             if (prePhase == null) {
                 continue;

From 9ef17ce0b014493d1dc1ed91dbe82a772e8a60e3 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Tue, 6 Jun 2023 17:24:34 +0200
Subject: [PATCH 04/32] Add --start-from-id option to run multiple instances in
 parallel

---
 src/main/java/com/oltpbenchmark/DBWorkload.java        |  7 +++++++
 .../java/com/oltpbenchmark/WorkloadConfiguration.java  |  9 +++++++++
 src/main/java/com/oltpbenchmark/api/Loader.java        |  2 ++
 .../oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java   | 10 +++++++---
 .../com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java  |  2 +-
 .../com/oltpbenchmark/benchmarks/tpcc/TPCCWorker.java  |  1 -
 6 files changed, 26 insertions(+), 5 deletions(-)

diff --git a/src/main/java/com/oltpbenchmark/DBWorkload.java b/src/main/java/com/oltpbenchmark/DBWorkload.java
index 0371729a..453eb1fd 100644
--- a/src/main/java/com/oltpbenchmark/DBWorkload.java
+++ b/src/main/java/com/oltpbenchmark/DBWorkload.java
@@ -94,6 +94,11 @@ public static void main(String[] args) throws Exception {
             intervalMonitor = Integer.parseInt(argsLine.getOptionValue("im"));
         }
 
+        int startFromId = 1;
+        if (argsLine.hasOption("sf")) {
+            startFromId = Integer.parseInt(argsLine.getOptionValue("sf"));
+        }
+
         // -------------------------------------------------------------------
         // GET PLUGIN LIST
         // -------------------------------------------------------------------
@@ -137,6 +142,7 @@ public static void main(String[] args) throws Exception {
             int terminals = xmlConfig.getInt("terminals[not(@bench)]", 0);
             terminals = xmlConfig.getInt("terminals" + pluginTest, terminals);
             wrkld.setTerminals(terminals);
+            wrkld.setStartFrom(startFromId);
 
             if (xmlConfig.containsKey("loaderThreads")) {
                 int loaderThreads = xmlConfig.getInt("loaderThreads");
@@ -509,6 +515,7 @@ private static Options buildOptions(XMLConfiguration pluginConfig) {
         options.addOption("d", "directory", true, "Base directory for the result files, default is current directory");
         options.addOption(null, "dialects-export", true, "Export benchmark SQL to a dialects file");
         options.addOption("jh", "json-histograms", true, "Export histograms to JSON file");
+        options.addOption("sf", "start-from-id", true, "Start from a specific scale instance id");
         return options;
     }
 
diff --git a/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java b/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
index d05e64ea..b088ee63 100644
--- a/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
+++ b/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
@@ -42,6 +42,7 @@ public class WorkloadConfiguration {
     private double scaleFactor = 1.0;
     private double selectivity = -1.0;
     private int terminals;
+    private int startFromId = 1;
     private int loaderThreads = ThreadUtil.availableProcessors();
     private int warmupTime = 0;
     private XMLConfiguration xmlConfig = null;
@@ -276,6 +277,14 @@ public void setTerminals(int terminals) {
         this.terminals = terminals;
     }
 
+    public int getStartFromId() {
+        return startFromId;
+    }
+
+    public void setStartFrom(int startFromId) {
+        this.startFromId = startFromId;
+    }
+
     public TransactionTypes getTransTypes() {
         return transTypes;
     }
diff --git a/src/main/java/com/oltpbenchmark/api/Loader.java b/src/main/java/com/oltpbenchmark/api/Loader.java
index abdbd75f..11397546 100644
--- a/src/main/java/com/oltpbenchmark/api/Loader.java
+++ b/src/main/java/com/oltpbenchmark/api/Loader.java
@@ -44,12 +44,14 @@ public abstract class Loader<T extends BenchmarkModule> {
 
     protected final WorkloadConfiguration workConf;
     protected final double scaleFactor;
+    protected final int startFromId;
     private final Histogram<String> tableSizes = new Histogram<>(true);
 
     public Loader(T benchmark) {
         this.benchmark = benchmark;
         this.workConf = benchmark.getWorkloadConfiguration();
         this.scaleFactor = workConf.getScaleFactor();
+        this.startFromId = workConf.getStartFromId();
     }
 
     /**
diff --git a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java
index 8bd162ff..69bd6324 100644
--- a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java
+++ b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java
@@ -71,6 +71,8 @@ protected List<TPCCWorker> createTerminals() throws SQLException {
             numWarehouses = 1;
         }
 
+        final int startWarehouseId = workConf.getStartFromId();
+
         int numTerminals = workConf.getTerminals();
 
         // We distribute terminals evenly across the warehouses
@@ -78,9 +80,11 @@ protected List<TPCCWorker> createTerminals() throws SQLException {
         // are distributed as
         // 1, 1, 2, 1, 2, 1, 2
         final double terminalsPerWarehouse = (double) numTerminals / numWarehouses;
-        int workerId = 0;
 
-        for (int w = 0; w < numWarehouses; w++) {
+        int terminalIndex = 0;
+        int workerId = startWarehouseId / numWarehouses * numTerminals;
+
+        for (int w = startWarehouseId - 1; w < numWarehouses + startWarehouseId - 1; w++) {
             // Compute the number of terminals in *this* warehouse
             int lowerTerminalId = (int) (w * terminalsPerWarehouse);
             int upperTerminalId = (int) ((w + 1) * terminalsPerWarehouse);
@@ -105,7 +109,7 @@ protected List<TPCCWorker> createTerminals() throws SQLException {
                 lowerDistrictId += 1;
 
                 TPCCWorker terminal = new TPCCWorker(this, workerId++, w_id, lowerDistrictId, upperDistrictId, numWarehouses);
-                terminals[lowerTerminalId + terminalId] = terminal;
+                terminals[terminalIndex++] = terminal;
             }
 
         }
diff --git a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java
index 9b19f960..d1453ece 100644
--- a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java
+++ b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java
@@ -68,7 +68,7 @@ public void afterLoad() {
         // We use a separate thread per warehouse. Each thread will load
         // all of the tables that depend on that warehouse. They all have
         // to wait until the ITEM table is loaded first though.
-        for (int w = 1; w <= numWarehouses; w++) {
+        for (int w = this.startFromId; w <= startFromId + numWarehouses - 1; w++) {
             final int w_id = w;
             LoaderThread t = new LoaderThread(this.benchmark) {
                 @Override
diff --git a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCWorker.java b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCWorker.java
index bd75874d..d2e28a46 100644
--- a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCWorker.java
+++ b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCWorker.java
@@ -53,7 +53,6 @@ public TPCCWorker(TPCCBenchmark benchmarkModule, int id,
         this.terminalDistrictLowerID = terminalDistrictLowerID;
         this.terminalDistrictUpperID = terminalDistrictUpperID;
 
-
         this.numWarehouses = numWarehouses;
     }
 

From 28babdc483d0dccaa267d14a2a6cefe4616f5439 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Sun, 13 Aug 2023 16:21:21 +0200
Subject: [PATCH 05/32] avoid unhandled exception caused by failed rollback

---
 .../java/com/oltpbenchmark/api/Worker.java    | 28 +++++++++++++++----
 1 file changed, 22 insertions(+), 6 deletions(-)

diff --git a/src/main/java/com/oltpbenchmark/api/Worker.java b/src/main/java/com/oltpbenchmark/api/Worker.java
index e4f8e2d6..7c3dc727 100644
--- a/src/main/java/com/oltpbenchmark/api/Worker.java
+++ b/src/main/java/com/oltpbenchmark/api/Worker.java
@@ -456,16 +456,32 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                     break;
 
                 } catch (UserAbortException ex) {
-                    conn.rollback();
+                    // TODO: probably check exception and retry if possible
+                    try {
+                        conn.rollback();
+                        status = TransactionStatus.USER_ABORTED;
+                    } catch (Exception e) {
+                        LOG.warn(
+                            String.format("Failed to rollback transaction after UserAbortException (%s): %s",
+                                          ex.toString(), e.toString()));
+
+                        status = TransactionStatus.ERROR;
+                    }
 
                     ABORT_LOG.debug(String.format("%s Aborted", transactionType), ex);
 
-                    status = TransactionStatus.USER_ABORTED;
 
                     break;
 
                 } catch (SQLException ex) {
-                    conn.rollback();
+                    // TODO: probably check exception and retry if possible
+                    try {
+                        conn.rollback();
+                    } catch (Exception e) {
+                        LOG.warn(
+                            String.format("Failed to rollback transaction after SQLException (%s): %s",
+                                          ex.toString(), e.toString()));
+                    }
 
                     if (isRetryable(ex)) {
                         LOG.debug(String.format("Retryable SQLException occurred during [%s]... current retry attempt [%d], max retry attempts [%d], sql state [%s], error code [%d].", transactionType, retryCount, maxRetryCount, ex.getSQLState(), ex.getErrorCode()), ex);
@@ -503,10 +519,10 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                 }
 
             }
-        } catch (SQLException ex) {
+        } catch (RuntimeException ex) {
             String msg = String.format("Unexpected SQLException in '%s' when executing '%s' on [%s]", this, transactionType, databaseType.name());
-
-            throw new RuntimeException(msg, ex);
+            LOG.error(msg);
+            throw ex;
         }
 
         return status;

From a72a6d655fbcbc1c412384256bf61a5d8adbebaf Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Sun, 13 Aug 2023 22:33:29 +0200
Subject: [PATCH 06/32] print uncought exception

---
 src/main/java/com/oltpbenchmark/api/Worker.java | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/src/main/java/com/oltpbenchmark/api/Worker.java b/src/main/java/com/oltpbenchmark/api/Worker.java
index 7c3dc727..ee850733 100644
--- a/src/main/java/com/oltpbenchmark/api/Worker.java
+++ b/src/main/java/com/oltpbenchmark/api/Worker.java
@@ -520,7 +520,8 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
 
             }
         } catch (RuntimeException ex) {
-            String msg = String.format("Unexpected SQLException in '%s' when executing '%s' on [%s]", this, transactionType, databaseType.name());
+            String msg = String.format("Unexpected RuntimeException in '%s' when executing '%s' on [%s]: %s",
+                                       this, transactionType, databaseType.name(), ex.toString());
             LOG.error(msg);
             throw ex;
         }

From 4521d64f158ccfc4408925cea00147e738a70bd9 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Mon, 14 Aug 2023 18:42:12 +0200
Subject: [PATCH 07/32] add scripts/tpcc.sh

---
 scripts/tpcc.sh | 41 +++++++++++++++++++++++++++++++++++++++++
 1 file changed, 41 insertions(+)
 create mode 100755 scripts/tpcc.sh

diff --git a/scripts/tpcc.sh b/scripts/tpcc.sh
new file mode 100755
index 00000000..a326fa21
--- /dev/null
+++ b/scripts/tpcc.sh
@@ -0,0 +1,41 @@
+#!/bin/bash
+
+export TZ=UTC
+export LC_ALL=en_US.UTF-8
+
+MEMORY='1G'
+
+args=()
+
+while [[ "$#" > 0 ]]; do case $1 in
+    --memory)
+        memory=$2
+        shift;;
+    *)
+        args+=("$1")
+        ;;
+esac; shift; done
+
+if [[ -z $memory ]]; then
+    memory=$MEMORY
+fi
+
+if command -v java >/dev/null; then
+    java_version=$(java -version 2>&1 | awk -F '"' '/version/ {print $2}')
+    if [[ $java_version = "17"* ]]; then
+        java="java"
+    fi
+fi
+
+if [[ -z $java ]]; then
+    if [[ -e "/usr/lib/jvm/java-17-openjdk-amd64/bin/java" ]]; then
+        java="/usr/lib/jvm/java-17-openjdk-amd64/bin/java"
+    elif [[ -e "/usr/lib/jvm/java-17/bin/java" ]]; then
+        java="/usr/lib/jvm/java-17/bin/java"
+    else
+        echo "Java 17 is required to run this script."
+        exit 1
+    fi
+fi
+
+$java -Xmx$memory -jar benchbase.jar -b tpcc "${args[@]}"

From 99fb402698cf67c7d7a96796004c7146f9eab867 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Mon, 14 Aug 2023 21:33:17 +0200
Subject: [PATCH 08/32] output to raw file if request is successful

---
 src/main/java/com/oltpbenchmark/util/ResultWriter.java | 4 +++-
 1 file changed, 3 insertions(+), 1 deletion(-)

diff --git a/src/main/java/com/oltpbenchmark/util/ResultWriter.java b/src/main/java/com/oltpbenchmark/util/ResultWriter.java
index ae3aff33..91e33923 100644
--- a/src/main/java/com/oltpbenchmark/util/ResultWriter.java
+++ b/src/main/java/com/oltpbenchmark/util/ResultWriter.java
@@ -208,7 +208,8 @@ public void writeRaw(List<TransactionType> activeTXTypes, PrintStream out) {
                 "Start Time (microseconds)",
                 "Latency (microseconds)",
                 "Worker Id (start number)",
-                "Phase Id (index in config file)"
+                "Phase Id (index in config file)",
+                "IsSuccess"
         };
         out.println(StringUtil.join(",", header));
         for (LatencyRecord.Sample s : results.getLatencySamples()) {
@@ -222,6 +223,7 @@ public void writeRaw(List<TransactionType> activeTXTypes, PrintStream out) {
                     Integer.toString(s.getLatencyMicrosecond()),
                     Integer.toString(s.getWorkerId()),
                     Integer.toString(s.getPhaseId()),
+                    Boolean.toString(s.isSuccess()),
             };
             out.println(StringUtil.join(",", row));
         }

From a4f0fda57b475a84e29c10e637062aa7a8bc4095 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Wed, 30 Aug 2023 17:35:09 +0200
Subject: [PATCH 09/32] each delivery transaction must use all 10 districts,
 issue #10

---
 .../benchmarks/tpcc/TPCCBenchmark.java        | 41 ++++---------------
 1 file changed, 9 insertions(+), 32 deletions(-)

diff --git a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java
index 69bd6324..a20ef65f 100644
--- a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java
+++ b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCBenchmark.java
@@ -73,50 +73,27 @@ protected List<TPCCWorker> createTerminals() throws SQLException {
 
         final int startWarehouseId = workConf.getStartFromId();
 
-        int numTerminals = workConf.getTerminals();
+        final int numTerminals = workConf.getTerminals();
 
-        // We distribute terminals evenly across the warehouses
-        // Eg. if there are 10 terminals across 7 warehouses, they
-        // are distributed as
-        // 1, 1, 2, 1, 2, 1, 2
-        final double terminalsPerWarehouse = (double) numTerminals / numWarehouses;
+        final int terminalsPerWarehouse = (int) numTerminals / numWarehouses;
+
+        assert (terminalsPerWarehouse == 10); // according TPC-C
+
+        final int lowerDistrictId = 1;
+        final int upperDistrictId = terminalsPerWarehouse;
 
         int terminalIndex = 0;
         int workerId = startWarehouseId / numWarehouses * numTerminals;
 
         for (int w = startWarehouseId - 1; w < numWarehouses + startWarehouseId - 1; w++) {
-            // Compute the number of terminals in *this* warehouse
-            int lowerTerminalId = (int) (w * terminalsPerWarehouse);
-            int upperTerminalId = (int) ((w + 1) * terminalsPerWarehouse);
-            // protect against double rounding errors
-            int w_id = w + 1;
-            if (w_id == numWarehouses) {
-                upperTerminalId = numTerminals;
-            }
-            int numWarehouseTerminals = upperTerminalId - lowerTerminalId;
-
-            if (LOG.isDebugEnabled()) {
-                LOG.debug(String.format("w_id %d = %d terminals [lower=%d / upper%d]", w_id, numWarehouseTerminals, lowerTerminalId, upperTerminalId));
-            }
-
-            final double districtsPerTerminal = TPCCConfig.configDistPerWhse / (double) numWarehouseTerminals;
-            for (int terminalId = 0; terminalId < numWarehouseTerminals; terminalId++) {
-                int lowerDistrictId = (int) (terminalId * districtsPerTerminal);
-                int upperDistrictId = (int) ((terminalId + 1) * districtsPerTerminal);
-                if (terminalId + 1 == numWarehouseTerminals) {
-                    upperDistrictId = TPCCConfig.configDistPerWhse;
-                }
-                lowerDistrictId += 1;
+            final int w_id = w + 1;
 
+            for (int terminalId = 0; terminalId < terminalsPerWarehouse; terminalId++) {
                 TPCCWorker terminal = new TPCCWorker(this, workerId++, w_id, lowerDistrictId, upperDistrictId, numWarehouses);
                 terminals[terminalIndex++] = terminal;
             }
-
         }
 
-
         return Arrays.asList(terminals);
     }
-
-
 }

From 5852a20047e2babdfe461134f009e1b3a61f17aa Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Fri, 1 Sep 2023 16:47:12 +0200
Subject: [PATCH 10/32] allow to build on Mac

---
 pom.xml | 1 +
 1 file changed, 1 insertion(+)

diff --git a/pom.xml b/pom.xml
index 60323dd1..18f43b41 100644
--- a/pom.xml
+++ b/pom.xml
@@ -281,6 +281,7 @@
                     <finalName>${project.artifactId}-${classifier}</finalName>
                     <recompressZippedFiles>false</recompressZippedFiles>
                     <descriptors>${descriptors}</descriptors>
+                    <tarLongFileMode>posix</tarLongFileMode>
                 </configuration>
                 <executions>
                     <execution>

From a0224d6dd475f0e01ae8c34878060e8324a5b1d4 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Sat, 2 Sep 2023 15:24:20 +0200
Subject: [PATCH 11/32] Use aggregated statistics to decrease memory footprint

---
 .../java/com/oltpbenchmark/DBWorkload.java    |  31 +-
 .../oltpbenchmark/DistributionStatistics.java | 170 -----------
 .../java/com/oltpbenchmark/LatencyRecord.java | 198 ------------
 .../java/com/oltpbenchmark/ResultStats.java   | 288 ++++++++++++++++++
 src/main/java/com/oltpbenchmark/Results.java  |  29 +-
 .../java/com/oltpbenchmark/ThreadBench.java   | 137 +--------
 .../java/com/oltpbenchmark/api/Worker.java    |  17 +-
 .../com/oltpbenchmark/util/ResultWriter.java  | 118 +------
 src/main/resources/log4j.properties           |   1 -
 9 files changed, 316 insertions(+), 673 deletions(-)
 delete mode 100644 src/main/java/com/oltpbenchmark/DistributionStatistics.java
 delete mode 100644 src/main/java/com/oltpbenchmark/LatencyRecord.java
 create mode 100644 src/main/java/com/oltpbenchmark/ResultStats.java

diff --git a/src/main/java/com/oltpbenchmark/DBWorkload.java b/src/main/java/com/oltpbenchmark/DBWorkload.java
index 453eb1fd..394c896b 100644
--- a/src/main/java/com/oltpbenchmark/DBWorkload.java
+++ b/src/main/java/com/oltpbenchmark/DBWorkload.java
@@ -591,20 +591,12 @@ private static void writeOutputs(Results r, List<TransactionType> activeTXTypes,
 
         String baseFileName = name + "_" + TimeUtil.getCurrentTimeString();
 
-        int windowSize = Integer.parseInt(argsLine.getOptionValue("s", "5"));
-
-        String rawFileName = baseFileName + ".raw.csv";
+        String rawFileName = baseFileName + ".raw.json";
         try (PrintStream ps = new PrintStream(FileUtil.joinPath(outputDirectory, rawFileName))) {
             LOG.info("Output Raw data into file: {}", rawFileName);
             rw.writeRaw(activeTXTypes, ps);
         }
 
-        String sampleFileName = baseFileName + ".samples.csv";
-        try (PrintStream ps = new PrintStream(FileUtil.joinPath(outputDirectory, sampleFileName))) {
-            LOG.info("Output samples into file: {}", sampleFileName);
-            rw.writeSamples(ps);
-        }
-
         String summaryFileName = baseFileName + ".summary.json";
         try (PrintStream ps = new PrintStream(FileUtil.joinPath(outputDirectory, summaryFileName))) {
             LOG.info("Output summary data into file: {}", summaryFileName);
@@ -630,20 +622,6 @@ private static void writeOutputs(Results r, List<TransactionType> activeTXTypes,
             LOG.info("Output benchmark config into file: {}", configFileName);
             rw.writeConfig(ps);
         }
-
-        String resultsFileName = baseFileName + ".results.csv";
-        try (PrintStream ps = new PrintStream(FileUtil.joinPath(outputDirectory, resultsFileName))) {
-            LOG.info("Output results into file: {} with window size {}", resultsFileName, windowSize);
-            rw.writeResults(windowSize, ps);
-        }
-
-        for (TransactionType t : activeTXTypes) {
-            String fileName = baseFileName + ".results." + t.getName() + ".csv";
-            try (PrintStream ps = new PrintStream(FileUtil.joinPath(outputDirectory, fileName))) {
-                rw.writeResults(windowSize, ps, t);
-            }
-        }
-
     }
 
     private static void runCreator(BenchmarkModule bench) throws SQLException, IOException {
@@ -675,12 +653,7 @@ private static Results runWorkload(List<BenchmarkModule> benchList, int interval
     }
 
     private static void printToplineResults(Results r) {
-        long numNewOrderTransactions = 0;
-        for (LatencyRecord.Sample sample : r.getLatencySamples()) {
-            if (sample.getTransactionType() == newOrderTxnId && sample.isSuccess()) {
-                ++numNewOrderTransactions;
-            }
-        }
+        long numNewOrderTransactions = r.getStats().getSuccessCount(newOrderTxnId);
 
         double tpmc = 1.0 * numNewOrderTransactions * 60 / time;
         double efficiency = 1.0 * tpmc * 100 / numWarehouses / 12.86;
diff --git a/src/main/java/com/oltpbenchmark/DistributionStatistics.java b/src/main/java/com/oltpbenchmark/DistributionStatistics.java
deleted file mode 100644
index 65705d2a..00000000
--- a/src/main/java/com/oltpbenchmark/DistributionStatistics.java
+++ /dev/null
@@ -1,170 +0,0 @@
-/*
- * Copyright 2020 by OLTPBenchmark Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- *
- */
-
-
-package com.oltpbenchmark;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.Arrays;
-import java.util.LinkedHashMap;
-import java.util.Map;
-import java.util.concurrent.TimeUnit;
-
-public class DistributionStatistics {
-    private static final Logger LOG = LoggerFactory.getLogger(DistributionStatistics.class);
-
-    private static final double[] PERCENTILES = {0.0, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 1.0};
-
-    private static final int MINIMUM = 0;
-    private static final int PERCENTILE_25TH = 1;
-    private static final int MEDIAN = 2;
-    private static final int PERCENTILE_75TH = 3;
-    private static final int PERCENTILE_90TH = 4;
-    private static final int PERCENTILE_95TH = 5;
-    private static final int PERCENTILE_99TH = 6;
-    private static final int MAXIMUM = 7;
-
-    private final int count;
-    private final long[] percentiles;
-    private final double average;
-    private final double standardDeviation;
-
-    public DistributionStatistics(int count, long[] percentiles, double average, double standardDeviation) {
-        this.count = count;
-        this.percentiles = Arrays.copyOfRange(percentiles, 0, PERCENTILES.length);
-        this.average = average;
-        this.standardDeviation = standardDeviation;
-    }
-
-    /**
-     * Computes distribution statistics over values. WARNING: This will sort
-     * values.
-     */
-    public static DistributionStatistics computeStatistics(int[] valuesAsMicroseconds) {
-        if (valuesAsMicroseconds.length == 0) {
-            long[] percentiles = new long[PERCENTILES.length];
-            Arrays.fill(percentiles, -1);
-            return new DistributionStatistics(0, percentiles, -1, -1);
-        }
-
-        Arrays.sort(valuesAsMicroseconds);
-
-        double sum = 0;
-        for (int value1 : valuesAsMicroseconds) {
-            sum += value1;
-        }
-        double average = sum / valuesAsMicroseconds.length;
-
-        double sumDiffsSquared = 0;
-        for (int value : valuesAsMicroseconds) {
-            double v = value - average;
-            sumDiffsSquared += v * v;
-        }
-        double standardDeviation = 0;
-        if (valuesAsMicroseconds.length > 1) {
-            standardDeviation = Math
-                    .sqrt(sumDiffsSquared / (valuesAsMicroseconds.length - 1));
-        }
-
-        // NOTE: NIST recommends interpolating. This just selects the closest
-        // value, which is described as another common technique.
-        // http://www.itl.nist.gov/div898/handbook/prc/section2/prc252.htm
-        long[] percentiles = new long[PERCENTILES.length];
-        for (int i = 0; i < percentiles.length; ++i) {
-            int index = (int) (PERCENTILES[i] * valuesAsMicroseconds.length);
-            if (index == valuesAsMicroseconds.length) {
-                index = valuesAsMicroseconds.length - 1;
-            }
-            percentiles[i] = valuesAsMicroseconds[index];
-        }
-
-        return new DistributionStatistics(valuesAsMicroseconds.length, percentiles, average, standardDeviation);
-    }
-
-    public int getCount() {
-        return count;
-    }
-
-    public double getAverage() {
-        return average;
-    }
-
-    public double getStandardDeviation() {
-        return standardDeviation;
-    }
-
-    public double getMinimum() {
-        return percentiles[MINIMUM];
-    }
-
-    public double get25thPercentile() {
-        return percentiles[PERCENTILE_25TH];
-    }
-
-    public double getMedian() {
-        return percentiles[MEDIAN];
-    }
-
-    public double get75thPercentile() {
-        return percentiles[PERCENTILE_75TH];
-    }
-
-    public double get90thPercentile() {
-        return percentiles[PERCENTILE_90TH];
-    }
-
-    public double get95thPercentile() {
-        return percentiles[PERCENTILE_95TH];
-    }
-
-    public double get99thPercentile() {
-        return percentiles[PERCENTILE_99TH];
-    }
-
-    public double getMaximum() {
-        return percentiles[MAXIMUM];
-    }
-
-    @Override
-    public String toString() {
-        return "in milliseconds [min=" + TimeUnit.MICROSECONDS.toMillis((long) getMinimum()) + ", "
-               + "25th=" + TimeUnit.MICROSECONDS.toMillis((long) get25thPercentile()) + ", "
-               + "median=" + TimeUnit.MICROSECONDS.toMillis((long) getMedian()) + ", "
-               + "avg=" + TimeUnit.MICROSECONDS.toMillis((long) getAverage()) + ", "
-               + "75th=" + TimeUnit.MICROSECONDS.toMillis((long) get75thPercentile()) + ", "
-               + "90th=" + TimeUnit.MICROSECONDS.toMillis((long) get90thPercentile()) + ", "
-               + "95th=" + TimeUnit.MICROSECONDS.toMillis((long) get95thPercentile()) + ", "
-               + "99th=" + TimeUnit.MICROSECONDS.toMillis((long) get99thPercentile()) + ", "
-               + "max=" + TimeUnit.MICROSECONDS.toMillis((long) getMaximum()) + "]";
-    }
-
-    public Map<String, Integer> toMap() {
-        Map<String, Integer> distMap = new LinkedHashMap<>();
-        distMap.put("Minimum Latency (microseconds)", (int) getMinimum());
-        distMap.put("25th Percentile Latency (microseconds)", (int) get25thPercentile());
-        distMap.put("Median Latency (microseconds)", (int) getMedian());
-        distMap.put("Average Latency (microseconds)", (int) getAverage());
-        distMap.put("75th Percentile Latency (microseconds)", (int) get75thPercentile());
-        distMap.put("90th Percentile Latency (microseconds)", (int) get90thPercentile());
-        distMap.put("95th Percentile Latency (microseconds)", (int) get95thPercentile());
-        distMap.put("99th Percentile Latency (microseconds)", (int) get99thPercentile());
-        distMap.put("Maximum Latency (microseconds)", (int) getMaximum());
-        return distMap;
-    }
-}
diff --git a/src/main/java/com/oltpbenchmark/LatencyRecord.java b/src/main/java/com/oltpbenchmark/LatencyRecord.java
deleted file mode 100644
index 3afb6093..00000000
--- a/src/main/java/com/oltpbenchmark/LatencyRecord.java
+++ /dev/null
@@ -1,198 +0,0 @@
-/*
- * Copyright 2020 by OLTPBenchmark Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- *
- */
-
-
-package com.oltpbenchmark;
-
-import java.util.ArrayList;
-import java.util.Iterator;
-
-/**
- * Efficiently stores a record of (start time, latency) pairs.
- */
-public class LatencyRecord implements Iterable<LatencyRecord.Sample> {
-    /**
-     * Allocate space for 500k samples at a time
-     */
-    static final int ALLOC_SIZE = 500000;
-
-    /**
-     * Contains (start time, latency, transactionType, workerid, phaseid) pentiplets
-     * in microsecond form. The start times are "compressed" by encoding them as
-     * increments, starting from startNs. A 32-bit integer provides sufficient resolution
-     * for an interval of 2146 seconds, or 35 minutes.
-     */
-    private final ArrayList<Sample[]> values = new ArrayList<>();
-    private int nextIndex;
-
-    private final long startNanosecond;
-    private long lastNanosecond;
-
-    public LatencyRecord(long startNanosecond) {
-        this.startNanosecond = startNanosecond;
-        this.lastNanosecond = startNanosecond;
-        allocateChunk();
-
-    }
-
-    public void addLatency(int transType, long startNanosecond, long endNanosecond, int workerId, int phaseId) {
-        addLatency(transType, startNanosecond, endNanosecond, workerId, phaseId, true);
-    }
-
-    public void addLatency(int transType, long startNanosecond, long endNanosecond, int workerId, int phaseId, boolean isSuccess) {
-
-        if (nextIndex == ALLOC_SIZE) {
-            allocateChunk();
-        }
-        Sample[] chunk = values.get(values.size() - 1);
-
-        long startOffsetNanosecond = (startNanosecond - lastNanosecond + 500);
-
-        int latencyMicroseconds = (int) ((endNanosecond - startNanosecond + 500) / 1000);
-
-
-        chunk[nextIndex] = new Sample(transType, startOffsetNanosecond, latencyMicroseconds, workerId, phaseId, isSuccess);
-        ++nextIndex;
-
-        lastNanosecond += startOffsetNanosecond;
-    }
-
-    private void allocateChunk() {
-        values.add(new Sample[ALLOC_SIZE]);
-        nextIndex = 0;
-    }
-
-    /**
-     * Returns the number of recorded samples.
-     */
-    public int size() {
-        // Samples stored in full chunks
-        int samples = (values.size() - 1) * ALLOC_SIZE;
-
-        // Samples stored in the last not full chunk
-        samples += nextIndex;
-        return samples;
-    }
-
-    /**
-     * Stores the start time and latency for a single sample. Immutable.
-     */
-    public static final class Sample implements Comparable<Sample> {
-        private final int transactionType;
-        private long startNanosecond;
-        private final int latencyMicrosecond;
-        private final int workerId;
-        private final int phaseId;
-        private final boolean isSuccess;
-
-        public Sample(int transactionType, long startNanosecond, int latencyMicrosecond, int workerId, int phaseId) {
-            this(transactionType, startNanosecond, latencyMicrosecond, workerId, phaseId, true);
-        }
-
-        public  Sample(int transactionType, long startNanosecond, int latencyMicrosecond, int workerId, int phaseId, boolean isSuccess) {
-            this.transactionType = transactionType;
-            this.startNanosecond = startNanosecond;
-            this.latencyMicrosecond = latencyMicrosecond;
-            this.workerId = workerId;
-            this.phaseId = phaseId;
-            this.isSuccess = isSuccess;
-        }
-
-        public int getTransactionType() {
-            return transactionType;
-        }
-
-        public long getStartNanosecond() {
-            return startNanosecond;
-        }
-
-        public int getLatencyMicrosecond() {
-            return latencyMicrosecond;
-        }
-
-        public int getWorkerId() {
-            return workerId;
-        }
-
-        public int getPhaseId() {
-            return phaseId;
-        }
-
-        public boolean isSuccess() {
-            return isSuccess;
-        }
-
-        @Override
-        public int compareTo(Sample other) {
-            long diff = this.startNanosecond - other.startNanosecond;
-
-            // explicit comparison to avoid long to int overflow
-            if (diff > 0) {
-                return 1;
-            } else if (diff < 0) {
-                return -1;
-            } else {
-
-                return 0;
-            }
-        }
-    }
-
-    private final class LatencyRecordIterator implements Iterator<Sample> {
-        private int chunkIndex = 0;
-        private int subIndex = 0;
-        private long lastIteratorNanosecond = startNanosecond;
-
-        @Override
-        public boolean hasNext() {
-            if (chunkIndex < values.size() - 1) {
-                return true;
-            }
-            return subIndex < nextIndex;
-        }
-
-        @Override
-        public Sample next() {
-            Sample[] chunk = values.get(chunkIndex);
-            Sample s = chunk[subIndex];
-
-            // Iterate in chunk, and wrap to next one
-            ++subIndex;
-
-            if (subIndex == ALLOC_SIZE) {
-                chunkIndex += 1;
-                subIndex = 0;
-            }
-
-            // Previously, s.startNs was just an offset from the previous
-            // value.  Now we make it an absolute.
-            s.startNanosecond += lastIteratorNanosecond;
-            lastIteratorNanosecond = s.startNanosecond;
-
-            return s;
-        }
-
-        @Override
-        public void remove() {
-            throw new UnsupportedOperationException("remove is not supported");
-        }
-    }
-
-    public Iterator<Sample> iterator() {
-        return new LatencyRecordIterator();
-    }
-}
diff --git a/src/main/java/com/oltpbenchmark/ResultStats.java b/src/main/java/com/oltpbenchmark/ResultStats.java
new file mode 100644
index 00000000..d38ef008
--- /dev/null
+++ b/src/main/java/com/oltpbenchmark/ResultStats.java
@@ -0,0 +1,288 @@
+/*
+ * Copyright 2020 by OLTPBenchmark Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+
+package com.oltpbenchmark;
+
+import com.oltpbenchmark.api.TransactionTypes;
+
+import java.util.Arrays;
+
+public class ResultStats {
+    TransactionTypes transactionTypes;
+
+    int transactionTypeCount;
+    TransactionStats[] transactionStats;
+
+    public ResultStats() {
+    }
+
+    public ResultStats(TransactionTypes transactionTypes) {
+        this.transactionTypes = transactionTypes;
+        this.transactionTypeCount = transactionTypes.size();
+        assert (this.transactionTypeCount > 0);
+
+        this.transactionStats = new TransactionStats[this.transactionTypeCount];
+        for (int i = 0; i < transactionTypeCount; i++) {
+            transactionStats[i] = new TransactionStats();
+        }
+    }
+
+    public void addLatency(int transType, long startNanosecond, long endNanosecond, boolean isSuccess) {
+        assert (transType < transactionTypeCount);
+        transactionStats[transType].addLatency(startNanosecond, endNanosecond, isSuccess);
+    }
+
+    public void add(ResultStats another) {
+        if (this.transactionTypeCount == 0) {
+            this.transactionTypes = another.transactionTypes;
+            this.transactionTypeCount = another.transactionTypeCount;
+            this.transactionStats = another.transactionStats;
+            return;
+        }
+
+        assert (this.transactionTypeCount == another.transactionTypeCount);
+
+        for (int i = 0; i < transactionTypeCount; i++) {
+            transactionStats[i].add(another.transactionStats[i]);
+        }
+    }
+
+    public long count() {
+        long total = 0;
+        for (int i = 0; i < transactionTypeCount; i++) {
+            total += transactionStats[i].count();
+        }
+
+        return total;
+    }
+
+    public long getSuccessCount(int transType) {
+        assert (transType < transactionTypeCount);
+        return transactionStats[transType].getSuccessCount();
+    }
+
+    public String toJson() {
+        StringBuilder json = new StringBuilder();
+        json.append("{");
+
+        for (int i = 0; i < transactionTypeCount; i++) {
+            if (i != 0) {
+                json.append(",\"");
+            } else {
+                json.append("\"");
+            }
+            json.append(transactionTypes.getType(i).getName());
+            json.append("\": ");
+            json.append(transactionStats[i].toJson());
+        }
+
+        json.append("}");
+        return json.toString();
+    }
+
+    @Override
+    public String toString() {
+        StringBuilder reprStr = new StringBuilder();
+        for (int i = 0; i < transactionTypeCount; i++) {
+            reprStr.append("\n");
+            reprStr.append(transactionTypes.getType(i).getName());
+            reprStr.append(":\n");
+            reprStr.append(transactionStats[i].toString());
+        }
+
+        return reprStr.toString();
+    }
+
+    public class Histogram {
+        private int[] bucketlist;
+        private int[] buckets;
+
+        public Histogram() {
+            // note, that because 5000 is here, we can calculate precisely number of transactions below
+            // this value.
+            this(new int[]{1, 5, 10, 50, 100, 500, 1000, 2000, 3000, 4000, 4500, 5000, 6000, 10000});
+        }
+
+        public Histogram(int[] bucketlist) {
+            Arrays.sort(bucketlist);
+            this.bucketlist = bucketlist;
+            this.buckets = new int[bucketlist.length + 1];
+        }
+
+        public void add(int value) {
+            int i = Arrays.binarySearch(bucketlist, value);
+            if (i < 0) {
+                i = -i - 1;
+            } else {
+                i += 1;
+            }
+            buckets[i]++;
+        }
+
+        public int count(int value) {
+            int i = Arrays.binarySearch(bucketlist, value);
+            if (i < 0) {
+                i = -i - 1;
+            } else {
+                i += 1;
+            }
+            return buckets[i];
+        }
+
+        public int totalCount() {
+            return Arrays.stream(buckets).sum();
+        }
+
+        public String percentile(double percentile) {
+            int total = totalCount();
+            int cumulative = 0;
+            for (int i = 0; i < buckets.length; i++) {
+                cumulative += buckets[i];
+                if ((double) cumulative / total >= percentile / 100.0) {
+                    return i != 0 ? Integer.toString(bucketlist[i - 1]) : "<" + bucketlist[0];
+                }
+            }
+            return ">= " + bucketlist[bucketlist.length - 1];
+        }
+
+        public void add(Histogram another) {
+            if (another.bucketlist.length != this.bucketlist.length) {
+                throw new IllegalArgumentException("Bucketlists must be of the same length");
+            }
+
+            for (int i = 0; i < this.bucketlist.length; i++) {
+                if (this.bucketlist[i] != another.bucketlist[i]) {
+                    throw new IllegalArgumentException("Bucketlists must have the same values");
+                }
+            }
+
+            for (int i = 0; i < this.buckets.length; i++) {
+                this.buckets[i] += another.buckets[i];
+            }
+        }
+
+        public String toJson() {
+            StringBuilder json = new StringBuilder();
+            json.append("{");
+
+            // Add bucketlist array to JSON
+            json.append("\"bucketlist\": [");
+            for (int i = 0; i < bucketlist.length; i++) {
+                json.append(bucketlist[i]);
+                if (i < bucketlist.length - 1) {
+                    json.append(", ");
+                }
+            }
+            json.append("], ");
+
+            // Add buckets array to JSON
+            json.append("\"buckets\": [");
+            for (int i = 0; i < buckets.length; i++) {
+                json.append(buckets[i]);
+                if (i < buckets.length - 1) {
+                    json.append(", ");
+                }
+            }
+            json.append("]");
+
+            json.append("}");
+            return json.toString();
+        }
+
+        @Override
+        public String toString() {
+            StringBuilder reprStr = new StringBuilder();
+            for (int i = 0; i < buckets.length; i++) {
+                if (i == 0) {
+                    reprStr.append("<").append(bucketlist[0]).append(": ").append(buckets[i]).append(", ");
+                } else if (i == buckets.length - 1) {
+                    reprStr.append(">=").append(bucketlist[i - 1]).append(": ").append(buckets[i]);
+                } else {
+                    reprStr.append(bucketlist[i - 1]).append("-").append(bucketlist[i]).append(": ").append(buckets[i]).append(", ");
+                }
+            }
+            return reprStr.toString();
+        }
+    }
+
+    public class TransactionStats {
+        long successCount;
+        long failedCount;
+
+        Histogram latencyHistogramMs;
+
+        public TransactionStats() {
+            this.latencyHistogramMs = new Histogram();
+        }
+
+        public void addLatency(long startNanosecond, long endNanosecond, boolean isSuccess) {
+            latencyHistogramMs.add((int) ((endNanosecond - startNanosecond) / 1000));
+
+            if (isSuccess) {
+                successCount++;
+            } else {
+                failedCount++;
+            }
+        }
+
+        public void add(TransactionStats another) {
+            this.successCount += another.successCount;
+            this.failedCount += another.failedCount;
+            this.latencyHistogramMs.add(another.latencyHistogramMs);
+        }
+
+        public long count() {
+            return successCount + failedCount;
+        }
+
+        public long getSuccessCount() {
+            return successCount;
+        }
+
+        public String toJson() {
+            StringBuilder json = new StringBuilder();
+            json.append("{");
+
+            // Add SuccessCount to JSON
+            json.append("\"SuccessCount\": ").append(successCount).append(", ");
+
+            // Add FailureCount to JSON
+            json.append("\"FailureCount\": ").append(failedCount).append(", ");
+
+            // Add LatencyHistogramMs to JSON
+            json.append("\"LatencyHistogramMs\": ").append(latencyHistogramMs.toJson());
+
+            json.append("}");
+            return json.toString();
+        }
+
+        @Override
+        public String toString() {
+            StringBuilder reprStr = new StringBuilder();
+            reprStr.append("Success: ");
+            reprStr.append(successCount);
+            reprStr.append("\nFailed: ");
+            reprStr.append(failedCount);
+            reprStr.append("\nLatency histogram, ms:\n");
+            reprStr.append(latencyHistogramMs.toString());
+
+            return reprStr.toString();
+        }
+    }
+
+}
diff --git a/src/main/java/com/oltpbenchmark/Results.java b/src/main/java/com/oltpbenchmark/Results.java
index 32a8bf5d..0652fdc9 100644
--- a/src/main/java/com/oltpbenchmark/Results.java
+++ b/src/main/java/com/oltpbenchmark/Results.java
@@ -18,7 +18,7 @@
 
 package com.oltpbenchmark;
 
-import com.oltpbenchmark.LatencyRecord.Sample;
+import com.oltpbenchmark.ResultStats;
 import com.oltpbenchmark.api.TransactionType;
 import com.oltpbenchmark.util.Histogram;
 
@@ -29,9 +29,8 @@
 public final class Results {
 
     private final long nanoseconds;
-    private final int measuredRequests;
-    private final DistributionStatistics distributionStatistics;
-    private final List<LatencyRecord.Sample> latencySamples;
+    private final long measuredRequests;
+    private final ResultStats resultStats;
     private final Histogram<TransactionType> unknown = new Histogram<>(false);
     private final Histogram<TransactionType> success = new Histogram<>(true);
     private final Histogram<TransactionType> abort = new Histogram<>(false);
@@ -40,22 +39,10 @@ public final class Results {
     private final Histogram<TransactionType> retryDifferent = new Histogram<>(false);
     private final Map<TransactionType, Histogram<String>> abortMessages = new HashMap<>();
 
-    public Results(long nanoseconds, int measuredRequests, DistributionStatistics distributionStatistics, final List<LatencyRecord.Sample> latencySamples) {
+    public Results(long nanoseconds, long measuredRequests, ResultStats resultStats) {
         this.nanoseconds = nanoseconds;
         this.measuredRequests = measuredRequests;
-        this.distributionStatistics = distributionStatistics;
-
-        if (distributionStatistics == null) {
-            this.latencySamples = null;
-        } else {
-            // defensive copy
-            this.latencySamples = List.copyOf(latencySamples);
-
-        }
-    }
-
-    public DistributionStatistics getDistributionStatistics() {
-        return distributionStatistics;
+        this.resultStats = resultStats;
     }
 
     public Histogram<TransactionType> getSuccess() {
@@ -94,15 +81,15 @@ public double requestsPerSecondGoodput() {
         return (double) success.getSampleCount() / (double) nanoseconds * 1e9;
     }
 
-    public List<Sample> getLatencySamples() {
-        return latencySamples;
+    public ResultStats getStats() {
+        return resultStats;
     }
 
     public long getNanoseconds() {
         return nanoseconds;
     }
 
-    public int getMeasuredRequests() {
+    public long getMeasuredRequests() {
         return measuredRequests;
     }
 
diff --git a/src/main/java/com/oltpbenchmark/ThreadBench.java b/src/main/java/com/oltpbenchmark/ThreadBench.java
index a7f98087..37d7b0cb 100644
--- a/src/main/java/com/oltpbenchmark/ThreadBench.java
+++ b/src/main/java/com/oltpbenchmark/ThreadBench.java
@@ -17,7 +17,7 @@
 
 package com.oltpbenchmark;
 
-import com.oltpbenchmark.LatencyRecord.Sample;
+import com.oltpbenchmark.ResultStats;
 import com.oltpbenchmark.api.BenchmarkModule;
 import com.oltpbenchmark.api.TransactionType;
 import com.oltpbenchmark.api.Worker;
@@ -36,7 +36,7 @@ public class ThreadBench implements Thread.UncaughtExceptionHandler {
     private final List<? extends Worker<? extends BenchmarkModule>> workers;
     private final ArrayList<Thread> workerThreads;
     private final List<WorkloadConfiguration> workConfs;
-    private final ArrayList<LatencyRecord.Sample> samples = new ArrayList<>();
+    private final ResultStats resultStats;
     private final int intervalMonitor;
 
     private ThreadBench(List<? extends Worker<? extends BenchmarkModule>> workers,
@@ -46,6 +46,7 @@ private ThreadBench(List<? extends Worker<? extends BenchmarkModule>> workers,
         this.workerThreads = new ArrayList<>(workers.size());
         this.intervalMonitor = intervalMonitoring;
         this.testState = new BenchmarkState(workers.size() + 1);
+        this.resultStats = new ResultStats();
     }
 
     public static Results runRateLimitedBenchmark(List<Worker<? extends BenchmarkModule>> workers,
@@ -71,9 +72,9 @@ private void interruptWorkers() {
         }
     }
 
-    private int finalizeWorkers(ArrayList<Thread> workerThreads) throws InterruptedException {
+    private long finalizeWorkers(ArrayList<Thread> workerThreads) throws InterruptedException {
 
-        int requests = 0;
+        long requests = 0;
 
         new WatchDogThread().start();
 
@@ -296,25 +297,13 @@ private Results runRateLimitedMultiPhase() {
         }
 
         try {
-            int requests = finalizeWorkers(this.workerThreads);
+            long requests = finalizeWorkers(this.workerThreads);
 
-            // Combine all the latencies together in the most disgusting way
-            // possible: sorting!
             for (Worker<?> w : workers) {
-                for (LatencyRecord.Sample sample : w.getLatencyRecords()) {
-                    samples.add(sample);
-                }
-            }
-            Collections.sort(samples);
-
-            // Compute stats on all the latencies
-            int[] latencies = new int[samples.size()];
-            for (int i = 0; i < samples.size(); ++i) {
-                latencies[i] = samples.get(i).getLatencyMicrosecond();
+                resultStats.add(w.getStats());
             }
-            DistributionStatistics stats = DistributionStatistics.computeStatistics(latencies);
 
-            Results results = new Results(measureEnd - start, requests, stats, samples);
+            Results results = new Results(measureEnd - start, requests, resultStats);
 
             // Compute transaction histogram
             Set<TransactionType> txnTypes = new HashSet<>();
@@ -377,116 +366,6 @@ public void uncaughtException(Thread t, Throwable e) {
         }
     }
 
-    public static final class TimeBucketIterable implements Iterable<DistributionStatistics> {
-        private final Iterable<Sample> samples;
-        private final int windowSizeSeconds;
-        private final TransactionType transactionType;
-
-        /**
-         * @param samples
-         * @param windowSizeSeconds
-         * @param transactionType   Allows to filter transactions by type
-         */
-        public TimeBucketIterable(Iterable<Sample> samples, int windowSizeSeconds, TransactionType transactionType) {
-            this.samples = samples;
-            this.windowSizeSeconds = windowSizeSeconds;
-            this.transactionType = transactionType;
-        }
-
-        @Override
-        public Iterator<DistributionStatistics> iterator() {
-            return new TimeBucketIterator(samples.iterator(), windowSizeSeconds, transactionType);
-        }
-    }
-
-    private static final class TimeBucketIterator implements Iterator<DistributionStatistics> {
-        private final Iterator<Sample> samples;
-        private final int windowSizeSeconds;
-        private final TransactionType txType;
-
-        private Sample sample;
-        private long nextStartNanosecond;
-
-        private DistributionStatistics next;
-
-        /**
-         * @param samples
-         * @param windowSizeSeconds
-         * @param txType            Allows to filter transactions by type
-         */
-        public TimeBucketIterator(Iterator<LatencyRecord.Sample> samples, int windowSizeSeconds,
-                TransactionType txType) {
-            this.samples = samples;
-            this.windowSizeSeconds = windowSizeSeconds;
-            this.txType = txType;
-
-            if (samples.hasNext()) {
-                sample = samples.next();
-                // TODO: To be totally correct, we would want this to be the
-                // timestamp of the start
-                // of the measurement interval. In most cases this won't matter.
-                nextStartNanosecond = sample.getStartNanosecond();
-                calculateNext();
-            }
-        }
-
-        private void calculateNext() {
-
-            // Collect all samples in the time window
-            ArrayList<Integer> latencies = new ArrayList<>();
-            long endNanoseconds = nextStartNanosecond + (windowSizeSeconds * 1000000000L);
-            while (sample != null && sample.getStartNanosecond() < endNanoseconds) {
-
-                // Check if a TX Type filter is set, in the default case,
-                // INVALID TXType means all should be reported, if a filter is
-                // set, only this specific transaction
-                if (txType.equals(TransactionType.INVALID) || txType.getId() == sample.getTransactionType()) {
-                    latencies.add(sample.getLatencyMicrosecond());
-                }
-
-                if (samples.hasNext()) {
-                    sample = samples.next();
-                } else {
-                    sample = null;
-                }
-            }
-
-            // Set up the next time window
-
-            nextStartNanosecond = endNanoseconds;
-
-            int[] l = new int[latencies.size()];
-            for (int i = 0; i < l.length; ++i) {
-                l[i] = latencies.get(i);
-            }
-
-            next = DistributionStatistics.computeStatistics(l);
-        }
-
-        @Override
-        public boolean hasNext() {
-            return next != null;
-        }
-
-        @Override
-        public DistributionStatistics next() {
-            if (next == null) {
-                throw new NoSuchElementException();
-            }
-            DistributionStatistics out = next;
-            next = null;
-            if (sample != null) {
-                calculateNext();
-            }
-            return out;
-        }
-
-        @Override
-        public void remove() {
-            throw new UnsupportedOperationException("unsupported");
-        }
-    }
-
     private class WatchDogThread extends Thread {
         {
             this.setDaemon(true);
diff --git a/src/main/java/com/oltpbenchmark/api/Worker.java b/src/main/java/com/oltpbenchmark/api/Worker.java
index ee850733..08d36a76 100644
--- a/src/main/java/com/oltpbenchmark/api/Worker.java
+++ b/src/main/java/com/oltpbenchmark/api/Worker.java
@@ -43,7 +43,7 @@ public abstract class Worker<T extends BenchmarkModule> implements Runnable {
     private static final Logger ABORT_LOG = LoggerFactory.getLogger("com.oltpbenchmark.api.ABORT_LOG");
 
     private WorkloadState workloadState;
-    private LatencyRecord latencies;
+    private ResultStats resultStats;
     private final Statement currStatement;
 
     // Interval requests used by the monitor
@@ -74,6 +74,7 @@ public Worker(T benchmark, int id) {
         this.workloadState = this.configuration.getWorkloadState();
         this.currStatement = null;
         this.transactionTypes = this.configuration.getTransTypes();
+        this.resultStats = new ResultStats(this.transactionTypes);
 
         if (!this.configuration.getNewConnectionPerTxn()) {
             try {
@@ -121,16 +122,16 @@ public final Random rng() {
         return (this.benchmark.rng());
     }
 
-    public final int getRequests() {
-        return latencies.size();
+    public final long getRequests() {
+        return resultStats.count();
     }
 
     public final int getAndResetIntervalRequests() {
         return intervalRequests.getAndSet(0);
     }
 
-    public final Iterable<LatencyRecord.Sample> getLatencyRecords() {
-        return latencies;
+    public final ResultStats getStats() {
+        return resultStats;
     }
 
     public final Procedure getProcedure(TransactionType type) {
@@ -190,7 +191,7 @@ public final void run() {
         t.setName(this.toString());
 
         // In case of reuse reset the measurements
-        latencies = new LatencyRecord(workloadState.getTestStartNs());
+        resultStats = new ResultStats(this.transactionTypes);
 
         // Invoke initialize callback
         try {
@@ -325,12 +326,10 @@ public final void run() {
                         if (preState == MEASURE && postPhase.getId() == prePhase.getId()) {
                             boolean isSuccess = status == TransactionStatus.SUCCESS ||
                                 status == TransactionStatus.USER_ABORTED;
-                            latencies.addLatency(
+                            resultStats.addLatency(
                                 transactionType.getId(),
                                 start,
                                 end,
-                                this.id,
-                                prePhase.getId(),
                                 isSuccess);
                             intervalRequests.incrementAndGet();
                         }
diff --git a/src/main/java/com/oltpbenchmark/util/ResultWriter.java b/src/main/java/com/oltpbenchmark/util/ResultWriter.java
index 91e33923..245f55de 100644
--- a/src/main/java/com/oltpbenchmark/util/ResultWriter.java
+++ b/src/main/java/com/oltpbenchmark/util/ResultWriter.java
@@ -17,8 +17,7 @@
 
 package com.oltpbenchmark.util;
 
-import com.oltpbenchmark.DistributionStatistics;
-import com.oltpbenchmark.LatencyRecord;
+import com.oltpbenchmark.ResultStats;
 import com.oltpbenchmark.Results;
 import com.oltpbenchmark.ThreadBench;
 import com.oltpbenchmark.api.TransactionType;
@@ -106,7 +105,6 @@ public void writeSummary(PrintStream os) {
         summaryMap.put("DBMS Type", dbType);
         summaryMap.put("DBMS Version", collector.collectVersion());
         summaryMap.put("Benchmark Type", benchType);
-        summaryMap.put("Latency Distribution", results.getDistributionStatistics().toMap());
         summaryMap.put("Throughput (requests/second)", results.requestsPerSecondThroughput());
         summaryMap.put("Goodput (requests/second)", results.requestsPerSecondGoodput());
         for (String field : BENCHMARK_KEY_FIELD) {
@@ -115,119 +113,7 @@ public void writeSummary(PrintStream os) {
         os.println(JSONUtil.format(JSONUtil.toJSONString(summaryMap)));
     }
 
-    public void writeResults(int windowSizeSeconds, PrintStream out) {
-        writeResults(windowSizeSeconds, out, TransactionType.INVALID);
-    }
-
-    public void writeResults(int windowSizeSeconds, PrintStream out, TransactionType txType) {
-        String[] header = {
-                "Time (seconds)",
-                "Throughput (requests/second)",
-                "Average Latency (millisecond)",
-                "Minimum Latency (millisecond)",
-                "25th Percentile Latency (millisecond)",
-                "Median Latency (millisecond)",
-                "75th Percentile Latency (millisecond)",
-                "90th Percentile Latency (millisecond)",
-                "95th Percentile Latency (millisecond)",
-                "99th Percentile Latency (millisecond)",
-                "Maximum Latency (millisecond)",
-                "tp (req/s) scaled"
-        };
-        out.println(StringUtil.join(",", header));
-        int i = 0;
-        for (DistributionStatistics s : new ThreadBench.TimeBucketIterable(results.getLatencySamples(), windowSizeSeconds, txType)) {
-            out.printf("%d,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f\n",
-                    i * windowSizeSeconds,
-                    (double) s.getCount() / windowSizeSeconds,
-                    s.getAverage() / MILLISECONDS_FACTOR,
-                    s.getMinimum() / MILLISECONDS_FACTOR,
-                    s.get25thPercentile() / MILLISECONDS_FACTOR,
-                    s.getMedian() / MILLISECONDS_FACTOR,
-                    s.get75thPercentile() / MILLISECONDS_FACTOR,
-                    s.get90thPercentile() / MILLISECONDS_FACTOR,
-                    s.get95thPercentile() / MILLISECONDS_FACTOR,
-                    s.get99thPercentile() / MILLISECONDS_FACTOR,
-                    s.getMaximum() / MILLISECONDS_FACTOR,
-                    MILLISECONDS_FACTOR / s.getAverage());
-            i += 1;
-        }
-    }
-
-    public void writeSamples(PrintStream out) {
-        writeSamples(1, out, TransactionType.INVALID);
-    }
-
-    public void writeSamples(int windowSizeSeconds, PrintStream out, TransactionType txType) {
-        String[] header = {
-                "Time (seconds)",
-                "Requests",
-                "Throughput (requests/second)",
-                "Minimum Latency (microseconds)",
-                "25th Percentile Latency (microseconds)",
-                "Median Latency (microseconds)",
-                "Average Latency (microseconds)",
-                "75th Percentile Latency (microseconds)",
-                "90th Percentile Latency (microseconds)",
-                "95th Percentile Latency (microseconds)",
-                "99th Percentile Latency (microseconds)",
-                "Maximum Latency (microseconds)"
-        };
-        out.println(StringUtil.join(",", header));
-        int i = 0;
-        for (DistributionStatistics s : new ThreadBench.TimeBucketIterable(results.getLatencySamples(), windowSizeSeconds, txType)) {
-            out.printf("%d,%d,%.3f,%d,%d,%d,%d,%d,%d,%d,%d,%d\n",
-                    i * windowSizeSeconds,
-                    s.getCount(),
-                    (double) s.getCount() / windowSizeSeconds,
-                    (int) s.getMinimum(),
-                    (int) s.get25thPercentile(),
-                    (int) s.getMedian(),
-                    (int) s.getAverage(),
-                    (int) s.get75thPercentile(),
-                    (int) s.get90thPercentile(),
-                    (int) s.get95thPercentile(),
-                    (int) s.get99thPercentile(),
-                    (int) s.getMaximum());
-            i += 1;
-        }
-    }
-
     public void writeRaw(List<TransactionType> activeTXTypes, PrintStream out) {
-
-        // This is needed because nanTime does not guarantee offset... we
-        // ground it (and round it) to ms from 1970-01-01 like currentTime
-        double x = ((double) System.nanoTime() / (double) 1000000000);
-        double y = ((double) System.currentTimeMillis() / (double) 1000);
-        double offset = x - y;
-
-        // long startNs = latencySamples.get(0).startNs;
-        String[] header = {
-                "Transaction Type Index",
-                "Transaction Name",
-                "Start Time (microseconds)",
-                "Latency (microseconds)",
-                "Worker Id (start number)",
-                "Phase Id (index in config file)",
-                "IsSuccess"
-        };
-        out.println(StringUtil.join(",", header));
-        for (LatencyRecord.Sample s : results.getLatencySamples()) {
-            double startUs = ((double) s.getStartNanosecond() / (double) 1000000000);
-            String[] row = {
-                    Integer.toString(s.getTransactionType()),
-                    // Important!
-                    // The TxnType offsets start at 1!
-                    activeTXTypes.get(s.getTransactionType() - 1).getName(),
-                    String.format("%10.6f", startUs - offset),
-                    Integer.toString(s.getLatencyMicrosecond()),
-                    Integer.toString(s.getWorkerId()),
-                    Integer.toString(s.getPhaseId()),
-                    Boolean.toString(s.isSuccess()),
-            };
-            out.println(StringUtil.join(",", row));
-        }
+        out.println(results.getStats().toJson());
     }
-
-
 }
diff --git a/src/main/resources/log4j.properties b/src/main/resources/log4j.properties
index d75b2d38..71d7a524 100644
--- a/src/main/resources/log4j.properties
+++ b/src/main/resources/log4j.properties
@@ -10,7 +10,6 @@ log4j.appender.A1.layout.ConversionPattern=[%-5p] %d [%t] %x %c %M - %m%n
 log4j.logger.com.oltpbenchmark=INFO
 log4j.logger.com.oltpbenchmark.DBWorkload=INFO
 log4j.logger.com.oltpbenchmark.ThreadBench=INFO
-log4j.logger.com.oltpbenchmark.DistributionStatistics=INFO
 log4j.logger.com.oltpbenchmark.api.BenchmarkModule=INFO
 log4j.logger.com.oltpbenchmark.api.Loader=INFO
 log4j.logger.com.oltpbenchmark.api.Worker=INFO

From b29c36830c5cf1b79318933d68a055034761926f Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Mon, 4 Sep 2023 15:21:58 +0200
Subject: [PATCH 12/32] add a separate histogram for failed requests

---
 .../java/com/oltpbenchmark/ResultStats.java   | 27 +++++++++++--------
 1 file changed, 16 insertions(+), 11 deletions(-)

diff --git a/src/main/java/com/oltpbenchmark/ResultStats.java b/src/main/java/com/oltpbenchmark/ResultStats.java
index d38ef008..dff873e0 100644
--- a/src/main/java/com/oltpbenchmark/ResultStats.java
+++ b/src/main/java/com/oltpbenchmark/ResultStats.java
@@ -224,18 +224,21 @@ public class TransactionStats {
         long successCount;
         long failedCount;
 
-        Histogram latencyHistogramMs;
+        Histogram latencySuccessHistogramMs;
+        Histogram latencyFailedHistogramMs;
 
         public TransactionStats() {
-            this.latencyHistogramMs = new Histogram();
+            this.latencySuccessHistogramMs = new Histogram();
+            this.latencyFailedHistogramMs = new Histogram();
         }
 
         public void addLatency(long startNanosecond, long endNanosecond, boolean isSuccess) {
-            latencyHistogramMs.add((int) ((endNanosecond - startNanosecond) / 1000));
 
             if (isSuccess) {
+                latencySuccessHistogramMs.add((int) ((endNanosecond - startNanosecond) / 1000));
                 successCount++;
             } else {
+                latencyFailedHistogramMs.add((int) ((endNanosecond - startNanosecond) / 1000));
                 failedCount++;
             }
         }
@@ -243,7 +246,8 @@ public void addLatency(long startNanosecond, long endNanosecond, boolean isSucce
         public void add(TransactionStats another) {
             this.successCount += another.successCount;
             this.failedCount += another.failedCount;
-            this.latencyHistogramMs.add(another.latencyHistogramMs);
+            this.latencySuccessHistogramMs.add(another.latencySuccessHistogramMs);
+            this.latencyFailedHistogramMs.add(another.latencyFailedHistogramMs);
         }
 
         public long count() {
@@ -258,14 +262,11 @@ public String toJson() {
             StringBuilder json = new StringBuilder();
             json.append("{");
 
-            // Add SuccessCount to JSON
             json.append("\"SuccessCount\": ").append(successCount).append(", ");
-
-            // Add FailureCount to JSON
             json.append("\"FailureCount\": ").append(failedCount).append(", ");
 
-            // Add LatencyHistogramMs to JSON
-            json.append("\"LatencyHistogramMs\": ").append(latencyHistogramMs.toJson());
+            json.append("\"LatencySuccessHistogramMs\": ").append(latencySuccessHistogramMs.toJson());
+            json.append(", \"LatencyFailedHistogramMs\": ").append(latencyFailedHistogramMs.toJson());
 
             json.append("}");
             return json.toString();
@@ -278,8 +279,12 @@ public String toString() {
             reprStr.append(successCount);
             reprStr.append("\nFailed: ");
             reprStr.append(failedCount);
-            reprStr.append("\nLatency histogram, ms:\n");
-            reprStr.append(latencyHistogramMs.toString());
+
+            reprStr.append("\nLatency success histogram, ms:\n");
+            reprStr.append(latencySuccessHistogramMs.toString());
+
+            reprStr.append("\nLatency failed histogram, ms:\n");
+            reprStr.append(latencyFailedHistogramMs.toString());
 
             return reprStr.toString();
         }

From 1e6030cdb7c64f18d2a935dd27ead646267c5eb7 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Mon, 19 Jun 2023 14:58:23 +0200
Subject: [PATCH 13/32] Use virtual threads and Java 20

---
 pom.xml                                       |  9 ++--
 scripts/tpcc.sh                               | 41 ++++++++++---------
 .../java/com/oltpbenchmark/DBWorkload.java    | 11 +++--
 .../java/com/oltpbenchmark/ThreadBench.java   | 15 +++++--
 4 files changed, 47 insertions(+), 29 deletions(-)

diff --git a/pom.xml b/pom.xml
index 18f43b41..c4b483e6 100644
--- a/pom.xml
+++ b/pom.xml
@@ -12,9 +12,9 @@
 
     <properties>
         <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
-        <java.version>17</java.version>
-        <maven.compiler.source>17</maven.compiler.source>
-        <maven.compiler.target>17</maven.compiler.target>
+        <java.version>20</java.version>
+        <maven.compiler.source>20</maven.compiler.source>
+        <maven.compiler.target>20</maven.compiler.target>
         <buildDirectory>${project.basedir}/target</buildDirectory>
         <!--
             Provids a way to limit which assembly package formats we produce.
@@ -253,6 +253,9 @@
                 <configuration>
                     <source>${maven.compiler.source}</source>
                     <target>${maven.compiler.target}</target>
+                    <compilerArgs>
+                        --enable-preview
+                    </compilerArgs>
                 </configuration>
             </plugin>
             <plugin>
diff --git a/scripts/tpcc.sh b/scripts/tpcc.sh
index a326fa21..e389bb27 100755
--- a/scripts/tpcc.sh
+++ b/scripts/tpcc.sh
@@ -1,9 +1,6 @@
 #!/bin/bash
 
-export TZ=UTC
-export LC_ALL=en_US.UTF-8
-
-MEMORY='1G'
+memory='1G'
 
 args=()
 
@@ -16,26 +13,32 @@ while [[ "$#" > 0 ]]; do case $1 in
         ;;
 esac; shift; done
 
-if [[ -z $memory ]]; then
-    memory=$MEMORY
-fi
+min_java_version=20
 
 if command -v java >/dev/null; then
-    java_version=$(java -version 2>&1 | awk -F '"' '/version/ {print $2}')
-    if [[ $java_version = "17"* ]]; then
+    java_version=$(java -version 2>&1 | awk -F '"' '/version/ {print $2}' | awk -F '.' '{print $1}')
+
+    if [[ $java_version -ge $min_java_version ]]; then
         java="java"
     fi
 fi
 
-if [[ -z $java ]]; then
-    if [[ -e "/usr/lib/jvm/java-17-openjdk-amd64/bin/java" ]]; then
-        java="/usr/lib/jvm/java-17-openjdk-amd64/bin/java"
-    elif [[ -e "/usr/lib/jvm/java-17/bin/java" ]]; then
-        java="/usr/lib/jvm/java-17/bin/java"
-    else
-        echo "Java 17 is required to run this script."
-        exit 1
-    fi
+if [[ -z "$java" ]]; then
+    for d in /usr/lib/jvm/*${min_java_version}*; do
+        java_check="$d/bin/java"
+        if [[ -x $java_check ]]; then
+            java_version=$($java_check -version 2>&1 | awk -F '"' '/version/ {print $2}' | awk -F '.' '{print $1}')
+            if [[ $java_version -ge $min_java_version ]]; then
+                java=$java_check
+                break
+            fi
+        fi
+    done
+fi
+
+if [[ -z "$java" ]]; then
+    echo "No Java $java_version found"
+    exit 1
 fi
 
-$java -Xmx$memory -jar benchbase.jar -b tpcc "${args[@]}"
+$java --enable-preview -Xmx$memory -jar benchbase.jar -b tpcc "${args[@]}"
diff --git a/src/main/java/com/oltpbenchmark/DBWorkload.java b/src/main/java/com/oltpbenchmark/DBWorkload.java
index 394c896b..a1712068 100644
--- a/src/main/java/com/oltpbenchmark/DBWorkload.java
+++ b/src/main/java/com/oltpbenchmark/DBWorkload.java
@@ -59,6 +59,8 @@ public class DBWorkload {
     private static int numWarehouses = 10;
     private static int time = 0;
 
+    private static Boolean useRealThreads = false;
+
     /**
      * @param args
      * @throws Exception
@@ -99,6 +101,10 @@ public static void main(String[] args) throws Exception {
             startFromId = Integer.parseInt(argsLine.getOptionValue("sf"));
         }
 
+        if (argsLine.hasOption("rt")) {
+            useRealThreads = true;
+        }
+
         // -------------------------------------------------------------------
         // GET PLUGIN LIST
         // -------------------------------------------------------------------
@@ -516,6 +522,7 @@ private static Options buildOptions(XMLConfiguration pluginConfig) {
         options.addOption(null, "dialects-export", true, "Export benchmark SQL to a dialects file");
         options.addOption("jh", "json-histograms", true, "Export histograms to JSON file");
         options.addOption("sf", "start-from-id", true, "Start from a specific scale instance id");
+        options.addOption("rt", "real-threads", false, "Use real threads");
         return options;
     }
 
@@ -646,9 +653,7 @@ private static Results runWorkload(List<BenchmarkModule> benchList, int interval
             workConfs.add(bench.getWorkloadConfiguration());
 
         }
-        Results r = ThreadBench.runRateLimitedBenchmark(workers, workConfs, intervalMonitor);
-        LOG.info(SINGLE_LINE);
-        LOG.info("Rate limited reqs/s: {}", r);
+        Results r = ThreadBench.runRateLimitedBenchmark(workers, workConfs, intervalMonitor, useRealThreads);
         return r;
     }
 
diff --git a/src/main/java/com/oltpbenchmark/ThreadBench.java b/src/main/java/com/oltpbenchmark/ThreadBench.java
index 37d7b0cb..fca200ec 100644
--- a/src/main/java/com/oltpbenchmark/ThreadBench.java
+++ b/src/main/java/com/oltpbenchmark/ThreadBench.java
@@ -38,20 +38,22 @@ public class ThreadBench implements Thread.UncaughtExceptionHandler {
     private final List<WorkloadConfiguration> workConfs;
     private final ResultStats resultStats;
     private final int intervalMonitor;
+    private final Boolean useRealThreads;
 
     private ThreadBench(List<? extends Worker<? extends BenchmarkModule>> workers,
-            List<WorkloadConfiguration> workConfs, int intervalMonitoring) {
+            List<WorkloadConfiguration> workConfs, int intervalMonitoring, Boolean useRealThreads) {
         this.workers = workers;
         this.workConfs = workConfs;
         this.workerThreads = new ArrayList<>(workers.size());
         this.intervalMonitor = intervalMonitoring;
         this.testState = new BenchmarkState(workers.size() + 1);
         this.resultStats = new ResultStats();
+        this.useRealThreads = useRealThreads;
     }
 
     public static Results runRateLimitedBenchmark(List<Worker<? extends BenchmarkModule>> workers,
-            List<WorkloadConfiguration> workConfs, int intervalMonitoring) {
-        ThreadBench bench = new ThreadBench(workers, workConfs, intervalMonitoring);
+            List<WorkloadConfiguration> workConfs, int intervalMonitoring, Boolean useRealThreads) {
+        ThreadBench bench = new ThreadBench(workers, workConfs, intervalMonitoring, useRealThreads);
         return bench.runRateLimitedMultiPhase();
     }
 
@@ -59,7 +61,12 @@ private void createWorkerThreads() {
 
         for (Worker<?> worker : workers) {
             worker.initializeState();
-            Thread thread = new Thread(worker);
+            Thread thread;
+            if (useRealThreads) {
+                thread = new Thread(worker);
+            } else {
+                thread = Thread.ofVirtual().unstarted(worker);
+            }
             thread.setUncaughtExceptionHandler(this);
             thread.start();
             this.workerThreads.add(thread);

From 80bfa3077ea8c3978fb7e283764939251a6bf17f Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Tue, 5 Sep 2023 13:20:34 +0200
Subject: [PATCH 14/32] fix ns->ms conversion, cleanup

---
 src/main/java/com/oltpbenchmark/ResultStats.java | 12 +++++-------
 1 file changed, 5 insertions(+), 7 deletions(-)

diff --git a/src/main/java/com/oltpbenchmark/ResultStats.java b/src/main/java/com/oltpbenchmark/ResultStats.java
index dff873e0..af4b9b9a 100644
--- a/src/main/java/com/oltpbenchmark/ResultStats.java
+++ b/src/main/java/com/oltpbenchmark/ResultStats.java
@@ -108,7 +108,7 @@ public String toString() {
         return reprStr.toString();
     }
 
-    public class Histogram {
+    public static class Histogram {
         private int[] bucketlist;
         private int[] buckets;
 
@@ -180,7 +180,6 @@ public String toJson() {
             StringBuilder json = new StringBuilder();
             json.append("{");
 
-            // Add bucketlist array to JSON
             json.append("\"bucketlist\": [");
             for (int i = 0; i < bucketlist.length; i++) {
                 json.append(bucketlist[i]);
@@ -190,7 +189,6 @@ public String toJson() {
             }
             json.append("], ");
 
-            // Add buckets array to JSON
             json.append("\"buckets\": [");
             for (int i = 0; i < buckets.length; i++) {
                 json.append(buckets[i]);
@@ -220,7 +218,7 @@ public String toString() {
         }
     }
 
-    public class TransactionStats {
+    public static class TransactionStats {
         long successCount;
         long failedCount;
 
@@ -233,12 +231,12 @@ public TransactionStats() {
         }
 
         public void addLatency(long startNanosecond, long endNanosecond, boolean isSuccess) {
-
+            int deltaMs = (int) ((endNanosecond - startNanosecond) / 1000000);
             if (isSuccess) {
-                latencySuccessHistogramMs.add((int) ((endNanosecond - startNanosecond) / 1000));
+                latencySuccessHistogramMs.add(deltaMs);
                 successCount++;
             } else {
-                latencyFailedHistogramMs.add((int) ((endNanosecond - startNanosecond) / 1000));
+                latencyFailedHistogramMs.add(deltaMs);
                 failedCount++;
             }
         }

From 4b6e0f09841dea3e98c609dcc412bafc60f914e4 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Fri, 11 Aug 2023 18:23:49 +0200
Subject: [PATCH 15/32] use c3p0 for connections pulling

---
 pom.xml                                       |  5 +++
 .../java/com/oltpbenchmark/DBWorkload.java    |  1 +
 .../oltpbenchmark/WorkloadConfiguration.java  |  9 +++++
 .../oltpbenchmark/api/BenchmarkModule.java    | 36 ++++++++++++++-----
 4 files changed, 42 insertions(+), 9 deletions(-)

diff --git a/pom.xml b/pom.xml
index c4b483e6..54ff9dc7 100644
--- a/pom.xml
+++ b/pom.xml
@@ -73,6 +73,11 @@
                     <artifactId>postgresql</artifactId>
                     <version>42.6.0</version>
                 </dependency>
+                <dependency>
+                    <groupId>com.mchange</groupId>
+                    <artifactId>c3p0</artifactId>
+                    <version>0.9.5.5</version>
+                </dependency>
             </dependencies>
         </profile>
         <profile>
diff --git a/src/main/java/com/oltpbenchmark/DBWorkload.java b/src/main/java/com/oltpbenchmark/DBWorkload.java
index a1712068..abfa38e9 100644
--- a/src/main/java/com/oltpbenchmark/DBWorkload.java
+++ b/src/main/java/com/oltpbenchmark/DBWorkload.java
@@ -143,6 +143,7 @@ public static void main(String[] args) throws Exception {
             wrkld.setRandomSeed(xmlConfig.getInt("randomSeed", -1));
             wrkld.setBatchSize(xmlConfig.getInt("batchsize", 128));
             wrkld.setMaxRetries(xmlConfig.getInt("retries", 3));
+            wrkld.setMaxConnections(xmlConfig.getInt("maxConnections", wrkld.getMaxConnections()));
             wrkld.setNewConnectionPerTxn(xmlConfig.getBoolean("newConnectionPerTxn", false));
 
             int terminals = xmlConfig.getInt("terminals[not(@bench)]", 0);
diff --git a/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java b/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
index b088ee63..351803b7 100644
--- a/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
+++ b/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
@@ -36,6 +36,7 @@ public class WorkloadConfiguration {
     private String username;
     private String password;
     private String driverClass;
+    private int maxConnections = 100;
     private int batchSize;
     private int maxRetries;
     private int randomSeed = -1;
@@ -110,6 +111,14 @@ public void setDriverClass(String driverClass) {
         this.driverClass = driverClass;
     }
 
+    public int getMaxConnections() {
+        return maxConnections;
+    }
+
+    public void setMaxConnections(int maxConnections) {
+        this.maxConnections = maxConnections;
+    }
+
     public int getBatchSize() {
         return batchSize;
     }
diff --git a/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java b/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
index ddd0a6cc..231d179f 100644
--- a/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
+++ b/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
@@ -18,6 +18,7 @@
 
 package com.oltpbenchmark.api;
 
+import com.mchange.v2.c3p0.ComboPooledDataSource;
 import com.oltpbenchmark.WorkloadConfiguration;
 import com.oltpbenchmark.catalog.AbstractCatalog;
 import com.oltpbenchmark.types.DatabaseType;
@@ -42,6 +43,7 @@
 public abstract class BenchmarkModule {
     private static final Logger LOG = LoggerFactory.getLogger(BenchmarkModule.class);
 
+    private static ComboPooledDataSource dataSource;
 
     /**
      * The workload configuration for this benchmark invocation
@@ -72,6 +74,30 @@ public abstract class BenchmarkModule {
     public BenchmarkModule(WorkloadConfiguration workConf) {
         this.workConf = workConf;
         this.dialects = new StatementDialects(workConf);
+
+        if (dataSource == null) {
+            try {
+                dataSource = new ComboPooledDataSource();
+                dataSource.setDriverClass("org.postgresql.Driver");
+                dataSource.setJdbcUrl(workConf.getUrl());
+                dataSource.setUser(workConf.getUsername());
+                dataSource.setPassword(workConf.getPassword());
+
+                // Optional Settings
+                dataSource.setMinPoolSize(10);
+                dataSource.setInitialPoolSize(10);
+                dataSource.setAcquireIncrement(10);
+                dataSource.setMaxPoolSize(workConf.getMaxConnections());
+                dataSource.setMaxStatements(workConf.getMaxConnections());
+
+                Runtime.getRuntime().addShutdownHook(new Thread(() -> {
+                    dataSource.close();
+                }));
+            } catch (Exception e) {
+                LOG.error("Unable to initialize DataSource: %s", e.toString());
+                throw new RuntimeException("Unable to initialize DataSource", e);
+            }
+        }
     }
 
     // --------------------------------------------------------------------------
@@ -79,15 +105,7 @@ public BenchmarkModule(WorkloadConfiguration workConf) {
     // --------------------------------------------------------------------------
 
     public final Connection makeConnection() throws SQLException {
-
-        if (StringUtils.isEmpty(workConf.getUsername())) {
-            return DriverManager.getConnection(workConf.getUrl());
-        } else {
-            return DriverManager.getConnection(
-                    workConf.getUrl(),
-                    workConf.getUsername(),
-                    workConf.getPassword());
-        }
+        return dataSource.getConnection();
     }
 
     // --------------------------------------------------------------------------

From fcb8da0bdd709f59c7eb15d87d487beda5875397 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Fri, 10 Nov 2023 17:41:45 +0100
Subject: [PATCH 16/32] Remove obsolete README content

---
 README.md | 288 +-----------------------------------------------------
 1 file changed, 1 insertion(+), 287 deletions(-)

diff --git a/README.md b/README.md
index 801a3abd..02256e41 100644
--- a/README.md
+++ b/README.md
@@ -1,287 +1 @@
-# BenchBase
-
-[![BenchBase (Java with Maven)](https://github.com/cmu-db/benchbase/actions/workflows/maven.yml/badge.svg?branch=main)](https://github.com/cmu-db/benchbase/actions/workflows/maven.yml)
-
-BenchBase (formerly [OLTPBench](https://github.com/oltpbenchmark/oltpbench/)) is a Multi-DBMS SQL Benchmarking Framework via JDBC.
-
-**Table of Contents**
-
-- [Quickstart](#quickstart)
-- [Description](#description)
-- [Usage Guide](#usage-guide)
-- [Contributing](#contributing)
-- [Known Issues](#known-issues)
-- [Credits](#credits)
-- [Citing This Repository](#citing-this-repository)
-
----
-
-## Quickstart
-
-To clone and build BenchBase using the `postgres` profile,
-
-```bash
-git clone --depth 1 https://github.com/cmu-db/benchbase.git
-cd benchbase
-./mvnw clean package -P postgres
-```
-
-This produces artifacts in the `target` folder, which can be extracted,
-
-```bash
-cd target
-tar xvzf benchbase-postgres.tgz
-cd benchbase-postgres
-```
-
-Inside this folder, you can run BenchBase. For example, to execute the `tpcc` benchmark,
-
-```bash
-java -jar benchbase.jar -b tpcc -c config/postgres/sample_tpcc_config.xml --create=true --load=true --execute=true
-```
-
-A full list of options can be displayed,
-
-```bash
-java -jar benchbase.jar -h
-```
-
----
-
-## Description
-
-Benchmarking is incredibly useful, yet endlessly painful. This benchmark suite is the result of a group of
-PhDs/post-docs/professors getting together and combining their workloads/frameworks/experiences/efforts. We hope this
-will save other people's time, and will provide an extensible platform, that can be grown in an open-source fashion.
-
-BenchBase is a multi-threaded load generator. The framework is designed to be able to produce variable rate,
-variable mixture load against any JDBC-enabled relational database. The framework also provides data collection
-features, e.g., per-transaction-type latency and throughput logs.
-
-The BenchBase framework has the following benchmarks:
-
-* [AuctionMark](https://github.com/cmu-db/benchbase/wiki/AuctionMark)
-* [CH-benCHmark](https://github.com/cmu-db/benchbase/wiki/CH-benCHmark)
-* [Epinions.com](https://github.com/cmu-db/benchbase/wiki/epinions)
-* hyadapt -- pending configuration files
-* [NoOp](https://github.com/cmu-db/benchbase/wiki/NoOp)
-* [OT-Metrics](https://github.com/cmu-db/benchbase/wiki/OT-Metrics)
-* [Resource Stresser](https://github.com/cmu-db/benchbase/wiki/Resource-Stresser)
-* [SEATS](https://github.com/cmu-db/benchbase/wiki/Seats)
-* [SIBench](https://github.com/cmu-db/benchbase/wiki/SIBench)
-* [SmallBank](https://github.com/cmu-db/benchbase/wiki/SmallBank)
-* [TATP](https://github.com/cmu-db/benchbase/wiki/TATP)
-* [TPC-C](https://github.com/cmu-db/benchbase/wiki/TPC-C)
-* [TPC-H](https://github.com/cmu-db/benchbase/wiki/TPC-H)
-* TPC-DS -- pending configuration files
-* [Twitter](https://github.com/cmu-db/benchbase/wiki/Twitter)
-* [Voter](https://github.com/cmu-db/benchbase/wiki/Voter)
-* [Wikipedia](https://github.com/cmu-db/benchbase/wiki/Wikipedia)
-* [YCSB](https://github.com/cmu-db/benchbase/wiki/YCSB)
-
-This framework is design to allow for easy extension. We provide stub code that a contributor can use to include a new
-benchmark, leveraging all the system features (logging, controlled speed, controlled mixture, etc.)
-
----
-
-## Usage Guide
-
-### How to Build
-Run the following command to build the distribution for a given database specified as the profile name (`-P`).  The following profiles are currently supported: `postgres`, `mysql`, `mariadb`, `sqlite`, `cockroachdb`, `phoenix`, and `spanner`.
-
-```bash
-./mvnw clean package -P <profile name>
-```
-
-The following files will be placed in the `./target` folder:
-
-* `benchbase-<profile name>.tgz`
-* `benchbase-<profile name>.zip`
-
-### How to Run
-Once you build and unpack the distribution, you can run `benchbase` just like any other executable jar.  The following examples assume you are running from the root of the expanded `.zip` or `.tgz` distribution.  If you attempt to run `benchbase` outside of the distribution structure you may encounter a variety of errors including `java.lang.NoClassDefFoundError`.
-
-To bring up help contents:
-```bash
-java -jar benchbase.jar -h
-```
-
-To execute the `tpcc` benchmark:
-```bash
-java -jar benchbase.jar -b tpcc -c config/postgres/sample_tpcc_config.xml --create=true --load=true --execute=true
-```
-
-For composite benchmarks like `chbenchmark`, which require multiple schemas to be created and loaded, you can provide a comma separated list:
-```bash
-java -jar benchbase.jar -b tpcc,chbenchmark -c config/postgres/sample_chbenchmark_config.xml --create=true --load=true --execute=true
-```
-
-The following options are provided:
-
-```text
-usage: benchbase
- -b,--bench <arg>               [required] Benchmark class. Currently
-                                supported: [tpcc, tpch, tatp, wikipedia,
-                                resourcestresser, twitter, epinions, ycsb,
-                                seats, auctionmark, chbenchmark, voter,
-                                sibench, noop, smallbank, hyadapt, otmetrics]
- -c,--config <arg>              [required] Workload configuration file
-    --clear <arg>               Clear all records in the database for this
-                                benchmark
-    --create <arg>              Initialize the database for this benchmark
- -d,--directory <arg>           Base directory for the result files,
-                                default is current directory
-    --dialects-export <arg>     Export benchmark SQL to a dialects file
-    --execute <arg>             Execute the benchmark workload
- -h,--help                      Print this help
- -im,--interval-monitor <arg>   Throughput Monitoring Interval in
-                                milliseconds
-    --load <arg>                Load data using the benchmark's data
-                                loader
- -s,--sample <arg>              Sampling window
-```
-
-### How to Run with Maven
-
-Instead of first building, packaging and extracting before running benchbase, it is possible to execute benchmarks directly against the source code using Maven. Once you have the project cloned you can run any benchmark from the root project directory using the Maven `exec:java` goal. For example, the following command executes the `tpcc` benchmark against `postgres`:
-
-```
-mvn clean compile exec:java -P postgres -Dexec.args="-b tpcc -c config/postgres/sample_tpcc_config.xml --create=true --load=true --execute=true"
-```
-
-this is equivalent to the steps above but eliminates the need to first package and then extract the distribution.
-
-### How to Enable Logging
-
-To enable logging, e.g., for the PostgreSQL JDBC driver, add the following JVM property when starting...
-
-```
--Djava.util.logging.config.file=src/main/resources/logging.properties
-```
-
-To modify the logging level you can update [`logging.properties`](src/main/resources/logging.properties) and/or [`log4j.properties`](src/main/resources/log4j.properties).
-
-### How to Release
-
-```
-./mvnw -B release:prepare
-./mvnw -B release:perform
-```
-
-### How use with Docker
-
-- Build or pull a dev image to help building from source:
-
-  ```sh
-  ./docker/benchbase/build-dev-image.sh
-  ./docker/benchbase/run-dev-image.sh
-  ```
-
-  or
-
-  ```sh
-  docker run -it --rm --pull \
-    -v /path/to/benchbase-source:/benchbase \
-    -v $HOME/.m2:/home/containeruser/.m2 \
-    benchbase.azure.cr.io/benchbase-dev
-  ```
-
-- Build the full image:
-
-  ```sh
-  # build an image with all profiles
-  ./docker/benchbase/build-full-image.sh
-
-  # or if you only want to build some of them
-  BENCHBASE_PROFILES='postgres mysql' ./docker/benchbase/build-full-image.sh
-  ```
-
-- Run the image for a given profile:
-
-  ```sh
-  BENCHBASE_PROFILE='postgres' ./docker/benchbase/run-full-image.sh --help # or other benchbase args as before
-  ```
-
-  or
-
-  ```sh
-  docker run -it --rm --env BENCHBASE_PROFILE='postgres' \
-    -v results:/benchbase/results benchbase.azurecr.io/benchbase --help # or other benchbase args as before
-  ```
-
-> See the [docker/benchbase/README.md](./docker/benchbase/) for further details.
-
-[Github Codespaces](https://github.com/features/codespaces) and [VSCode devcontainer](https://code.visualstudio.com/docs/remote/containers) support is also available.
-
-### How to Add Support for a New Database
-
-Please see the existing MySQL and PostgreSQL code for an example.
-
----
-
-## Contributing
-
-We welcome all contributions! Please open a pull request. Common contributions may include:
-
-- Adding support for a new DBMS.
-- Adding more tests of existing benchmarks.
-- Fixing any bugs or known issues.
-
-## Known Issues
-
-Please use GitHub's issue tracker for all issues.
-
-## Credits
-
-BenchBase is the official modernized version of the original OLTPBench.
-
-The original OLTPBench code was largely written by the authors of the original paper, [OLTP-Bench: An Extensible Testbed for Benchmarking Relational Databases](http://www.vldb.org/pvldb/vol7/p277-difallah.pdf), D. E. Difallah, A. Pavlo, C. Curino, and P. Cudr-Mauroux. In VLDB 2014. Please see the citation guide below.
-
-A significant portion of the modernization was contributed by [Tim Veil @ Cockroach Labs](https://github.com/timveil-cockroach), including but not limited to:
-
-* Built with and for Java ~~11~~ 17.
-* Migration from Ant to Maven.
-  * Reorganized project to fit Maven structure.
-  * Removed static `lib` directory and dependencies.
-  * Updated required dependencies and removed unused or unwanted dependencies.
-  * Moved all non `.java` files to standard Maven `resources` directory.
-  * Shipped with [Maven Wrapper](https://maven.apache.org/wrapper).
-* Improved packaging and versioning.
-    * Moved to Calendar Versioning (https://calver.org/).
-    * Project is now distributed as a `.tgz` or `.zip` with an executable `.jar`.
-    * All code updated to read `resources` from inside `.jar` instead of directory.
-* Moved from direct dependence on Log4J to SLF4J.
-* Reorganized and renamed many files for clarity and consistency.
-* Applied countless fixes based on "Static Analysis".
-    * JDK migrations (boxing, un-boxing, etc.).
-    * Implemented `try-with-resources` for all `java.lang.AutoCloseable` instances.
-    * Removed calls to `printStackTrace()` or `System.out.println` in favor of proper logging.
-* Reformatted code and cleaned up imports.
-* Removed all calls to `assert`.
-* Removed various forms of dead code and stale configurations.
-* Removed calls to `commit()` during `Loader` operations.
-* Refactored `Worker` and `Loader` usage of `Connection` objects and cleaned up transaction handling.
-* Introduced [Dependabot](https://dependabot.com/) to keep Maven dependencies up to date.
-* Simplified output flags by removing most of them, generally leaving the reporting functionality enabled by default.
-* Provided an alternate `Catalog` that can be populated directly from the configured Benchmark database. The old catalog was proxied through `HSQLDB` -- this remains an option for DBMSes that may have incomplete catalog support.
-
-## Citing This Repository
-
-If you use this repository in an academic paper, please cite this repository:
-
-> D. E. Difallah, A. Pavlo, C. Curino, and P. Cudr-Mauroux, "OLTP-Bench: An Extensible Testbed for Benchmarking Relational Databases," PVLDB, vol. 7, iss. 4, pp. 277-288, 2013.
-
-The BibTeX is provided below for convenience.
-
-```bibtex
-@article{DifallahPCC13,
-  author = {Djellel Eddine Difallah and Andrew Pavlo and Carlo Curino and Philippe Cudr{\'e}-Mauroux},
-  title = {OLTP-Bench: An Extensible Testbed for Benchmarking Relational Databases},
-  journal = {PVLDB},
-  volume = {7},
-  number = {4},
-  year = {2013},
-  pages = {277--288},
-  url = {http://www.vldb.org/pvldb/vol7/p277-difallah.pdf},
-}
-```
+Please refer to the README file in the main branch of this repository for more information.

From 04e8b6c8091a02f3109218055f0a7589785225f6 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Fri, 10 Nov 2023 18:13:28 +0100
Subject: [PATCH 17/32] Switch to Java 21

---
 pom.xml         | 9 +++------
 scripts/tpcc.sh | 4 ++--
 2 files changed, 5 insertions(+), 8 deletions(-)

diff --git a/pom.xml b/pom.xml
index 54ff9dc7..9c95c9a6 100644
--- a/pom.xml
+++ b/pom.xml
@@ -12,9 +12,9 @@
 
     <properties>
         <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
-        <java.version>20</java.version>
-        <maven.compiler.source>20</maven.compiler.source>
-        <maven.compiler.target>20</maven.compiler.target>
+        <java.version>1</java.version>
+        <maven.compiler.source>21</maven.compiler.source>
+        <maven.compiler.target>21</maven.compiler.target>
         <buildDirectory>${project.basedir}/target</buildDirectory>
         <!--
             Provids a way to limit which assembly package formats we produce.
@@ -258,9 +258,6 @@
                 <configuration>
                     <source>${maven.compiler.source}</source>
                     <target>${maven.compiler.target}</target>
-                    <compilerArgs>
-                        --enable-preview
-                    </compilerArgs>
                 </configuration>
             </plugin>
             <plugin>
diff --git a/scripts/tpcc.sh b/scripts/tpcc.sh
index e389bb27..89e6613e 100755
--- a/scripts/tpcc.sh
+++ b/scripts/tpcc.sh
@@ -13,7 +13,7 @@ while [[ "$#" > 0 ]]; do case $1 in
         ;;
 esac; shift; done
 
-min_java_version=20
+min_java_version=21
 
 if command -v java >/dev/null; then
     java_version=$(java -version 2>&1 | awk -F '"' '/version/ {print $2}' | awk -F '.' '{print $1}')
@@ -41,4 +41,4 @@ if [[ -z "$java" ]]; then
     exit 1
 fi
 
-$java --enable-preview -Xmx$memory -jar benchbase.jar -b tpcc "${args[@]}"
+$java -Xmx$memory -jar benchbase.jar -b tpcc "${args[@]}"

From 481a3f719d137cdab19344c98727179c61135af2 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Fri, 10 Nov 2023 22:43:51 +0100
Subject: [PATCH 18/32] Better logging

---
 .../java/com/oltpbenchmark/ThreadBench.java   |  2 +-
 .../java/com/oltpbenchmark/api/Worker.java    | 76 +++++++++----------
 2 files changed, 39 insertions(+), 39 deletions(-)

diff --git a/src/main/java/com/oltpbenchmark/ThreadBench.java b/src/main/java/com/oltpbenchmark/ThreadBench.java
index fca200ec..b7bb9a2c 100644
--- a/src/main/java/com/oltpbenchmark/ThreadBench.java
+++ b/src/main/java/com/oltpbenchmark/ThreadBench.java
@@ -353,7 +353,7 @@ private long getInterval(int lowestRate, Phase.Arrival arrival) {
     @Override
     public void uncaughtException(Thread t, Throwable e) {
         // Here we handle the case in which one of our worker threads died
-        LOG.error(e.getMessage(), e);
+        LOG.error("Uncaught exception: {}", e.getMessage(), e);
         // We do not continue with the experiment. Instead, bypass rest of
         // phases that were left in the test and signal error state.
         // The rest of the workflow to finish the experiment remains the same,
diff --git a/src/main/java/com/oltpbenchmark/api/Worker.java b/src/main/java/com/oltpbenchmark/api/Worker.java
index 08d36a76..221a5518 100644
--- a/src/main/java/com/oltpbenchmark/api/Worker.java
+++ b/src/main/java/com/oltpbenchmark/api/Worker.java
@@ -181,7 +181,7 @@ synchronized public void cancelStatement() {
                 this.currStatement.cancel();
             }
         } catch (SQLException e) {
-            LOG.error("Failed to cancel statement: {}", e.getMessage());
+            LOG.error("worker {} failed to cancel statement: {}", id, e.getMessage());
         }
     }
 
@@ -237,9 +237,9 @@ public final void run() {
                     long maxDelay = 2000 * warmup / 3;
                     try {
                         Thread.sleep(ThreadLocalRandom.current().nextLong(maxDelay));
-                        LOG.debug("Thread started");
+                        LOG.debug("Worker {} thread started", id);
                     } catch (InterruptedException e) {
-                        LOG.error("Pre-start sleep interrupted", e);
+                        LOG.error("Worker {} pre-start sleep interrupted", id, e);
                     }
                 }
             }
@@ -265,7 +265,7 @@ public final void run() {
                 case DONE, EXIT, LATENCY_COMPLETE -> {
                     // Once a latency run is complete, we wait until the next
                     // phase or until DONE.
-                    LOG.warn("preState is {}? will continue...", preState);
+                    LOG.warn("preState {} will continue...", preState);
                     continue;
                 }
                 default -> {
@@ -289,11 +289,13 @@ public final void run() {
 
                 if (preExecutionWaitInMillis > 0) {
                     try {
-                        LOG.debug("{} will sleep for {} ms before executing", transactionType.getName(), preExecutionWaitInMillis);
+                        LOG.debug("Worker {}: {} will sleep for {} ms before executing",
+                            id, transactionType.getName(), preExecutionWaitInMillis);
 
                         Thread.sleep(preExecutionWaitInMillis);
+                        LOG.debug("Worker {} woke up to execute {}", id, transactionType.getName());
                     } catch (InterruptedException e) {
-                        LOG.error("Pre-execution sleep interrupted", e);
+                        LOG.error("Worker {} pre-execution sleep interrupted", id, e);
                     }
                 }
 
@@ -354,11 +356,12 @@ public final void run() {
 
                 if (postExecutionWaitInMillis > 0) {
                     try {
-                        LOG.debug("{} will sleep for {} ms after executing", transactionType.getName(), postExecutionWaitInMillis);
+                        LOG.debug("Worker {} {} will sleep for {} ms after executing",
+                            id, transactionType.getName(), postExecutionWaitInMillis);
 
                         Thread.sleep(postExecutionWaitInMillis);
                     } catch (InterruptedException e) {
-                        LOG.error("Post-execution sleep interrupted", e);
+                        LOG.error("Worker {} post-execution sleep interrupted", id, e);
                     }
                 }
             }
@@ -366,7 +369,7 @@ public final void run() {
             workloadState.finishedWork();
         }
 
-        LOG.debug("worker calling teardown");
+        LOG.debug("Worker {} calling teardown", id);
 
         tearDown();
     }
@@ -378,19 +381,19 @@ private TransactionType getTransactionType(SubmittedProcedure pieceOfWork, Phase
             type = transactionTypes.getType(pieceOfWork.getType());
         } catch (IndexOutOfBoundsException e) {
             if (phase.isThroughputRun()) {
-                LOG.error("Thread tried executing disabled phase!");
+                LOG.error("Worker {} thread tried executing disabled phase!", id);
                 throw e;
             }
             if (phase.getId() == workloadState.getCurrentPhase().getId()) {
                 switch (state) {
                     case WARMUP -> {
                         // Don't quit yet: we haven't even begun!
-                        LOG.info("[Serial] Resetting serial for phase.");
+                        LOG.info("Worker {} [Serial] Resetting serial for phase.", id);
                         phase.resetSerial();
                     }
                     case COLD_QUERY, MEASURE -> {
                         // The serial phase is over. Finish the run early.
-                        LOG.info("[Serial] Updating workload state to {}.", State.LATENCY_COMPLETE);
+                        LOG.info("Worker {} [Serial] Updating workload state to {}.", id, State.LATENCY_COMPLETE);
                         workloadState.signalLatencyComplete();
                     }
                     default -> throw e;
@@ -422,13 +425,12 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
 
                 if (this.conn == null) {
                     try {
+                        LOG.debug("Worker {} opening a new connection", id);
                         this.conn = this.benchmark.makeConnection();
                         this.conn.setAutoCommit(false);
                         this.conn.setTransactionIsolation(this.configuration.getIsolationMode());
                     } catch (SQLException ex) {
-                        if (LOG.isDebugEnabled()) {
-                            LOG.debug(String.format("%s failed to open a connection...", this));
-                        }
+                        LOG.debug("Worker {} failed to open a connection: {}", id, ex);
                         retryCount++;
                         continue;
                     }
@@ -436,19 +438,12 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
 
                 try {
 
-                    if (LOG.isDebugEnabled()) {
-                        LOG.debug(String.format("%s %s attempting...", this, transactionType));
-                    }
+                    LOG.debug("Worker {} is attempting {}", id, transactionType);
 
                     status = this.executeWork(conn, transactionType);
 
-                    if (LOG.isDebugEnabled()) {
-                        LOG.debug(String.format("%s %s completed with status [%s]...", this, transactionType, status.name()));
-                    }
-
-                    if (LOG.isDebugEnabled()) {
-                        LOG.debug(String.format("%s %s committing...", this, transactionType));
-                    }
+                    LOG.debug("Worker {} completed {} with status {} and going to commit",
+                        id, transactionType, status.name());
 
                     conn.commit();
 
@@ -461,13 +456,13 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                         status = TransactionStatus.USER_ABORTED;
                     } catch (Exception e) {
                         LOG.warn(
-                            String.format("Failed to rollback transaction after UserAbortException (%s): %s",
-                                          ex.toString(), e.toString()));
+                            "Worker {} failed to rollback transaction after UserAbortException ({}): {}",
+                            id, ex.toString(), e.toString());
 
                         status = TransactionStatus.ERROR;
                     }
 
-                    ABORT_LOG.debug(String.format("%s Aborted", transactionType), ex);
+                    ABORT_LOG.debug("{} Aborted", transactionType, ex);
 
 
                     break;
@@ -475,21 +470,26 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                 } catch (SQLException ex) {
                     // TODO: probably check exception and retry if possible
                     try {
+                        LOG.debug("Worker {} rolled back transaction {}", id, transactionType);
                         conn.rollback();
                     } catch (Exception e) {
                         LOG.warn(
-                            String.format("Failed to rollback transaction after SQLException (%s): %s",
-                                          ex.toString(), e.toString()));
+                            "Worker {} failed to rollback transaction after SQLException ({}): {}",
+                            id, ex.toString(), e.toString());
                     }
 
                     if (isRetryable(ex)) {
-                        LOG.debug(String.format("Retryable SQLException occurred during [%s]... current retry attempt [%d], max retry attempts [%d], sql state [%s], error code [%d].", transactionType, retryCount, maxRetryCount, ex.getSQLState(), ex.getErrorCode()), ex);
+                        LOG.debug(
+                            "Worker {} Retryable SQLException occurred during [{}]... current retry attempt [{}], max retry attempts [{}], sql state [{}], error code [{}].",
+                            id, transactionType, retryCount, maxRetryCount, ex.getSQLState(), ex.getErrorCode(), ex);
 
                         status = TransactionStatus.RETRY;
 
                         retryCount++;
                     } else {
-                        LOG.warn(String.format("SQLException occurred during [%s] and will not be retried... sql state [%s], error code [%d].", transactionType, ex.getSQLState(), ex.getErrorCode()), ex);
+                        LOG.warn(
+                            "Worker {} SQLException occurred during [{}] and will not be retried... sql state [{}], error code [{}].",
+                            id, transactionType, ex.getSQLState(), ex.getErrorCode(), ex);
 
                         status = TransactionStatus.ERROR;
 
@@ -499,10 +499,11 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                 } finally {
                     if (this.configuration.getNewConnectionPerTxn() && this.conn != null) {
                         try {
+                            LOG.debug("Worker {} closing connection", id);
                             this.conn.close();
                             this.conn = null;
                         } catch (SQLException e) {
-                            LOG.error("Connection couldn't be closed.", e);
+                            LOG.error("Worker {} connection couldn't be closed.", id, e);
                         }
                     }
 
@@ -519,9 +520,8 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
 
             }
         } catch (RuntimeException ex) {
-            String msg = String.format("Unexpected RuntimeException in '%s' when executing '%s' on [%s]: %s",
-                                       this, transactionType, databaseType.name(), ex.toString());
-            LOG.error(msg);
+            LOG.error("Worker {} Unexpected RuntimeException when executing '%s' on [%s]: %s",
+                id, transactionType, databaseType.name(), ex.toString(), ex);
             throw ex;
         }
 
@@ -533,7 +533,7 @@ private boolean isRetryable(SQLException ex) {
         String sqlState = ex.getSQLState();
         int errorCode = ex.getErrorCode();
 
-        LOG.debug("sql state [{}] and error code [{}]", sqlState, errorCode);
+        LOG.debug("Worker {} sql state [{}] and error code [{}]", id, sqlState, errorCode);
 
         if (sqlState == null) {
             return false;
@@ -584,7 +584,7 @@ public void tearDown() {
             try {
                 conn.close();
             } catch (SQLException e) {
-                LOG.error("Connection couldn't be closed.", e);
+                LOG.error("Worker {} connection couldn't be closed.", id, e);
             }
         }
     }

From 175f0c03d9c16652c85a6103331fec473017797e Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Sat, 11 Nov 2023 00:25:01 +0100
Subject: [PATCH 19/32] avoid exhausting vthread carriers and deadlocking

---
 .../oltpbenchmark/api/BenchmarkModule.java    | 28 ++++++++++++++++++-
 .../java/com/oltpbenchmark/api/Worker.java    |  3 ++
 2 files changed, 30 insertions(+), 1 deletion(-)

diff --git a/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java b/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
index 231d179f..3827d92b 100644
--- a/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
+++ b/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
@@ -35,6 +35,7 @@
 import java.sql.Connection;
 import java.sql.DriverManager;
 import java.sql.SQLException;
+import java.util.concurrent.Semaphore;
 import java.util.*;
 
 /**
@@ -45,6 +46,16 @@ public abstract class BenchmarkModule {
 
     private static ComboPooledDataSource dataSource;
 
+    // We use virtual threads. There is a limitted number of c3p0 provided connections.
+    // When c3p0 runs out of connections, it will block until one is available. Block in a way
+    // that carrier threads are blocked. Same time other virtual threads holding connections
+    // might be parked waiting for a carrier thread to be available. This will cause a deadlock.
+    // To avoid this, we use a semaphore to wait for a connection without blocking the carrier thread.
+    //
+    // TODO: currently this breaks all non TPC-C benchmarks,
+    // because they have to call returnConnection() now
+    private static Semaphore connectionSemaphore;
+
     /**
      * The workload configuration for this benchmark invocation
      */
@@ -90,6 +101,8 @@ public BenchmarkModule(WorkloadConfiguration workConf) {
                 dataSource.setMaxPoolSize(workConf.getMaxConnections());
                 dataSource.setMaxStatements(workConf.getMaxConnections());
 
+                connectionSemaphore = new Semaphore(workConf.getMaxConnections());
+
                 Runtime.getRuntime().addShutdownHook(new Thread(() -> {
                     dataSource.close();
                 }));
@@ -105,7 +118,20 @@ public BenchmarkModule(WorkloadConfiguration workConf) {
     // --------------------------------------------------------------------------
 
     public final Connection makeConnection() throws SQLException {
-        return dataSource.getConnection();
+        try {
+            connectionSemaphore.acquire();
+            return dataSource.getConnection();
+        } catch (SQLException e) {
+            connectionSemaphore.release();
+            throw e;
+        } catch (InterruptedException e) {
+            connectionSemaphore.release();
+            throw new SQLException(e);
+        }
+    }
+
+    public final void returnConnection() {
+        connectionSemaphore.release();
     }
 
     // --------------------------------------------------------------------------
diff --git a/src/main/java/com/oltpbenchmark/api/Worker.java b/src/main/java/com/oltpbenchmark/api/Worker.java
index 221a5518..088b5d74 100644
--- a/src/main/java/com/oltpbenchmark/api/Worker.java
+++ b/src/main/java/com/oltpbenchmark/api/Worker.java
@@ -502,6 +502,7 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                             LOG.debug("Worker {} closing connection", id);
                             this.conn.close();
                             this.conn = null;
+                            this.benchmark.returnConnection();
                         } catch (SQLException e) {
                             LOG.error("Worker {} connection couldn't be closed.", id, e);
                         }
@@ -583,6 +584,8 @@ public void tearDown() {
         if (!this.configuration.getNewConnectionPerTxn() && this.conn != null) {
             try {
                 conn.close();
+                this.conn = null;
+                this.benchmark.returnConnection();
             } catch (SQLException e) {
                 LOG.error("Worker {} connection couldn't be closed.", id, e);
             }

From 49c08e739a130234d85ffe8f2f294c21576948c8 Mon Sep 17 00:00:00 2001
From: Maksim Zinal <mzinal@ru.ibm.com>
Date: Wed, 20 Dec 2023 17:28:53 +0300
Subject: [PATCH 20/32] KIKIMR-20581 add returnConnection() call to
 LoaderThread

---
 src/main/java/com/oltpbenchmark/api/LoaderThread.java | 1 +
 1 file changed, 1 insertion(+)

diff --git a/src/main/java/com/oltpbenchmark/api/LoaderThread.java b/src/main/java/com/oltpbenchmark/api/LoaderThread.java
index 50f4ba9c..4f6d9aac 100644
--- a/src/main/java/com/oltpbenchmark/api/LoaderThread.java
+++ b/src/main/java/com/oltpbenchmark/api/LoaderThread.java
@@ -49,6 +49,7 @@ public final void run() {
             LOG.error(msg, next_ex);
             throw new RuntimeException(ex);
         } finally {
+            benchmarkModule.returnConnection();
             afterLoad();
         }
     }

From 91628bd6904549993b87f4581d87beb94e1df024 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Sat, 27 Jan 2024 19:38:17 +0100
Subject: [PATCH 21/32] update README

---
 README.md | 39 ++++++++++++++++++++++++++++++++++++++-
 1 file changed, 38 insertions(+), 1 deletion(-)

diff --git a/README.md b/README.md
index 02256e41..bc38702b 100644
--- a/README.md
+++ b/README.md
@@ -1 +1,38 @@
-Please refer to the README file in the main branch of this repository for more information.
+# Overview
+
+This is a fork of [BenchBase](https://github.com/cmu-db/benchbase) done to enhance TPC-C for PostgresSQL:
+1. Fixed some performance issues in the original benchbase to speed up the benchmark.
+2. To address issues with running high number of warehouses, we added support for virtual threads (requires Java >= 21).
+3. Significantly reduced the memory footprint of the benchmark.
+4. Added c3p0 as a connection pool for PostgreSQL
+
+Please, note that this is for PostgreSQL only.
+
+## Hardware requirements
+
+Minumum requirements for running the benchmark against YDB:
+* 2 cores and 4 GB RAM (for 100 warehouses)
+* 4 cores and 6 GB RAM (for 1000 warehouses)
+
+Above 1000 warehouses, the memory and CPU consumption grow linearly, you need:
+* 1 core per 1000 warehouses
+* 6 MB RAM per warehouse
+
+E.g. to run 10000 warehouses you need to have at least 10 cores and 64 GB RAM. However, Instead of running 10000 warehouses on a single instance (and machine), we recommend to run at most 5000 warehouses per instance (preferably on separate machines).
+
+To reduce memory consumption, make sure you don't use huge pages or transparent huge pages.
+
+# TPC-C benchmark for PostgreSQL
+
+## How to build
+
+```
+./mvnw clean package -P postgres -DskipTests
+```
+
+Prebuilt packages:
+* [benchbase-postgres.tgz](https://storage.yandexcloud.net/ydb-benchmark-builds/benchbase-postgres.tgz)
+
+## How to run
+
+The simplest way is to use helper scripts from [benchhelpers](https://github.com/ydb-platform/benchhelpers). You can find the full instruction [here](https://github.com/ydb-platform/benchhelpers/blob/main/tpcc/postgres/README.md).

From 874f2c0b3fe54a8c05af9b162b930677f3b439c5 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Tue, 6 Feb 2024 17:42:39 +0100
Subject: [PATCH 22/32] Major refactoring

- remove all stuff not needed by TPC-C
- remove all synchronized sections to avoid deadlocks in virtual threads
---
 .../com/oltpbenchmark/BenchmarkState.java     |  91 +--
 .../java/com/oltpbenchmark/DBWorkload.java    | 527 ++++++++----------
 src/main/java/com/oltpbenchmark/Phase.java    | 136 +----
 .../java/com/oltpbenchmark/ThreadBench.java   | 265 ++-------
 .../oltpbenchmark/WorkloadConfiguration.java  |  37 +-
 .../java/com/oltpbenchmark/WorkloadState.java | 265 ---------
 .../oltpbenchmark/api/StatementDialects.java  |   1 -
 .../java/com/oltpbenchmark/api/Worker.java    | 292 +++-------
 .../distributions/ZipfianGenerator.java       |   9 +-
 .../java/com/oltpbenchmark/types/State.java   |  25 -
 .../com/oltpbenchmark/util/Histogram.java     |  11 +-
 11 files changed, 433 insertions(+), 1226 deletions(-)
 delete mode 100644 src/main/java/com/oltpbenchmark/WorkloadState.java
 delete mode 100644 src/main/java/com/oltpbenchmark/types/State.java

diff --git a/src/main/java/com/oltpbenchmark/BenchmarkState.java b/src/main/java/com/oltpbenchmark/BenchmarkState.java
index 8eee9cbe..b5541c73 100644
--- a/src/main/java/com/oltpbenchmark/BenchmarkState.java
+++ b/src/main/java/com/oltpbenchmark/BenchmarkState.java
@@ -17,32 +17,46 @@
 
 package com.oltpbenchmark;
 
-import com.oltpbenchmark.types.State;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicReference;
+import java.util.concurrent.CountDownLatch;
 
+// shared between controlling ThreadBench thread and worker threads
 public final class BenchmarkState {
+    public enum State {
+        WARMUP, MEASURE, DONE, EXIT, ERROR
+    }
 
     private static final Logger LOG = LoggerFactory.getLogger(BenchmarkState.class);
 
+    private final WorkloadConfiguration workloadConf;
     private final long testStartNs;
     private final CountDownLatch startBarrier;
     private final AtomicInteger notDoneCount;
-    private volatile State state = State.WARMUP;
+
+    private final AtomicReference<State> state = new AtomicReference<>(State.WARMUP);
 
     /**
      * @param numThreads number of threads involved in the test: including the
      *                   master thread.
      */
-    public BenchmarkState(int numThreads) {
-        startBarrier = new CountDownLatch(numThreads);
-        notDoneCount = new AtomicInteger(numThreads);
+    public BenchmarkState(int numThreads, WorkloadConfiguration workloadConf) {
+        this.workloadConf = workloadConf;
+        this.startBarrier = new CountDownLatch(numThreads);
+        this.notDoneCount = new AtomicInteger(numThreads);
+
+        this.testStartNs = System.nanoTime();
+    }
 
+    public SubmittedProcedure fetchWork() {
+        if (getState() == State.EXIT || getState() == State.DONE) {
+            return null;
+        }
 
-        testStartNs = System.nanoTime();
+        return new SubmittedProcedure(workloadConf.getPhase().chooseTransaction());
     }
 
     // Protected by this
@@ -52,9 +66,7 @@ public long getTestStartNs() {
     }
 
     public State getState() {
-        synchronized (this) {
-            return state;
-        }
+        return state.get();
     }
 
     /**
@@ -62,8 +74,6 @@ public State getState() {
      * entered.
      */
     public void blockForStart() {
-
-
         startBarrier.countDown();
         try {
             startBarrier.await();
@@ -73,54 +83,45 @@ public void blockForStart() {
     }
 
     public void startMeasure() {
-        state = State.MEASURE;
+        state.set(State.MEASURE);
     }
 
-    public void startColdQuery() {
-        state = State.COLD_QUERY;
+    public void signalError() {
+        notDoneCount.decrementAndGet();
+        state.set(State.ERROR);
     }
 
-    public void startHotQuery() {
-        state = State.MEASURE;
+    public boolean isError() {
+        return getState() == State.ERROR;
     }
 
-    public void signalLatencyComplete() {
-        state = State.LATENCY_COMPLETE;
+    public boolean isWorkingOrMeasuring() {
+        return getState() == State.WARMUP || getState() == State.MEASURE;
     }
 
-    public void ackLatencyComplete() {
-        state = State.MEASURE;
+    public boolean isMeasuring() {
+        return getState() == State.MEASURE;
     }
 
-    public void signalError() {
-        // A thread died, decrement the count and set error state
+    public void workerFinished() {
         notDoneCount.decrementAndGet();
-        state = State.ERROR;
-    }
-
-    public void startCoolDown() {
-        state = State.DONE;
-
-        // The master thread must also signal that it is done
-        signalDone();
     }
 
-    /**
-     * Notify that this thread has entered the done state.
-     */
-    public int signalDone() {
-
-        int current = notDoneCount.decrementAndGet();
+    public void stopWorkers() {
+        int waitCount = notDoneCount.decrementAndGet();
+        if (waitCount > 0) {
+            LOG.debug(String.format("%d workers are not done. Waiting until they finish", waitCount));
+        }
 
-        if (LOG.isDebugEnabled()) {
-            LOG.debug(String.format("%d workers are not done. Waiting until they finish", current));
+        if (getState() != State.ERROR) {
+            // might be a minor race here, but not a problem
+            state.set(State.DONE);
         }
-        if (current == 0) {
-            // We are the last thread to notice that we are done: wake any
-            // blocked workers
-            this.state = State.EXIT;
+
+        while (notDoneCount.get() > 0) {
+            Thread.yield();
         }
-        return current;
-    }
 
+        LOG.debug("Workers stopped");
+    }
 }
\ No newline at end of file
diff --git a/src/main/java/com/oltpbenchmark/DBWorkload.java b/src/main/java/com/oltpbenchmark/DBWorkload.java
index abfa38e9..b0e43019 100644
--- a/src/main/java/com/oltpbenchmark/DBWorkload.java
+++ b/src/main/java/com/oltpbenchmark/DBWorkload.java
@@ -51,9 +51,6 @@ public class DBWorkload {
 
     private static final String SINGLE_LINE = StringUtil.repeat("=", 70);
 
-    private static final String RATE_DISABLED = "disabled";
-    private static final String RATE_UNLIMITED = "unlimited";
-
     // FIXME: TPC-C only hack
     private static int newOrderTxnId = -1;
     private static int numWarehouses = 10;
@@ -112,7 +109,17 @@ public static void main(String[] args) throws Exception {
         String targetBenchmarks = argsLine.getOptionValue("b");
 
         String[] targetList = targetBenchmarks.split(",");
-        List<BenchmarkModule> benchList = new ArrayList<>();
+        if (targetList.length == 0) {
+            throw new ParseException("No benchmarks specified", 1);
+        }
+
+        if (targetList.length > 1) {
+            throw new ParseException("Only one benchmark can be specified when exporting dialects", 1);
+        }
+
+        if (!targetList[0].equals("tpcc")) {
+            throw new ParseException("Only TPC-C benchmark is supported", 1);
+        }
 
         // Use this list for filtering of the output
         List<TransactionType> activeTXTypes = new ArrayList<>();
@@ -123,318 +130,252 @@ public static void main(String[] args) throws Exception {
 
         // Load the configuration for each benchmark
         int lastTxnId = 0;
-        for (String plugin : targetList) {
-            String pluginTest = "[@bench='" + plugin + "']";
-
-            // ----------------------------------------------------------------
-            // BEGIN LOADING WORKLOAD CONFIGURATION
-            // ----------------------------------------------------------------
-
-            WorkloadConfiguration wrkld = new WorkloadConfiguration();
-            wrkld.setBenchmarkName(plugin);
-            wrkld.setXmlConfig(xmlConfig);
-
-            // Pull in database configuration
-            wrkld.setDatabaseType(DatabaseType.get(xmlConfig.getString("type")));
-            wrkld.setDriverClass(xmlConfig.getString("driver"));
-            wrkld.setUrl(xmlConfig.getString("url"));
-            wrkld.setUsername(xmlConfig.getString("username"));
-            wrkld.setPassword(xmlConfig.getString("password"));
-            wrkld.setRandomSeed(xmlConfig.getInt("randomSeed", -1));
-            wrkld.setBatchSize(xmlConfig.getInt("batchsize", 128));
-            wrkld.setMaxRetries(xmlConfig.getInt("retries", 3));
-            wrkld.setMaxConnections(xmlConfig.getInt("maxConnections", wrkld.getMaxConnections()));
-            wrkld.setNewConnectionPerTxn(xmlConfig.getBoolean("newConnectionPerTxn", false));
-
-            int terminals = xmlConfig.getInt("terminals[not(@bench)]", 0);
-            terminals = xmlConfig.getInt("terminals" + pluginTest, terminals);
-            wrkld.setTerminals(terminals);
-            wrkld.setStartFrom(startFromId);
-
-            if (xmlConfig.containsKey("loaderThreads")) {
-                int loaderThreads = xmlConfig.getInt("loaderThreads");
-                wrkld.setLoaderThreads(loaderThreads);
-            }
-
-            String isolationMode = xmlConfig.getString("isolation[not(@bench)]", "TRANSACTION_SERIALIZABLE");
-            wrkld.setIsolationMode(xmlConfig.getString("isolation" + pluginTest, isolationMode));
-
-            double scaleFactor = xmlConfig.getDouble("scalefactor", 1.0);
-            numWarehouses = (int) scaleFactor;
-            wrkld.setScaleFactor(scaleFactor);
-
-            wrkld.setDataDir(xmlConfig.getString("datadir", "."));
-            wrkld.setDDLPath(xmlConfig.getString("ddlpath", null));
-
-            double selectivity = -1;
-            try {
-                selectivity = xmlConfig.getDouble("selectivity");
-                wrkld.setSelectivity(selectivity);
-            } catch (NoSuchElementException nse) {
-                // Nothing to do here !
-            }
+        final String plugin = "tpcc";
+        String pluginTest = "[@bench='" + plugin + "']";
+
+        // ----------------------------------------------------------------
+        // BEGIN LOADING WORKLOAD CONFIGURATION
+        // ----------------------------------------------------------------
+
+        WorkloadConfiguration wrkld = new WorkloadConfiguration();
+        wrkld.setBenchmarkName(plugin);
+        wrkld.setXmlConfig(xmlConfig);
+
+        // Pull in database configuration
+        wrkld.setDatabaseType(DatabaseType.get(xmlConfig.getString("type")));
+        wrkld.setDriverClass(xmlConfig.getString("driver"));
+        wrkld.setUrl(xmlConfig.getString("url"));
+        wrkld.setUsername(xmlConfig.getString("username"));
+        wrkld.setPassword(xmlConfig.getString("password"));
+        wrkld.setRandomSeed(xmlConfig.getInt("randomSeed", -1));
+        wrkld.setBatchSize(xmlConfig.getInt("batchsize", 128));
+        wrkld.setMaxRetries(xmlConfig.getInt("retries", 3));
+        wrkld.setMaxConnections(xmlConfig.getInt("maxConnections", wrkld.getMaxConnections()));
+        wrkld.setNewConnectionPerTxn(xmlConfig.getBoolean("newConnectionPerTxn", false));
+
+        int terminals = xmlConfig.getInt("terminals[not(@bench)]", 0);
+        terminals = xmlConfig.getInt("terminals" + pluginTest, terminals);
+        wrkld.setTerminals(terminals);
+        wrkld.setStartFrom(startFromId);
+
+        if (xmlConfig.containsKey("loaderThreads")) {
+            int loaderThreads = xmlConfig.getInt("loaderThreads");
+            wrkld.setLoaderThreads(loaderThreads);
+        }
 
-            // ----------------------------------------------------------------
-            // CREATE BENCHMARK MODULE
-            // ----------------------------------------------------------------
+        String isolationMode = xmlConfig.getString("isolation[not(@bench)]", "TRANSACTION_SERIALIZABLE");
+        wrkld.setIsolationMode(xmlConfig.getString("isolation" + pluginTest, isolationMode));
 
-            String classname = pluginConfig.getString("/plugin[@name='" + plugin + "']");
+        double scaleFactor = xmlConfig.getDouble("scalefactor", 1.0);
+        numWarehouses = (int) scaleFactor;
+        wrkld.setScaleFactor(scaleFactor);
 
-            if (classname == null) {
-                throw new ParseException("Plugin " + plugin + " is undefined in config/plugin.xml", 1);
-            }
+        wrkld.setDataDir(xmlConfig.getString("datadir", "."));
+        wrkld.setDDLPath(xmlConfig.getString("ddlpath", null));
 
-            BenchmarkModule bench = ClassUtil.newInstance(classname, new Object[]{wrkld}, new Class<?>[]{WorkloadConfiguration.class});
-            Map<String, Object> initDebug = new ListOrderedMap<>();
-            initDebug.put("Benchmark", String.format("%s {%s}", plugin.toUpperCase(), classname));
-            initDebug.put("Configuration", configFile);
-            initDebug.put("Type", wrkld.getDatabaseType());
-            initDebug.put("Driver", wrkld.getDriverClass());
-            initDebug.put("URL", wrkld.getUrl());
-            initDebug.put("Isolation", wrkld.getIsolationString());
-            initDebug.put("Batch Size", wrkld.getBatchSize());
-            initDebug.put("Scale Factor", wrkld.getScaleFactor());
-            initDebug.put("Terminals", wrkld.getTerminals());
-            initDebug.put("New Connection Per Txn", wrkld.getNewConnectionPerTxn());
-
-            if (selectivity != -1) {
-                initDebug.put("Selectivity", selectivity);
-            }
-
-            LOG.info("{}\n\n{}", SINGLE_LINE, StringUtil.formatMaps(initDebug));
-            LOG.info(SINGLE_LINE);
-
-            // ----------------------------------------------------------------
-            // LOAD TRANSACTION DESCRIPTIONS
-            // ----------------------------------------------------------------
-            int numTxnTypes = xmlConfig.configurationsAt("transactiontypes" + pluginTest + "/transactiontype").size();
-            if (numTxnTypes == 0 && targetList.length == 1) {
-                //if it is a single workload run, <transactiontypes /> w/o attribute is used
-                pluginTest = "[not(@bench)]";
-                numTxnTypes = xmlConfig.configurationsAt("transactiontypes" + pluginTest + "/transactiontype").size();
-            }
+        double selectivity = -1;
+        try {
+            selectivity = xmlConfig.getDouble("selectivity");
+            wrkld.setSelectivity(selectivity);
+        } catch (NoSuchElementException nse) {
+            // Nothing to do here !
+        }
 
+        // ----------------------------------------------------------------
+        // CREATE BENCHMARK MODULE
+        // ----------------------------------------------------------------
 
-            List<TransactionType> ttypes = new ArrayList<>();
-            ttypes.add(TransactionType.INVALID);
-            int txnIdOffset = lastTxnId;
-            for (int i = 1; i <= numTxnTypes; i++) {
-                String key = "transactiontypes" + pluginTest + "/transactiontype[" + i + "]";
-                String txnName = xmlConfig.getString(key + "/name");
-                if (txnName.equals("NewOrder")) {
-                    newOrderTxnId = i + txnIdOffset;
-                }
+        String classname = pluginConfig.getString("/plugin[@name='" + plugin + "']");
 
-                // Get ID if specified; else increment from last one.
-                int txnId = i;
-                if (xmlConfig.containsKey(key + "/id")) {
-                    txnId = xmlConfig.getInt(key + "/id");
-                }
+        if (classname == null) {
+            throw new ParseException("Plugin " + plugin + " is undefined in config/plugin.xml", 1);
+        }
 
-                long preExecutionWait = 0;
-                if (xmlConfig.containsKey(key + "/preExecutionWait")) {
-                    preExecutionWait = xmlConfig.getLong(key + "/preExecutionWait");
-                }
+        BenchmarkModule benchmark = ClassUtil.newInstance(classname, new Object[]{wrkld}, new Class<?>[]{WorkloadConfiguration.class});
+        Map<String, Object> initDebug = new ListOrderedMap<>();
+        initDebug.put("Benchmark", String.format("%s {%s}", plugin.toUpperCase(), classname));
+        initDebug.put("Configuration", configFile);
+        initDebug.put("Type", wrkld.getDatabaseType());
+        initDebug.put("Driver", wrkld.getDriverClass());
+        initDebug.put("URL", wrkld.getUrl());
+        initDebug.put("Isolation", wrkld.getIsolationString());
+        initDebug.put("Batch Size", wrkld.getBatchSize());
+        initDebug.put("Scale Factor", wrkld.getScaleFactor());
+        initDebug.put("Terminals", wrkld.getTerminals());
+        initDebug.put("New Connection Per Txn", wrkld.getNewConnectionPerTxn());
+
+        if (selectivity != -1) {
+            initDebug.put("Selectivity", selectivity);
+        }
 
-                long postExecutionWait = 0;
-                if (xmlConfig.containsKey(key + "/postExecutionWait")) {
-                    postExecutionWait = xmlConfig.getLong(key + "/postExecutionWait");
-                }
+        LOG.info("{}\n\n{}", SINGLE_LINE, StringUtil.formatMaps(initDebug));
+        LOG.info(SINGLE_LINE);
 
-                TransactionType tmpType = bench.initTransactionType(txnName, txnId + txnIdOffset, preExecutionWait, postExecutionWait);
+        // ----------------------------------------------------------------
+        // LOAD TRANSACTION DESCRIPTIONS
+        // ----------------------------------------------------------------
+        int numTxnTypes = xmlConfig.configurationsAt("transactiontypes" + pluginTest + "/transactiontype").size();
+        if (numTxnTypes == 0 && targetList.length == 1) {
+            //if it is a single workload run, <transactiontypes /> w/o attribute is used
+            pluginTest = "[not(@bench)]";
+            numTxnTypes = xmlConfig.configurationsAt("transactiontypes" + pluginTest + "/transactiontype").size();
+        }
 
-                // Keep a reference for filtering
-                activeTXTypes.add(tmpType);
 
-                // Add a ref for the active TTypes in this benchmark
-                ttypes.add(tmpType);
-                lastTxnId = i;
+        List<TransactionType> ttypes = new ArrayList<>();
+        ttypes.add(TransactionType.INVALID);
+        int txnIdOffset = lastTxnId;
+        for (int i = 1; i <= numTxnTypes; i++) {
+            String key = "transactiontypes" + pluginTest + "/transactiontype[" + i + "]";
+            String txnName = xmlConfig.getString(key + "/name");
+            if (txnName.equals("NewOrder")) {
+                newOrderTxnId = i + txnIdOffset;
             }
 
-            // Wrap the list of transactions and save them
-            TransactionTypes tt = new TransactionTypes(ttypes);
-            wrkld.setTransTypes(tt);
-            LOG.debug("Using the following transaction types: {}", tt);
-
-            // Read in the groupings of transactions (if any) defined for this
-            // benchmark
-            int numGroupings = xmlConfig.configurationsAt("transactiontypes" + pluginTest + "/groupings/grouping").size();
-            LOG.debug("Num groupings: {}", numGroupings);
-            for (int i = 1; i < numGroupings + 1; i++) {
-                String key = "transactiontypes" + pluginTest + "/groupings/grouping[" + i + "]";
-
-                // Get the name for the grouping and make sure it's valid.
-                String groupingName = xmlConfig.getString(key + "/name").toLowerCase();
-                if (!groupingName.matches("^[a-z]\\w*$")) {
-                    LOG.error(String.format("Grouping name \"%s\" is invalid." + " Must begin with a letter and contain only" + " alphanumeric characters.", groupingName));
-                    System.exit(-1);
-                } else if (groupingName.equals("all")) {
-                    LOG.error("Grouping name \"all\" is reserved." + " Please pick a different name.");
-                    System.exit(-1);
-                }
+            // Get ID if specified; else increment from last one.
+            int txnId = i;
+            if (xmlConfig.containsKey(key + "/id")) {
+                txnId = xmlConfig.getInt(key + "/id");
+            }
 
-                // Get the weights for this grouping and make sure that there
-                // is an appropriate number of them.
-                List<String> groupingWeights = Arrays.asList(xmlConfig.getString(key + "/weights").split("\\s*,\\s*"));
-                if (groupingWeights.size() != numTxnTypes) {
-                    LOG.error(String.format("Grouping \"%s\" has %d weights," + " but there are %d transactions in this" + " benchmark.", groupingName, groupingWeights.size(), numTxnTypes));
-                    System.exit(-1);
-                }
+            long preExecutionWait = 0;
+            if (xmlConfig.containsKey(key + "/preExecutionWait")) {
+                preExecutionWait = xmlConfig.getLong(key + "/preExecutionWait");
+            }
 
-                LOG.debug("Creating grouping with name, weights: {}, {}", groupingName, groupingWeights);
+            long postExecutionWait = 0;
+            if (xmlConfig.containsKey(key + "/postExecutionWait")) {
+                postExecutionWait = xmlConfig.getLong(key + "/postExecutionWait");
             }
 
+            TransactionType tmpType = benchmark.initTransactionType(txnName, txnId + txnIdOffset, preExecutionWait, postExecutionWait);
 
-            benchList.add(bench);
+            // Keep a reference for filtering
+            activeTXTypes.add(tmpType);
 
-            // ----------------------------------------------------------------
-            // WORKLOAD CONFIGURATION
-            // ----------------------------------------------------------------
+            // Add a ref for the active TTypes in this benchmark
+            ttypes.add(tmpType);
+            lastTxnId = i;
+        }
 
-            int size = xmlConfig.configurationsAt("/works/work").size();
-            for (int i = 1; i < size + 1; i++) {
-                final HierarchicalConfiguration<ImmutableNode> work = xmlConfig.configurationAt("works/work[" + i + "]");
-                List<String> weight_strings;
+        // Wrap the list of transactions and save them
+        TransactionTypes tt = new TransactionTypes(ttypes);
+        wrkld.setTransTypes(tt);
+        LOG.debug("Using the following transaction types: {}", tt);
+
+        // Read in the groupings of transactions (if any) defined for this
+        // benchmark
+        int numGroupings = xmlConfig.configurationsAt("transactiontypes" + pluginTest + "/groupings/grouping").size();
+        LOG.debug("Num groupings: {}", numGroupings);
+        for (int i = 1; i < numGroupings + 1; i++) {
+            String key = "transactiontypes" + pluginTest + "/groupings/grouping[" + i + "]";
+
+            // Get the name for the grouping and make sure it's valid.
+            String groupingName = xmlConfig.getString(key + "/name").toLowerCase();
+            if (!groupingName.matches("^[a-z]\\w*$")) {
+                LOG.error(String.format("Grouping name \"%s\" is invalid." + " Must begin with a letter and contain only" + " alphanumeric characters.", groupingName));
+                System.exit(-1);
+            } else if (groupingName.equals("all")) {
+                LOG.error("Grouping name \"all\" is reserved." + " Please pick a different name.");
+                System.exit(-1);
+            }
 
-                // use a workaround if there are multiple workloads or single
-                // attributed workload
-                if (targetList.length > 1 || work.containsKey("weights[@bench]")) {
-                    weight_strings = Arrays.asList(work.getString("weights" + pluginTest).split("\\s*,\\s*"));
-                } else {
-                    weight_strings = Arrays.asList(work.getString("weights[not(@bench)]").split("\\s*,\\s*"));
-                }
+            // Get the weights for this grouping and make sure that there
+            // is an appropriate number of them.
+            List<String> groupingWeights = Arrays.asList(xmlConfig.getString(key + "/weights").split("\\s*,\\s*"));
+            if (groupingWeights.size() != numTxnTypes) {
+                LOG.error(String.format("Grouping \"%s\" has %d weights," + " but there are %d transactions in this" + " benchmark.", groupingName, groupingWeights.size(), numTxnTypes));
+                System.exit(-1);
+            }
 
-                int rate = 1;
-                boolean rateLimited = true;
-                boolean disabled = false;
-                boolean timed;
-
-                // can be "disabled", "unlimited" or a number
-                String rate_string;
-                rate_string = work.getString("rate[not(@bench)]", "");
-                rate_string = work.getString("rate" + pluginTest, rate_string);
-                if (rate_string.equals(RATE_DISABLED)) {
-                    disabled = true;
-                } else if (rate_string.equals(RATE_UNLIMITED)) {
-                    rateLimited = false;
-                } else if (rate_string.isEmpty()) {
-                    LOG.error(String.format("Please specify the rate for phase %d and workload %s", i, plugin));
-                    System.exit(-1);
-                } else {
-                    try {
-                        rate = Integer.parseInt(rate_string);
-                        if (rate < 1) {
-                            LOG.error("Rate limit must be at least 1. Use unlimited or disabled values instead.");
-                            System.exit(-1);
-                        }
-                    } catch (NumberFormatException e) {
-                        LOG.error(String.format("Rate string must be '%s', '%s' or a number", RATE_DISABLED, RATE_UNLIMITED));
-                        System.exit(-1);
-                    }
-                }
-                Phase.Arrival arrival = Phase.Arrival.REGULAR;
-                String arrive = work.getString("@arrival", "regular");
-                if (arrive.equalsIgnoreCase("POISSON")) {
-                    arrival = Phase.Arrival.POISSON;
-                }
+            LOG.debug("Creating grouping with name, weights: {}, {}", groupingName, groupingWeights);
+        }
 
-                // We now have the option to run all queries exactly once in
-                // a serial (rather than random) order.
-                boolean serial = Boolean.parseBoolean(work.getString("serial", Boolean.FALSE.toString()));
 
+        // ----------------------------------------------------------------
+        // WORKLOAD CONFIGURATION
+        // ----------------------------------------------------------------
 
-                int activeTerminals;
-                activeTerminals = work.getInt("active_terminals[not(@bench)]", terminals);
-                activeTerminals = work.getInt("active_terminals" + pluginTest, activeTerminals);
-                // If using serial, we should have only one terminal
-                if (serial && activeTerminals != 1) {
-                    LOG.warn("Serial ordering is enabled, so # of active terminals is clamped to 1.");
-                    activeTerminals = 1;
-                }
-                if (activeTerminals > terminals) {
-                    LOG.error(String.format("Configuration error in work %d: " + "Number of active terminals is bigger than the total number of terminals", i));
-                    System.exit(-1);
-                }
+        int size = xmlConfig.configurationsAt("/works/work").size();
+        if (size != 1) {
+            LOG.error("Only one work is allowed");
+            System.exit(-1);
+        }
 
-                time = work.getInt("/time", 0);
-                int warmup = work.getInt("/warmup", 0);
-                timed = (time > 0);
-                if (!timed) {
-                    if (serial) {
-                        LOG.info("Timer disabled for serial run; will execute" + " all queries exactly once.");
-                    } else {
-                        LOG.error("Must provide positive time bound for" + " non-serial executions. Either provide" + " a valid time or enable serial mode.");
-                        System.exit(-1);
-                    }
-                } else if (serial) {
-                    LOG.info("Timer enabled for serial run; will run queries" + " serially in a loop until the timer expires.");
-                }
-                if (warmup < 0) {
-                    LOG.error("Must provide non-negative time bound for" + " warmup.");
-                    System.exit(-1);
-                }
+        for (int i = 1; i < size + 1; i++) {
+            final HierarchicalConfiguration<ImmutableNode> work = xmlConfig.configurationAt("works/work[" + i + "]");
+            List<String> weight_strings;
 
-                wrkld.setWarmupTime(warmup);
-                ArrayList<Double> weights = new ArrayList<>();
+            // use a workaround if there are multiple workloads or single
+            // attributed workload
+            if (targetList.length > 1 || work.containsKey("weights[@bench]")) {
+                weight_strings = Arrays.asList(work.getString("weights" + pluginTest).split("\\s*,\\s*"));
+            } else {
+                weight_strings = Arrays.asList(work.getString("weights[not(@bench)]").split("\\s*,\\s*"));
+            }
 
-                double totalWeight = 0;
+            Phase.Arrival arrival = Phase.Arrival.REGULAR;
+            String arrive = work.getString("@arrival", "regular");
+            if (arrive.equalsIgnoreCase("POISSON")) {
+                arrival = Phase.Arrival.POISSON;
+            }
 
-                for (String weightString : weight_strings) {
-                    double weight = Double.parseDouble(weightString);
-                    totalWeight += weight;
-                    weights.add(weight);
-                }
+            int activeTerminals;
+            activeTerminals = work.getInt("active_terminals[not(@bench)]", terminals);
+            activeTerminals = work.getInt("active_terminals" + pluginTest, activeTerminals);
 
-                long roundedWeight = Math.round(totalWeight);
+            if (activeTerminals > terminals) {
+                LOG.error(String.format("Configuration error in work %d: " + "Number of active terminals is bigger than the total number of terminals", i));
+                System.exit(-1);
+            }
 
-                if (roundedWeight != 100) {
-                    LOG.warn("rounded weight [{}] does not equal 100.  Original weight is [{}]", roundedWeight, totalWeight);
-                }
+            time = work.getInt("/time", 0);
+            int warmup = work.getInt("/warmup", 0);
+            boolean timed = (time > 0);
+            if (!timed) {
+                LOG.error("Must provide positive time bound executions.");
+                System.exit(-1);
+            }
+            if (warmup < 0) {
+                LOG.error("Must provide non-negative time bound for" + " warmup.");
+                System.exit(-1);
+            }
 
+            wrkld.setWarmupTime(warmup);
+            ArrayList<Double> weights = new ArrayList<>();
 
-                wrkld.addPhase(i, time, warmup, rate, weights, rateLimited, disabled, serial, timed, activeTerminals, arrival);
-            }
+            double totalWeight = 0;
 
-            // CHECKING INPUT PHASES
-            int j = 0;
-            for (Phase p : wrkld.getPhases()) {
-                j++;
-                if (p.getWeightCount() != numTxnTypes) {
-                    LOG.error(String.format("Configuration files is inconsistent, phase %d contains %d weights but you defined %d transaction types", j, p.getWeightCount(), numTxnTypes));
-                    if (p.isSerial()) {
-                        LOG.error("However, note that since this a serial phase, the weights are irrelevant (but still must be included---sorry).");
-                    }
-                    System.exit(-1);
-                }
+            for (String weightString : weight_strings) {
+                double weight = Double.parseDouble(weightString);
+                totalWeight += weight;
+                weights.add(weight);
             }
 
-            // Generate the dialect map
-            wrkld.init();
+            long roundedWeight = Math.round(totalWeight);
 
+            if (roundedWeight != 100) {
+                LOG.warn("rounded weight [{}] does not equal 100.  Original weight is [{}]", roundedWeight, totalWeight);
+            }
 
+            wrkld.setPhase(i, time, warmup, weights, timed, activeTerminals, arrival);
         }
 
-
-        // Export StatementDialects
-        if (isBooleanOptionSet(argsLine, "dialects-export")) {
-            BenchmarkModule bench = benchList.get(0);
-            if (bench.getStatementDialects() != null) {
-                LOG.info("Exporting StatementDialects for {}", bench);
-                String xml = bench.getStatementDialects().export(bench.getWorkloadConfiguration().getDatabaseType(), bench.getProcedures().values());
-                LOG.debug(xml);
-                System.exit(0);
-            }
-            throw new RuntimeException("No StatementDialects is available for " + bench);
+        Phase phase = wrkld.getPhase();
+        if (phase.getWeightCount() != numTxnTypes) {
+            LOG.error(String.format("Configuration files is inconsistent: contains %d weights but you defined %d transaction types", phase.getWeightCount(), numTxnTypes));
+            System.exit(-1);
         }
 
+        // Generate the dialect map
+        wrkld.init();
+
         // Create the Benchmark's Database
         if (isBooleanOptionSet(argsLine, "create")) {
             try {
-                for (BenchmarkModule benchmark : benchList) {
-                    LOG.info("Creating new {} database...", benchmark.getBenchmarkName().toUpperCase());
-                    runCreator(benchmark);
-                    LOG.info("Finished creating new {} database...", benchmark.getBenchmarkName().toUpperCase());
-                }
+                LOG.info("Creating new {} database...", benchmark.getBenchmarkName().toUpperCase());
+                runCreator(benchmark);
+                LOG.info("Finished creating new {} database...", benchmark.getBenchmarkName().toUpperCase());
             } catch (Throwable ex) {
                 LOG.error("Unexpected error when creating benchmark database tables.", ex);
                 System.exit(1);
@@ -443,21 +384,16 @@ public static void main(String[] args) throws Exception {
             LOG.debug("Skipping creating benchmark database tables");
         }
 
-        // Refresh the catalog.
-        for (BenchmarkModule benchmark : benchList) {
-            benchmark.refreshCatalog();
-        }
+        benchmark.refreshCatalog();
 
         // Clear the Benchmark's Database
         if (isBooleanOptionSet(argsLine, "clear")) {
             try {
-                for (BenchmarkModule benchmark : benchList) {
-                    LOG.info("Clearing {} database...", benchmark.getBenchmarkName().toUpperCase());
-                    benchmark.refreshCatalog();
-                    benchmark.clearDatabase();
-                    benchmark.refreshCatalog();
-                    LOG.info("Finished clearing {} database...", benchmark.getBenchmarkName().toUpperCase());
-                }
+                LOG.info("Clearing {} database...", benchmark.getBenchmarkName().toUpperCase());
+                benchmark.refreshCatalog();
+                benchmark.clearDatabase();
+                benchmark.refreshCatalog();
+                LOG.info("Finished clearing {} database...", benchmark.getBenchmarkName().toUpperCase());
             } catch (Throwable ex) {
                 LOG.error("Unexpected error when clearing benchmark database tables.", ex);
                 System.exit(1);
@@ -469,11 +405,9 @@ public static void main(String[] args) throws Exception {
         // Execute Loader
         if (isBooleanOptionSet(argsLine, "load")) {
             try {
-                for (BenchmarkModule benchmark : benchList) {
-                    LOG.info("Loading data into {} database...", benchmark.getBenchmarkName().toUpperCase());
-                    runLoader(benchmark);
-                    LOG.info("Finished loading data into {} database...", benchmark.getBenchmarkName().toUpperCase());
-                }
+                LOG.info("Loading data into {} database...", benchmark.getBenchmarkName().toUpperCase());
+                runLoader(benchmark);
+                LOG.info("Finished loading data into {} database...", benchmark.getBenchmarkName().toUpperCase());
             } catch (Throwable ex) {
                 LOG.error("Unexpected error when loading benchmark database records.", ex);
                 System.exit(1);
@@ -487,7 +421,7 @@ public static void main(String[] args) throws Exception {
         if (isBooleanOptionSet(argsLine, "execute")) {
             // Bombs away!
             try {
-                Results r = runWorkload(benchList, intervalMonitor);
+                Results r = runWorkload(benchmark, intervalMonitor);
                 printToplineResults(r);
                 writeOutputs(r, activeTXTypes, argsLine, xmlConfig);
                 writeHistograms(r);
@@ -520,7 +454,6 @@ private static Options buildOptions(XMLConfiguration pluginConfig) {
         options.addOption("s", "sample", true, "Sampling window");
         options.addOption("im", "interval-monitor", true, "Throughput Monitoring Interval in milliseconds");
         options.addOption("d", "directory", true, "Base directory for the result files, default is current directory");
-        options.addOption(null, "dialects-export", true, "Export benchmark SQL to a dialects file");
         options.addOption("jh", "json-histograms", true, "Export histograms to JSON file");
         options.addOption("sf", "start-from-id", true, "Start from a specific scale instance id");
         options.addOption("rt", "real-threads", false, "Use real threads");
@@ -642,19 +575,17 @@ private static void runLoader(BenchmarkModule bench) throws SQLException, Interr
         bench.loadDatabase();
     }
 
-    private static Results runWorkload(List<BenchmarkModule> benchList, int intervalMonitor) throws IOException {
+    private static Results runWorkload(BenchmarkModule benchmark, int intervalMonitor) throws IOException {
         List<Worker<?>> workers = new ArrayList<>();
         List<WorkloadConfiguration> workConfs = new ArrayList<>();
-        for (BenchmarkModule bench : benchList) {
-            LOG.info("Creating {} virtual terminals...", bench.getWorkloadConfiguration().getTerminals());
-            workers.addAll(bench.makeWorkers());
 
-            int num_phases = bench.getWorkloadConfiguration().getNumberOfPhases();
-            LOG.info(String.format("Launching the %s Benchmark with %s Phase%s...", bench.getBenchmarkName().toUpperCase(), num_phases, (num_phases > 1 ? "s" : "")));
-            workConfs.add(bench.getWorkloadConfiguration());
+        LOG.info("Creating {} virtual terminals...", benchmark.getWorkloadConfiguration().getTerminals());
+        workers.addAll(benchmark.makeWorkers());
 
-        }
-        Results r = ThreadBench.runRateLimitedBenchmark(workers, workConfs, intervalMonitor, useRealThreads);
+        LOG.info(String.format("Launching the %s Benchmark", benchmark.getBenchmarkName().toUpperCase()));
+        WorkloadConfiguration workConf = benchmark.getWorkloadConfiguration();
+
+        Results r = ThreadBench.runBenchmark(workers, workConf, intervalMonitor, useRealThreads);
         return r;
     }
 
@@ -671,7 +602,7 @@ private static void printToplineResults(Results r) {
                 + String.format("%18s | %18d\n", "NewOrders", numNewOrderTransactions)
                 + String.format("%18s | %18.2f\n", "TPM-C", tpmc)
                 + String.format("%18s | %17.2f%%\n", "Efficiency", efficiency)
-                + String.format("Rate limited reqs/s: %s\n", r);
+                + String.format("reqs/s: %s\n", r);
 
         LOG.info(SINGLE_LINE);
         LOG.info(resultOut);
diff --git a/src/main/java/com/oltpbenchmark/Phase.java b/src/main/java/com/oltpbenchmark/Phase.java
index d4da78bb..b599ddab 100644
--- a/src/main/java/com/oltpbenchmark/Phase.java
+++ b/src/main/java/com/oltpbenchmark/Phase.java
@@ -21,79 +21,48 @@
 
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Random;
+
+import java.util.concurrent.ThreadLocalRandom;
 
 public class Phase {
     public enum Arrival {
         REGULAR, POISSON,
     }
 
-    private final Random gen = new Random();
     private final String benchmarkName;
     private final int id;
     private final int time;
     private final int warmupTime;
-    private final int rate;
     private final Arrival arrival;
 
-
-    private final boolean rateLimited;
-    private final boolean disabled;
-    private final boolean serial;
     private final boolean timed;
     private final List<Double> weights;
+    private final int totalWeight;
     private final int weightCount;
     private final int activeTerminals;
-    private int nextSerial;
-
 
-    Phase(String benchmarkName, int id, int t, int wt, int r, List<Double> weights, boolean rateLimited, boolean disabled, boolean serial, boolean timed, int activeTerminals, Arrival a) {
+    Phase(String benchmarkName, int id, int t, int wt, List<Double> weights, boolean timed, int activeTerminals, Arrival a) {
         this.benchmarkName = benchmarkName;
         this.id = id;
         this.time = t;
         this.warmupTime = wt;
-        this.rate = r;
         this.weights = weights;
         this.weightCount = this.weights.size();
-        this.rateLimited = rateLimited;
-        this.disabled = disabled;
-        this.serial = serial;
         this.timed = timed;
-        this.nextSerial = 1;
         this.activeTerminals = activeTerminals;
         this.arrival = a;
-    }
-
-
 
-    public boolean isRateLimited() {
-        return rateLimited;
-    }
-
-    public boolean isDisabled() {
-        return disabled;
-    }
-
-    public boolean isSerial() {
-        return serial;
+        double total = 0;
+        for (Double d : weights) {
+            total += d;
+        }
+        this.totalWeight = (int)total;
     }
 
     public boolean isTimed() {
         return timed;
     }
 
-    public boolean isLatencyRun() {
-        return !timed && serial;
-    }
-
-    public boolean isThroughputRun() {
-        return !isLatencyRun();
-    }
-
-    public void resetSerial() {
-        this.nextSerial = 1;
-    }
-
     public int getActiveTerminals() {
         return activeTerminals;
     }
@@ -114,10 +83,6 @@ public int getWarmupTime() {
         return warmupTime;
     }
 
-    public int getRate() {
-        return rate;
-    }
-
     public Arrival getArrival() {
         return arrival;
     }
@@ -126,19 +91,6 @@ public List<Double> getWeights() {
         return (this.weights);
     }
 
-    /**
-     * Computes the sum of weights. Usually needs to add up to 100%
-     *
-     * @return The total weight
-     */
-    public double totalWeight() {
-        double total = 0.0;
-        for (Double d : weights) {
-            total += d;
-        }
-        return total;
-    }
-
     /**
      * This simply computes the next transaction by randomly selecting one based
      * on the weights of this phase.
@@ -146,49 +98,12 @@ public double totalWeight() {
      * @return
      */
     public int chooseTransaction() {
-        return chooseTransaction(false);
-    }
-
-    public int chooseTransaction(boolean isColdQuery) {
-        if (isDisabled()) {
-            return -1;
-        }
-
-        if (isSerial()) {
-            int ret;
-            synchronized (this) {
-                ret = this.nextSerial;
-
-                // Serial runs should not execute queries with non-positive
-                // weights.
-                while (ret <= this.weightCount && weights.get(ret - 1) <= 0.0) {
-                    ret = ++this.nextSerial;
-                }
-
-                // If it's a cold execution, then we don't want to advance yet,
-                // since the hot run needs to execute the same query.
-                if (!isColdQuery) {
-
-                    // throughput) run, so we loop through the list multiple
-                    // times. Note that we do the modulus before the increment
-                    // so that we end up in the range [1,num_weights]
-                    if (isTimed()) {
-
-                        this.nextSerial %= this.weightCount;
-                    }
-
-                    ++this.nextSerial;
-                }
-            }
-            return ret;
-        } else {
-            int randomPercentage = gen.nextInt((int) totalWeight()) + 1;
-            double weight = 0.0;
-            for (int i = 0; i < this.weightCount; i++) {
-                weight += weights.get(i);
-                if (randomPercentage <= weight) {
-                    return i + 1;
-                }
+        int randomPercentage = ThreadLocalRandom.current().nextInt(totalWeight) + 1;
+        double weight = 0.0;
+        for (int i = 0; i < this.weightCount; i++) {
+            weight += weights.get(i);
+            if (randomPercentage <= weight) {
+                return i + 1;
             }
         }
 
@@ -201,22 +116,11 @@ public int chooseTransaction(boolean isColdQuery) {
     public String currentPhaseString() {
         List<String> inner = new ArrayList<>();
         inner.add("[Workload=" + benchmarkName.toUpperCase() + "]");
-        if (isDisabled()) {
-            inner.add("[Disabled=true]");
-        } else {
-            if (isLatencyRun()) {
-                inner.add("[Serial=true]");
-                inner.add("[Time=n/a]");
-            } else {
-                inner.add("[Serial=" + isSerial() + "]");
-                inner.add("[Time=" + time + "]");
-            }
-            inner.add("[WarmupTime=" + warmupTime + "]");
-            inner.add("[Rate=" + (isRateLimited() ? rate : "unlimited") + "]");
-            inner.add("[Arrival=" + arrival + "]");
-            inner.add("[Ratios=" + getWeights() + "]");
-            inner.add("[ActiveWorkers=" + getActiveTerminals() + "]");
-        }
+        inner.add("[Time=" + time + "]");
+        inner.add("[WarmupTime=" + warmupTime + "]");
+        inner.add("[Arrival=" + arrival + "]");
+        inner.add("[Ratios=" + getWeights() + "]");
+        inner.add("[ActiveWorkers=" + getActiveTerminals() + "]");
 
         return StringUtil.bold("PHASE START") + " :: " + StringUtil.join(" ", inner);
     }
diff --git a/src/main/java/com/oltpbenchmark/ThreadBench.java b/src/main/java/com/oltpbenchmark/ThreadBench.java
index b7bb9a2c..4a50e9ca 100644
--- a/src/main/java/com/oltpbenchmark/ThreadBench.java
+++ b/src/main/java/com/oltpbenchmark/ThreadBench.java
@@ -17,11 +17,9 @@
 
 package com.oltpbenchmark;
 
-import com.oltpbenchmark.ResultStats;
 import com.oltpbenchmark.api.BenchmarkModule;
 import com.oltpbenchmark.api.TransactionType;
 import com.oltpbenchmark.api.Worker;
-import com.oltpbenchmark.types.State;
 import com.oltpbenchmark.util.StringUtil;
 import org.apache.commons.collections4.map.ListOrderedMap;
 import org.slf4j.Logger;
@@ -32,35 +30,37 @@
 public class ThreadBench implements Thread.UncaughtExceptionHandler {
     private static final Logger LOG = LoggerFactory.getLogger(ThreadBench.class);
 
-    private final BenchmarkState testState;
+    private final BenchmarkState benchmarkState;
     private final List<? extends Worker<? extends BenchmarkModule>> workers;
     private final ArrayList<Thread> workerThreads;
-    private final List<WorkloadConfiguration> workConfs;
+    private final WorkloadConfiguration workConf;
     private final ResultStats resultStats;
     private final int intervalMonitor;
     private final Boolean useRealThreads;
 
     private ThreadBench(List<? extends Worker<? extends BenchmarkModule>> workers,
-            List<WorkloadConfiguration> workConfs, int intervalMonitoring, Boolean useRealThreads) {
+            WorkloadConfiguration workConf, int intervalMonitoring, Boolean useRealThreads) {
         this.workers = workers;
-        this.workConfs = workConfs;
+        this.workConf = workConf;
         this.workerThreads = new ArrayList<>(workers.size());
         this.intervalMonitor = intervalMonitoring;
-        this.testState = new BenchmarkState(workers.size() + 1);
+        this.benchmarkState = new BenchmarkState(workers.size() + 1, workConf);
         this.resultStats = new ResultStats();
         this.useRealThreads = useRealThreads;
+
+        for (Worker<?> worker : workers) {
+            worker.setBenchmarkState(this.benchmarkState);
+        }
     }
 
-    public static Results runRateLimitedBenchmark(List<Worker<? extends BenchmarkModule>> workers,
-            List<WorkloadConfiguration> workConfs, int intervalMonitoring, Boolean useRealThreads) {
-        ThreadBench bench = new ThreadBench(workers, workConfs, intervalMonitoring, useRealThreads);
-        return bench.runRateLimitedMultiPhase();
+    public static Results runBenchmark(List<Worker<? extends BenchmarkModule>> workers,
+            WorkloadConfiguration workConf, int intervalMonitoring, Boolean useRealThreads) {
+        ThreadBench bench = new ThreadBench(workers, workConf, intervalMonitoring, useRealThreads);
+        return bench.runBenchmark();
     }
 
     private void createWorkerThreads() {
-
         for (Worker<?> worker : workers) {
-            worker.initializeState();
             Thread thread;
             if (useRealThreads) {
                 thread = new Thread(worker);
@@ -73,14 +73,7 @@ private void createWorkerThreads() {
         }
     }
 
-    private void interruptWorkers() {
-        for (Worker<?> worker : workers) {
-            worker.cancelStatement();
-        }
-    }
-
     private long finalizeWorkers(ArrayList<Thread> workerThreads) throws InterruptedException {
-
         long requests = 0;
 
         new WatchDogThread().start();
@@ -109,55 +102,15 @@ private long finalizeWorkers(ArrayList<Thread> workerThreads) throws Interrupted
         return requests;
     }
 
-    private Results runRateLimitedMultiPhase() {
-        List<WorkloadState> workStates = new ArrayList<>();
-
-        for (WorkloadConfiguration workState : this.workConfs) {
-            workState.initializeState(testState);
-            workStates.add(workState.getWorkloadState());
-        }
-
+    private Results runBenchmark() {
         this.createWorkerThreads();
 
-        // long measureStart = start;
+        Phase phase = this.workConf.getPhase();
+        LOG.info(phase.currentPhaseString());
 
-        long start = System.nanoTime();
-        long warmupStart = System.nanoTime();
-        long warmup = warmupStart;
-        long measureEnd = -1;
-        // used to determine the longest sleep interval
-        int lowestRate = Integer.MAX_VALUE;
-
-        Phase phase = null;
-
-        for (WorkloadState workState : workStates) {
-            workState.switchToNextPhase();
-            phase = workState.getCurrentPhase();
-            LOG.info(phase.currentPhaseString());
-            if (phase.getRate() < lowestRate) {
-                lowestRate = phase.getRate();
-            }
-        }
-
-        // Change testState to cold query if execution is serial, since we don't
-        // have a warm-up phase for serial execution but execute a cold and a
-        // measured query in sequence.
-        if (phase != null && phase.isLatencyRun()) {
-            synchronized (testState) {
-                testState.startColdQuery();
-            }
-        }
-
-        long intervalNs = getInterval(lowestRate, phase.getArrival());
-
-        long nextInterval = start + intervalNs;
-        int nextToAdd = 1;
-        int rateFactor;
-
-        boolean resetQueues = true;
-
-        long delta = phase.getTime() * 1000000000L;
-        boolean lastEntry = false;
+        final long start = System.nanoTime();
+        final long warmupStart = start;
+        final long warmupEnd = warmupStart + phase.getWarmupTime() * 1000000000L;
 
         // Initialize the Monitor
         if (this.intervalMonitor > 0) {
@@ -165,144 +118,37 @@ private Results runRateLimitedMultiPhase() {
         }
 
         // Allow workers to start work.
-        testState.blockForStart();
+        benchmarkState.blockForStart();
 
-        // Main Loop
-        while (true) {
-            // posting new work... and resetting the queue in case we have new
-            // portion of the workload...
-
-            for (WorkloadState workState : workStates) {
-                if (workState.getCurrentPhase() != null) {
-                    rateFactor = workState.getCurrentPhase().getRate() / lowestRate;
-                } else {
-                    rateFactor = 1;
-                }
-                workState.addToQueue(nextToAdd * rateFactor, resetQueues);
-            }
-            resetQueues = false;
-
-            // Wait until the interval expires, which may be "don't wait"
-            long now = System.nanoTime();
-            if (phase != null) {
-                warmup = warmupStart + phase.getWarmupTime() * 1000000000L;
-            }
-            long diff = nextInterval - now;
-            while (diff > 0) { // this can wake early: sleep multiple times to avoid that
-                long ms = diff / 1000000;
-                diff = diff % 1000000;
+        final long warmupS = (warmupEnd - warmupStart) / 1000000000;
+        if (warmupS > 0) {
+            LOG.info("{} :: Warming up for {}s", StringUtil.bold("WARMUP"), warmupS);
+            while (System.nanoTime() < warmupEnd) {
                 try {
-                    Thread.sleep(ms, (int) diff);
+                    Thread.sleep(1000);
                 } catch (InterruptedException e) {
                     throw new RuntimeException(e);
                 }
-                now = System.nanoTime();
-                diff = nextInterval - now;
-            }
-
-            boolean phaseComplete = false;
-            if (phase != null) {
-                if (phase.isLatencyRun())
-                // Latency runs (serial run through each query) have their own
-                // state to mark completion
-                {
-                    phaseComplete = testState.getState() == State.LATENCY_COMPLETE;
-                } else {
-                    phaseComplete = testState.getState() == State.MEASURE
-                            && (start + delta <= now);
-                }
             }
+        }
 
-            // Go to next phase if this one is complete or enter if error was thrown
-            boolean errorThrown = testState.getState() == State.ERROR;
-            if ((phaseComplete || errorThrown) && !lastEntry) {
-                // enters here after each phase of the test
-                // reset the queues so that the new phase is not affected by the
-                // queue of the previous one
-                resetQueues = true;
-
-                // Fetch a new Phase
-                synchronized (testState) {
-                    if (phase.isLatencyRun()) {
-                        testState.ackLatencyComplete();
-                    }
-                    for (WorkloadState workState : workStates) {
-                        synchronized (workState) {
-                            workState.switchToNextPhase();
-                            lowestRate = Integer.MAX_VALUE;
-                            phase = workState.getCurrentPhase();
-                            interruptWorkers();
-                            if (phase == null && !lastEntry) {
-                                // Last phase
-                                lastEntry = true;
-                                testState.startCoolDown();
-                                measureEnd = now;
-                                LOG.info("{} :: Waiting for all terminals to finish ..", StringUtil.bold("TERMINATE"));
-                            } else if (phase != null) {
-                                // Reset serial execution parameters.
-                                if (phase.isLatencyRun()) {
-                                    phase.resetSerial();
-                                    testState.startColdQuery();
-                                }
-                                LOG.info(phase.currentPhaseString());
-                                if (phase.getRate() < lowestRate) {
-                                    lowestRate = phase.getRate();
-                                }
-                            }
-                        }
-                    }
-                    if (phase != null) {
-                        // update frequency in which we check according to
-                        // wakeup
-                        // speed
-                        // intervalNs = (long) (1000000000. / (double)
-                        // lowestRate + 0.5);
-                        delta += phase.getTime() * 1000000000L;
-                    }
-                }
-            }
+        final long stopAt = System.nanoTime() + phase.getTime() * 1000000000L;
+        benchmarkState.startMeasure();
 
-            // Compute the next interval
-            // and how many messages to deliver
-            if (phase != null) {
-                intervalNs = 0;
-                nextToAdd = 0;
-                do {
-                    intervalNs += getInterval(lowestRate, phase.getArrival());
-                    nextToAdd++;
-                } while ((-diff) > intervalNs && !lastEntry);
-                nextInterval += intervalNs;
-            }
+        LOG.info("{} :: Warmup complete, starting measurements.", StringUtil.bold("MEASURE"));
 
-            // Update the test state appropriately
-            State state = testState.getState();
-            if (state == State.WARMUP && now >= warmup) {
-                synchronized (testState) {
-                    if (phase != null && phase.isLatencyRun()) {
-                        testState.startColdQuery();
-                    } else {
-                        testState.startMeasure();
-                    }
-                    interruptWorkers();
-                }
-                start = now;
-                LOG.info("{} :: Warmup complete, starting measurements.", StringUtil.bold("MEASURE"));
-                // measureEnd = measureStart + measureSeconds * 1000000000L;
-
-                // For serial executions, we want to do every query exactly
-                // once, so we need to restart in case some of the queries
-                // began during the warmup phase.
-                // If we're not doing serial executions, this function has no
-                // effect and is thus safe to call regardless.
-                phase.resetSerial();
-            } else if (state == State.EXIT) {
-                // All threads have noticed the done, meaning all measured
-                // requests have definitely finished.
-                // Time to quit.
-                break;
+        // Main Loop
+        while (benchmarkState.isWorkingOrMeasuring() && System.nanoTime() < stopAt) {
+            try {
+                Thread.sleep(1000);
+            } catch (InterruptedException e) {
+                throw new RuntimeException(e);
             }
         }
 
+        final long measureEnd = System.nanoTime();
+        benchmarkState.stopWorkers();
+
         try {
             long requests = finalizeWorkers(this.workerThreads);
 
@@ -314,9 +160,7 @@ private Results runRateLimitedMultiPhase() {
 
             // Compute transaction histogram
             Set<TransactionType> txnTypes = new HashSet<>();
-            for (WorkloadConfiguration workConf : workConfs) {
-                txnTypes.addAll(workConf.getTransTypes());
-            }
+            txnTypes.addAll(workConf.getTransTypes());
             txnTypes.remove(TransactionType.INVALID);
 
             results.getUnknown().putAll(txnTypes, 0);
@@ -341,15 +185,6 @@ private Results runRateLimitedMultiPhase() {
         }
     }
 
-    private long getInterval(int lowestRate, Phase.Arrival arrival) {
-        // TODO Auto-generated method stub
-        if (arrival == Phase.Arrival.POISSON) {
-            return (long) ((-Math.log(1 - Math.random()) / lowestRate) * 1000000000.);
-        } else {
-            return (long) (1000000000. / (double) lowestRate + 0.5);
-        }
-    }
-
     @Override
     public void uncaughtException(Thread t, Throwable e) {
         // Here we handle the case in which one of our worker threads died
@@ -358,19 +193,8 @@ public void uncaughtException(Thread t, Throwable e) {
         // phases that were left in the test and signal error state.
         // The rest of the workflow to finish the experiment remains the same,
         // and partial metrics will be reported (i.e., until failure happened).
-        synchronized (testState) {
-            for (WorkloadConfiguration workConf : this.workConfs) {
-                synchronized (workConf.getWorkloadState()) {
-                    WorkloadState workState = workConf.getWorkloadState();
-                    Phase phase = workState.getCurrentPhase();
-                    while (phase != null) {
-                        workState.switchToNextPhase();
-                        phase = workState.getCurrentPhase();
-                    }
-                }
-            }
-            testState.signalError();
-        }
+
+        benchmarkState.signalError();
     }
 
     private class WatchDogThread extends Thread {
@@ -424,10 +248,8 @@ public void run() {
 
                 // Compute the last throughput
                 long measuredRequests = 0;
-                synchronized (testState) {
-                    for (Worker<?> w : workers) {
-                        measuredRequests += w.getAndResetIntervalRequests();
-                    }
+                for (Worker<?> w : workers) {
+                    measuredRequests += w.getAndResetIntervalRequests();
                 }
                 double seconds = this.intervalMonitor / 1000d;
                 double tps = (double) measuredRequests / seconds;
@@ -435,5 +257,4 @@ public void run() {
             }
         }
     }
-
 }
diff --git a/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java b/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
index 351803b7..1bac7699 100644
--- a/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
+++ b/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
@@ -29,7 +29,7 @@
 
 public class WorkloadConfiguration {
 
-    private final List<Phase> phases = new ArrayList<>();
+    private Phase phase = null;
     private DatabaseType databaseType;
     private String benchmarkName;
     private String url;
@@ -47,7 +47,6 @@ public class WorkloadConfiguration {
     private int loaderThreads = ThreadUtil.availableProcessors();
     private int warmupTime = 0;
     private XMLConfiguration xmlConfig = null;
-    private WorkloadState workloadState;
     private TransactionTypes transTypes = null;
     private int isolationMode = Connection.TRANSACTION_SERIALIZABLE;
     private String dataDir = null;
@@ -67,10 +66,6 @@ public void setBenchmarkName(String benchmarkName) {
         this.benchmarkName = benchmarkName;
     }
 
-    public WorkloadState getWorkloadState() {
-        return workloadState;
-    }
-
     public DatabaseType getDatabaseType() {
         return databaseType;
     }
@@ -152,20 +147,10 @@ public void setNewConnectionPerTxn(boolean newConnectionPerTxn) {
         this.newConnectionPerTxn = newConnectionPerTxn;
     }
 
-    /**
-     * Initiate a new benchmark and workload state
-     */
-    public void initializeState(BenchmarkState benchmarkState) {
-        this.workloadState = new WorkloadState(benchmarkState, phases, terminals);
-    }
-
-    public void addPhase(int id, int time, int warmup, int rate, List<Double> weights, boolean rateLimited, boolean disabled, boolean serial, boolean timed, int active_terminals, Phase.Arrival arrival) {
-        phases.add(new Phase(benchmarkName, id, time, warmup, rate, weights, rateLimited, disabled, serial, timed, active_terminals, arrival));
+    public void setPhase(int id, int time, int warmup, List<Double> weights, boolean timed, int active_terminals, Phase.Arrival arrival) {
+        this.phase = new Phase(benchmarkName, id, time, warmup, weights, timed, active_terminals, arrival);
     }
 
-
-
-
     /**
      * The number of loader threads that the framework is allowed to use.
      *
@@ -228,15 +213,6 @@ public void setScaleFactor(double scaleFactor) {
         this.scaleFactor = scaleFactor;
     }
 
-    /**
-     * Return the number of phases specified in the config file
-     *
-     * @return
-     */
-    public int getNumberOfPhases() {
-        return phases.size();
-    }
-
     /**
      * Return the directory in which we can find the data files (for example, CSV
      * files) for loading the database.
@@ -302,8 +278,8 @@ public void setTransTypes(TransactionTypes transTypes) {
         this.transTypes = transTypes;
     }
 
-    public List<Phase> getPhases() {
-        return phases;
+    public Phase getPhase() {
+        return this.phase;
     }
 
     public XMLConfiguration getXmlConfig() {
@@ -352,7 +328,7 @@ public String getIsolationString() {
     @Override
     public String toString() {
         return "WorkloadConfiguration{" +
-               "phases=" + phases +
+               "phase=" + phase +
                ", databaseType=" + databaseType +
                ", benchmarkName='" + benchmarkName + '\'' +
                ", url='" + url + '\'' +
@@ -365,7 +341,6 @@ public String toString() {
                ", selectivity=" + selectivity +
                ", terminals=" + terminals +
                ", loaderThreads=" + loaderThreads +
-               ", workloadState=" + workloadState +
                ", transTypes=" + transTypes +
                ", isolationMode=" + isolationMode +
                ", dataDir='" + dataDir + '\'' +
diff --git a/src/main/java/com/oltpbenchmark/WorkloadState.java b/src/main/java/com/oltpbenchmark/WorkloadState.java
deleted file mode 100644
index de12ec8c..00000000
--- a/src/main/java/com/oltpbenchmark/WorkloadState.java
+++ /dev/null
@@ -1,265 +0,0 @@
-/*
- * Copyright 2020 by OLTPBenchmark Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- *
- */
-
-package com.oltpbenchmark;
-
-import com.oltpbenchmark.types.State;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.Iterator;
-import java.util.LinkedList;
-import java.util.List;
-
-/**
- * This class is used to share a state among the workers of a single
- * workload. Worker use it to ask for work and as interface to the global
- * BenchmarkState
- *
- * @author alendit
- */
-public class WorkloadState {
-    private static final int RATE_QUEUE_LIMIT = 10000;
-    private static final Logger LOG = LoggerFactory.getLogger(WorkloadState.class);
-
-    private final BenchmarkState benchmarkState;
-    private final LinkedList<SubmittedProcedure> workQueue = new LinkedList<>();
-    private final int num_terminals;
-    private final Iterator<Phase> phaseIterator;
-
-    private int workersWaiting = 0;
-    private int workersWorking = 0;
-    private int workerNeedSleep;
-
-    private Phase currentPhase = null;
-
-    public WorkloadState(BenchmarkState benchmarkState, List<Phase> works, int num_terminals) {
-        this.benchmarkState = benchmarkState;
-        this.num_terminals = num_terminals;
-        this.workerNeedSleep = num_terminals;
-
-        phaseIterator = works.iterator();
-    }
-
-    /**
-     * Add a request to do work.
-     */
-    public void addToQueue(int amount, boolean resetQueues) {
-        int workAdded = 0;
-        
-        synchronized (this) {
-            if (resetQueues) {
-                workQueue.clear();
-            }
-
-            // Only use the work queue if the phase is enabled and rate limited.
-            if (currentPhase == null || currentPhase.isDisabled()
-                    || !currentPhase.isRateLimited() || currentPhase.isSerial()) {
-                return;
-            }
-            
-            // Add the specified number of procedures to the end of the queue.
-            // If we can't keep up with current rate, truncate transactions
-            for (int i = 0; i < amount && workQueue.size() <= RATE_QUEUE_LIMIT; ++i) {
-                workQueue.add(new SubmittedProcedure(currentPhase.chooseTransaction()));
-                workAdded++;
-            }
-
-            // Wake up sleeping workers to deal with the new work.
-            int numToWake = Math.min(workAdded, workersWaiting);
-            while (numToWake-- > 0) {
-                this.notify();
-            }
-        }
-    }
-
-    public void signalDone() {
-        int current = this.benchmarkState.signalDone();
-        if (current == 0) {
-            synchronized (this) {
-                if (workersWaiting > 0) {
-                    this.notifyAll();
-                }
-            }
-        }
-    }
-
-    /**
-     * Called by ThreadPoolThreads when waiting for work.
-     */
-    public SubmittedProcedure fetchWork() {
-        synchronized (this) {
-            if (currentPhase != null && currentPhase.isSerial()) {
-                ++workersWaiting;
-                while (getGlobalState() == State.LATENCY_COMPLETE) {
-                    try {
-                        this.wait();
-                    } catch (InterruptedException e) {
-                        throw new RuntimeException(e);
-                    }
-                }
-                --workersWaiting;
-
-                if (getGlobalState() == State.EXIT || getGlobalState() == State.DONE) {
-                    return null;
-                }
-
-                ++workersWorking;
-                return new SubmittedProcedure(currentPhase.chooseTransaction(getGlobalState() == State.COLD_QUERY));
-            }
-        }
-
-        // Unlimited-rate phases don't use the work queue.
-        if (currentPhase != null && !currentPhase.isRateLimited()) {
-            synchronized (this) {
-                ++workersWorking;
-            }
-            return new SubmittedProcedure(currentPhase.chooseTransaction(getGlobalState() == State.COLD_QUERY));
-        }
-
-        synchronized (this) {
-            // Sleep until work is available.
-            if (workQueue.peek() == null) {
-                workersWaiting += 1;
-                while (workQueue.peek() == null) {
-                    if (this.benchmarkState.getState() == State.EXIT
-                            || this.benchmarkState.getState() == State.DONE) {
-                        return null;
-                    }
-
-                    try {
-                        this.wait();
-                    } catch (InterruptedException e) {
-                        throw new RuntimeException(e);
-                    }
-                }
-                workersWaiting -= 1;
-            }
-
-
-            ++workersWorking;
-
-            return workQueue.remove();
-        }
-    }
-
-    public void finishedWork() {
-        synchronized (this) {
-
-            --workersWorking;
-        }
-    }
-
-    public Phase getNextPhase() {
-        if (phaseIterator.hasNext()) {
-            return phaseIterator.next();
-        }
-        return null;
-    }
-
-    public Phase getCurrentPhase() {
-        synchronized (benchmarkState) {
-            return currentPhase;
-        }
-    }
-
-    /*
-     * Called by workers to ask if they should stay awake in this phase
-     */
-    public void stayAwake() {
-        synchronized (this) {
-            while (workerNeedSleep > 0) {
-                workerNeedSleep--;
-                try {
-                    this.wait();
-                } catch (InterruptedException e) {
-                    LOG.error(e.getMessage(), e);
-                }
-            }
-        }
-    }
-
-    public void switchToNextPhase() {
-        synchronized (this) {
-            this.currentPhase = this.getNextPhase();
-
-            // Clear the work from the previous phase.
-            workQueue.clear();
-
-            // Determine how many workers need to sleep, then make sure they
-            // do.
-            if (this.currentPhase == null)
-            // Benchmark is over---wake everyone up so they can terminate
-            {
-                workerNeedSleep = 0;
-            } else {
-                this.currentPhase.resetSerial();
-                if (this.currentPhase.isDisabled())
-                // Phase disabled---everyone should sleep
-                {
-                    workerNeedSleep = this.num_terminals;
-                } else
-                // Phase running---activate the appropriate # of terminals
-                {
-                    workerNeedSleep = this.num_terminals
-                            - this.currentPhase.getActiveTerminals();
-                }
-
-            }
-
-
-            this.notifyAll();
-        }
-    }
-
-    /**
-     * Delegates pre-start blocking to the global state handler
-     */
-
-    public void blockForStart() {
-        benchmarkState.blockForStart();
-    }
-
-    /**
-     * Delegates a global state query to the benchmark state handler
-     *
-     * @return global state
-     */
-    public State getGlobalState() {
-        return benchmarkState.getState();
-    }
-
-    public void signalLatencyComplete() {
-
-        benchmarkState.signalLatencyComplete();
-    }
-
-    public void startColdQuery() {
-
-        benchmarkState.startColdQuery();
-    }
-
-    public void startHotQuery() {
-
-        benchmarkState.startHotQuery();
-    }
-
-    public long getTestStartNs() {
-        return benchmarkState.getTestStartNs();
-    }
-
-}
diff --git a/src/main/java/com/oltpbenchmark/api/StatementDialects.java b/src/main/java/com/oltpbenchmark/api/StatementDialects.java
index 5e5826ea..ac3eb101 100644
--- a/src/main/java/com/oltpbenchmark/api/StatementDialects.java
+++ b/src/main/java/com/oltpbenchmark/api/StatementDialects.java
@@ -20,7 +20,6 @@
 import com.oltpbenchmark.WorkloadConfiguration;
 import com.oltpbenchmark.api.dialects.*;
 import com.oltpbenchmark.types.DatabaseType;
-import com.oltpbenchmark.types.State;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.xml.sax.SAXException;
diff --git a/src/main/java/com/oltpbenchmark/api/Worker.java b/src/main/java/com/oltpbenchmark/api/Worker.java
index 088b5d74..1938869b 100644
--- a/src/main/java/com/oltpbenchmark/api/Worker.java
+++ b/src/main/java/com/oltpbenchmark/api/Worker.java
@@ -20,7 +20,6 @@
 import com.oltpbenchmark.*;
 import com.oltpbenchmark.api.Procedure.UserAbortException;
 import com.oltpbenchmark.types.DatabaseType;
-import com.oltpbenchmark.types.State;
 import com.oltpbenchmark.types.TransactionStatus;
 import com.oltpbenchmark.util.Histogram;
 import org.slf4j.Logger;
@@ -28,23 +27,18 @@
 
 import java.sql.Connection;
 import java.sql.SQLException;
-import java.sql.Statement;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
 import java.util.Random;
-import java.util.concurrent.ThreadLocalRandom;
 import java.util.concurrent.atomic.AtomicInteger;
-
-import static com.oltpbenchmark.types.State.MEASURE;
+import java.util.concurrent.ThreadLocalRandom;
 
 public abstract class Worker<T extends BenchmarkModule> implements Runnable {
     private static final Logger LOG = LoggerFactory.getLogger(Worker.class);
     private static final Logger ABORT_LOG = LoggerFactory.getLogger("com.oltpbenchmark.api.ABORT_LOG");
 
-    private WorkloadState workloadState;
     private ResultStats resultStats;
-    private final Statement currStatement;
 
     // Interval requests used by the monitor
     private final AtomicInteger intervalRequests = new AtomicInteger(0);
@@ -53,6 +47,7 @@ public abstract class Worker<T extends BenchmarkModule> implements Runnable {
     private final T benchmark;
     protected Connection conn = null;
     protected final WorkloadConfiguration configuration;
+    protected BenchmarkState benchmarkState;
     protected final TransactionTypes transactionTypes;
     protected final Map<TransactionType, Procedure> procedures = new HashMap<>();
     protected final Map<String, Procedure> name_procedures = new HashMap<>();
@@ -65,14 +60,10 @@ public abstract class Worker<T extends BenchmarkModule> implements Runnable {
     private final Histogram<TransactionType> txnErrors = new Histogram<>();
     private final Histogram<TransactionType> txtRetryDifferent = new Histogram<>();
 
-    private boolean seenDone = false;
-
     public Worker(T benchmark, int id) {
         this.id = id;
         this.benchmark = benchmark;
         this.configuration = this.benchmark.getWorkloadConfiguration();
-        this.workloadState = this.configuration.getWorkloadState();
-        this.currStatement = null;
         this.transactionTypes = this.configuration.getTransTypes();
         this.resultStats = new ResultStats(this.transactionTypes);
 
@@ -95,6 +86,10 @@ public Worker(T benchmark, int id) {
         }
     }
 
+    public void setBenchmarkState(BenchmarkState state) {
+        this.benchmarkState = state;
+    }
+
     /**
      * Get the BenchmarkModule managing this Worker
      */
@@ -172,19 +167,6 @@ public final Histogram<TransactionType> getTransactionRetryDifferentHistogram()
         return (this.txtRetryDifferent);
     }
 
-    /**
-     * Stop executing the current statement.
-     */
-    synchronized public void cancelStatement() {
-        try {
-            if (this.currStatement != null) {
-                this.currStatement.cancel();
-            }
-        } catch (SQLException e) {
-            LOG.error("worker {} failed to cancel statement: {}", id, e.getMessage());
-        }
-    }
-
     @Override
     public final void run() {
         Thread t = Thread.currentThread();
@@ -201,207 +183,88 @@ public final void run() {
         }
 
         // wait for start
-        workloadState.blockForStart();
-
-        boolean firstDelay = true;
-
-        while (true) {
-
-            // PART 1: Init and check if done
-
-            State preState = workloadState.getGlobalState();
-
-            // Do nothing
-            if (preState == State.DONE) {
-                if (!seenDone) {
-                    // This is the first time we have observed that the
-                    // test is done notify the global test state, then
-                    // continue applying load
-                    seenDone = true;
-                    workloadState.signalDone();
-                    break;
-                }
-            }
-
-            // PART 2: Wait for work
-
-            // Sleep if there's nothing to do.
-            workloadState.stayAwake();
-
-            if (firstDelay) {
-                firstDelay = false;
-                int warmup = configuration.getWarmupTime();
-
-                // Additional delay to avoid starting all threads simultaneously
-                if (warmup > 0) {
-                    long maxDelay = 2000 * warmup / 3;
-                    try {
-                        Thread.sleep(ThreadLocalRandom.current().nextLong(maxDelay));
-                        LOG.debug("Worker {} thread started", id);
-                    } catch (InterruptedException e) {
-                        LOG.error("Worker {} pre-start sleep interrupted", id, e);
-                    }
-                }
-            }
-
-            Phase prePhase = workloadState.getCurrentPhase();
-            if (prePhase == null) {
-                continue;
+        benchmarkState.blockForStart();
+
+        // Additional delay to avoid starting all threads simultaneously
+        final int warmup = configuration.getWarmupTime();
+        if (warmup > 0) {
+            int maxDelayMs = (int)(1000 * warmup * 2 / 3);
+            int delayMs = ThreadLocalRandom.current().nextInt(maxDelayMs);
+            LOG.debug("Worker {} will sleep for {} s before starting", id, (int)(delayMs / 1000));
+            try {
+                Thread.sleep(delayMs);
+                LOG.debug("Worker {} thread started", id);
+            } catch (InterruptedException e) {
+                LOG.error("Worker {} pre-start sleep interrupted", id, e);
             }
+        }
 
-            // Grab some work and update the state, in case it changed while we
-            // waited.
-
-            SubmittedProcedure pieceOfWork = workloadState.fetchWork();
-
-            prePhase = workloadState.getCurrentPhase();
-            if (prePhase == null) {
-                continue;
+        while (benchmarkState.isWorkingOrMeasuring()) {
+            SubmittedProcedure pieceOfWork = benchmarkState.fetchWork();
+            if (pieceOfWork == null) {
+                LOG.debug("Worker {} thread got null work", id);
+                break;
             }
 
-            preState = workloadState.getGlobalState();
+            TransactionType transactionType;
+            try {
+                transactionType = transactionTypes.getType(pieceOfWork.getType());
 
-            switch (preState) {
-                case DONE, EXIT, LATENCY_COMPLETE -> {
-                    // Once a latency run is complete, we wait until the next
-                    // phase or until DONE.
-                    LOG.warn("preState {} will continue...", preState);
-                    continue;
-                }
-                default -> {
+                // just sanity check
+                if (transactionType.equals(TransactionType.INVALID)) {
+                    LOG.error("Worker {} thread got invalid work", id);
+                    throw new IndexOutOfBoundsException("Invalid transaction type");
                 }
-                // Do nothing
+            } catch (IndexOutOfBoundsException e) {
+                LOG.error("Worker {} thread tried executing disabled phase!", id);
+                throw e;
             }
 
-            // PART 3: Execute work
-
-            TransactionType transactionType = getTransactionType(pieceOfWork, prePhase, preState, workloadState);
-
-            if (!transactionType.equals(TransactionType.INVALID)) {
-
-                // TODO: Measuring latency when not rate limited is ... a little
-                // weird because if you add more simultaneous clients, you will
-                // increase latency (queue delay) but we do this anyway since it is
-                // useful sometimes
-
-                // Wait before transaction if specified
-                long preExecutionWaitInMillis = getPreExecutionWaitInMillis(transactionType);
-
-                if (preExecutionWaitInMillis > 0) {
-                    try {
-                        LOG.debug("Worker {}: {} will sleep for {} ms before executing",
-                            id, transactionType.getName(), preExecutionWaitInMillis);
-
-                        Thread.sleep(preExecutionWaitInMillis);
-                        LOG.debug("Worker {} woke up to execute {}", id, transactionType.getName());
-                    } catch (InterruptedException e) {
-                        LOG.error("Worker {} pre-execution sleep interrupted", id, e);
-                    }
-                }
-
-                long start = System.nanoTime();
-
-                TransactionStatus status = doWork(configuration.getDatabaseType(), transactionType);
-
-                long end = System.nanoTime();
-
-                // PART 4: Record results
-
-                State postState = workloadState.getGlobalState();
-
-                switch (postState) {
-                    case MEASURE:
-                        // Non-serial measurement. Only measure if the state both
-                        // before and after was MEASURE, and the phase hasn't
-                        // changed, otherwise we're recording results for a query
-                        // that either started during the warmup phase or ended
-                        // after the timer went off.
-                        Phase postPhase = workloadState.getCurrentPhase();
+            long preExecutionWaitInMillis = getPreExecutionWaitInMillis(transactionType);
+            if (preExecutionWaitInMillis > 0) {
+                try {
+                    LOG.debug("Worker {}: {} will sleep for {} ms before executing",
+                        id, transactionType.getName(), preExecutionWaitInMillis);
 
-                        if (postPhase == null) {
-                            // Need a null check on postPhase since current phase being null is used in WorkloadState
-                            // and ThreadBench as the indication that the benchmark is over. However, there's a race
-                            // condition with postState not being changed from MEASURE to DONE yet, so we entered the
-                            // switch. In this scenario, just break from the switch.
-                            break;
-                        }
-                        if (preState == MEASURE && postPhase.getId() == prePhase.getId()) {
-                            boolean isSuccess = status == TransactionStatus.SUCCESS ||
-                                status == TransactionStatus.USER_ABORTED;
-                            resultStats.addLatency(
-                                transactionType.getId(),
-                                start,
-                                end,
-                                isSuccess);
-                            intervalRequests.incrementAndGet();
-                        }
-                        if (prePhase.isLatencyRun()) {
-                            workloadState.startColdQuery();
-                        }
-                        break;
-                    case COLD_QUERY:
-                        // No recording for cold runs, but next time we will since
-                        // it'll be a hot run.
-                        if (preState == State.COLD_QUERY) {
-                            workloadState.startHotQuery();
-                        }
-                        break;
-                    default:
-                        // Do nothing
+                    Thread.sleep(preExecutionWaitInMillis);
+                    LOG.debug("Worker {} woke up to execute {}", id, transactionType.getName());
+                } catch (InterruptedException e) {
+                    LOG.error("Worker {} pre-execution sleep interrupted", id, e);
                 }
+            }
 
+            long start = System.nanoTime();
+            TransactionStatus status = doWork(configuration.getDatabaseType(), transactionType);
+            long end = System.nanoTime();
+
+            if (benchmarkState.isMeasuring()) {
+                boolean isSuccess = status == TransactionStatus.SUCCESS ||
+                    status == TransactionStatus.USER_ABORTED;
+                resultStats.addLatency(
+                    transactionType.getId(),
+                    start,
+                    end,
+                    isSuccess);
+                intervalRequests.incrementAndGet();
+            }
 
-                // wait after transaction if specified
-                long postExecutionWaitInMillis = getPostExecutionWaitInMillis(transactionType);
-
-                if (postExecutionWaitInMillis > 0) {
-                    try {
-                        LOG.debug("Worker {} {} will sleep for {} ms after executing",
-                            id, transactionType.getName(), postExecutionWaitInMillis);
+            long postExecutionWaitInMillis = getPostExecutionWaitInMillis(transactionType);
+            if (postExecutionWaitInMillis > 0) {
+                try {
+                    LOG.debug("Worker {} {} will sleep for {} ms after executing",
+                        id, transactionType.getName(), postExecutionWaitInMillis);
 
-                        Thread.sleep(postExecutionWaitInMillis);
-                    } catch (InterruptedException e) {
-                        LOG.error("Worker {} post-execution sleep interrupted", id, e);
-                    }
+                    Thread.sleep(postExecutionWaitInMillis);
+                } catch (InterruptedException e) {
+                    LOG.error("Worker {} post-execution sleep interrupted", id, e);
                 }
             }
-
-            workloadState.finishedWork();
         }
 
         LOG.debug("Worker {} calling teardown", id);
 
         tearDown();
-    }
-
-    private TransactionType getTransactionType(SubmittedProcedure pieceOfWork, Phase phase, State state, WorkloadState workloadState) {
-        TransactionType type = TransactionType.INVALID;
-
-        try {
-            type = transactionTypes.getType(pieceOfWork.getType());
-        } catch (IndexOutOfBoundsException e) {
-            if (phase.isThroughputRun()) {
-                LOG.error("Worker {} thread tried executing disabled phase!", id);
-                throw e;
-            }
-            if (phase.getId() == workloadState.getCurrentPhase().getId()) {
-                switch (state) {
-                    case WARMUP -> {
-                        // Don't quit yet: we haven't even begun!
-                        LOG.info("Worker {} [Serial] Resetting serial for phase.", id);
-                        phase.resetSerial();
-                    }
-                    case COLD_QUERY, MEASURE -> {
-                        // The serial phase is over. Finish the run early.
-                        LOG.info("Worker {} [Serial] Updating workload state to {}.", id, State.LATENCY_COMPLETE);
-                        workloadState.signalLatencyComplete();
-                    }
-                    default -> throw e;
-                }
-            }
-        }
-
-        return type;
+        benchmarkState.workerFinished();
     }
 
     /**
@@ -416,11 +279,12 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
         TransactionStatus status = TransactionStatus.UNKNOWN;
 
         try {
+            // TODO: we might need backoff for retries
+
             int retryCount = 0;
             int maxRetryCount = configuration.getMaxRetries();
 
-            while (retryCount < maxRetryCount && this.workloadState.getGlobalState() != State.DONE) {
-
+            while (retryCount < maxRetryCount && this.benchmarkState.isWorkingOrMeasuring()) {
                 status = TransactionStatus.UNKNOWN;
 
                 if (this.conn == null) {
@@ -437,7 +301,6 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                 }
 
                 try {
-
                     LOG.debug("Worker {} is attempting {}", id, transactionType);
 
                     status = this.executeWork(conn, transactionType);
@@ -446,9 +309,7 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                         id, transactionType, status.name());
 
                     conn.commit();
-
                     break;
-
                 } catch (UserAbortException ex) {
                     // TODO: probably check exception and retry if possible
                     try {
@@ -464,11 +325,8 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
 
                     ABORT_LOG.debug("{} Aborted", transactionType, ex);
 
-
                     break;
-
                 } catch (SQLException ex) {
-                    // TODO: probably check exception and retry if possible
                     try {
                         LOG.debug("Worker {} rolled back transaction {}", id, transactionType);
                         conn.rollback();
@@ -495,7 +353,6 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
 
                         break;
                     }
-
                 } finally {
                     if (this.configuration.getNewConnectionPerTxn() && this.conn != null) {
                         try {
@@ -505,6 +362,7 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                             this.benchmark.returnConnection();
                         } catch (SQLException e) {
                             LOG.error("Worker {} connection couldn't be closed.", id, e);
+                            throw new RuntimeException("Failed to close connection", e);
                         }
                     }
 
@@ -516,9 +374,7 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                         case RETRY_DIFFERENT -> this.txtRetryDifferent.put(transactionType);
                         case ERROR -> this.txnErrors.put(transactionType);
                     }
-
                 }
-
             }
         } catch (RuntimeException ex) {
             LOG.error("Worker {} Unexpected RuntimeException when executing '%s' on [%s]: %s",
@@ -592,10 +448,6 @@ public void tearDown() {
         }
     }
 
-    public void initializeState() {
-        this.workloadState = this.configuration.getWorkloadState();
-    }
-
     protected long getPreExecutionWaitInMillis(TransactionType type) {
         return 0;
     }
diff --git a/src/main/java/com/oltpbenchmark/distributions/ZipfianGenerator.java b/src/main/java/com/oltpbenchmark/distributions/ZipfianGenerator.java
index 5697d453..751075da 100644
--- a/src/main/java/com/oltpbenchmark/distributions/ZipfianGenerator.java
+++ b/src/main/java/com/oltpbenchmark/distributions/ZipfianGenerator.java
@@ -22,6 +22,8 @@
 
 import java.util.Random;
 
+import java.util.concurrent.locks.ReentrantLock;
+
 /**
  * A generator of a zipfian distribution. It produces a sequence of items, such that some items are more popular than others, according
  * to a zipfian distribution. When you construct an instance of this class, you specify the number of items in the set to draw from, either
@@ -47,6 +49,8 @@ public class ZipfianGenerator extends IntegerGenerator {
 
     final Random rng;
 
+    private final ReentrantLock lock = new ReentrantLock();
+
     /**
      * Number of items.
      */
@@ -237,7 +241,8 @@ public long nextLong(long itemcount) {
         if (itemcount != countforzeta) {
 
             //have to recompute zetan and eta, since they depend on itemcount
-            synchronized (this) {
+            try {
+                lock.lock();
                 if (itemcount > countforzeta) {
                     //System.err.println("WARNING: Incrementally recomputing Zipfian distribtion. (itemcount="+itemcount+" countforzeta="+countforzeta+")");
 
@@ -257,6 +262,8 @@ public long nextLong(long itemcount) {
                     zetan = zeta(itemcount, theta);
                     eta = (1 - Math.pow(2.0 / items, 1 - theta)) / (1 - zeta2theta / zetan);
                 }
+            } finally {
+                lock.unlock();
             }
         }
 
diff --git a/src/main/java/com/oltpbenchmark/types/State.java b/src/main/java/com/oltpbenchmark/types/State.java
deleted file mode 100644
index 2ad96383..00000000
--- a/src/main/java/com/oltpbenchmark/types/State.java
+++ /dev/null
@@ -1,25 +0,0 @@
-/*
- * Copyright 2020 by OLTPBenchmark Project
- *
- * Licensed under the Apache License, Version 2.0 (the "License");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- *
- */
-
-/**
- *
- */
-package com.oltpbenchmark.types;
-
-public enum State {
-    WARMUP, MEASURE, COLD_QUERY, LATENCY_COMPLETE, DONE, EXIT, ERROR
-}
\ No newline at end of file
diff --git a/src/main/java/com/oltpbenchmark/util/Histogram.java b/src/main/java/com/oltpbenchmark/util/Histogram.java
index 9abc3524..5b8396eb 100644
--- a/src/main/java/com/oltpbenchmark/util/Histogram.java
+++ b/src/main/java/com/oltpbenchmark/util/Histogram.java
@@ -29,6 +29,8 @@
 import java.util.*;
 import java.util.Map.Entry;
 
+import java.util.concurrent.locks.ReentrantLock;
+
 /**
  * A very nice and simple generic Histogram
  *
@@ -38,6 +40,8 @@
 public class Histogram<X extends Comparable<X>> implements JSONSerializable {
     private static final Logger LOG = LoggerFactory.getLogger(Histogram.class);
 
+    private final ReentrantLock lock = new ReentrantLock();
+
     private static final String MARKER = "*";
     private static final Integer MAX_CHARS = 80;
     private static final Integer MAX_VALUE_LENGTH = 80;
@@ -110,7 +114,8 @@ public boolean hasDebugLabels() {
     public void setKeepZeroEntries(boolean flag) {
         // When this option is disabled, we need to remove all of the zeroed entries
         if (!flag && this.keep_zero_entries) {
-            synchronized (this) {
+            try {
+                lock.lock();
                 Iterator<X> it = this.histogram.keySet().iterator();
                 int ctr = 0;
                 while (it.hasNext()) {
@@ -124,6 +129,8 @@ public void setKeepZeroEntries(boolean flag) {
                 if (ctr > 0) {
                     LOG.debug("Removed {} zero entries from histogram", ctr);
                 }
+            } finally {
+                lock.unlock();
             }
         }
         this.keep_zero_entries = flag;
@@ -173,7 +180,7 @@ private synchronized void calculateInternalValues() {
         }
 
         // New Min/Max Counts
-        // The reason we have to loop through and check every time is that our 
+        // The reason we have to loop through and check every time is that our
         // value may be the current min/max count and thus it may or may not still
         // be after the count is changed
         this.max_count = 0;

From 87cf80ba6042dff862024d16d193f07955ce1848 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Thu, 8 Feb 2024 18:42:27 +0100
Subject: [PATCH 23/32] copy-paste YDB metrics code by @alex268 and add some
 additional metrics

---
 pom.xml                                       | 12 +++
 .../java/com/oltpbenchmark/DBWorkload.java    | 21 ++++
 .../oltpbenchmark/api/BenchmarkModule.java    | 55 +++++++++--
 .../java/com/oltpbenchmark/api/Worker.java    | 97 +++++++++++++++++++
 4 files changed, 177 insertions(+), 8 deletions(-)

diff --git a/pom.xml b/pom.xml
index 9c95c9a6..a11aa39b 100644
--- a/pom.xml
+++ b/pom.xml
@@ -239,6 +239,18 @@
             <version>2.7.1</version>
         </dependency>
 
+        <dependency>
+            <groupId>io.micrometer</groupId>
+            <artifactId>micrometer-registry-prometheus</artifactId>
+            <version>1.11.0</version>
+        </dependency>
+
+        <dependency>
+            <groupId>io.prometheus</groupId>
+            <artifactId>simpleclient_httpserver</artifactId>
+            <version>0.16.0</version>
+        </dependency>
+
         <dependency>
             <groupId>junit</groupId>
             <artifactId>junit</artifactId>
diff --git a/src/main/java/com/oltpbenchmark/DBWorkload.java b/src/main/java/com/oltpbenchmark/DBWorkload.java
index b0e43019..204bdc41 100644
--- a/src/main/java/com/oltpbenchmark/DBWorkload.java
+++ b/src/main/java/com/oltpbenchmark/DBWorkload.java
@@ -24,6 +24,12 @@
 import com.oltpbenchmark.api.Worker;
 import com.oltpbenchmark.types.DatabaseType;
 import com.oltpbenchmark.util.*;
+import io.micrometer.core.instrument.Metrics;
+import io.micrometer.core.instrument.Tags;
+import io.micrometer.prometheus.PrometheusConfig;
+import io.micrometer.prometheus.PrometheusMeterRegistry;
+import io.prometheus.client.exporter.HTTPServer;
+
 import org.apache.commons.cli.*;
 import org.apache.commons.collections4.map.ListOrderedMap;
 import org.apache.commons.configuration2.HierarchicalConfiguration;
@@ -41,6 +47,7 @@
 import java.io.File;
 import java.io.IOException;
 import java.io.PrintStream;
+import java.net.InetSocketAddress;
 import java.sql.SQLException;
 import java.text.DecimalFormat;
 import java.text.ParseException;
@@ -370,6 +377,20 @@ public static void main(String[] args) throws Exception {
         // Generate the dialect map
         wrkld.init();
 
+        int monitoringPort = xmlConfig.getInt("monitoringPort", 0);
+        if (monitoringPort > 0) {
+            LOG.info("Start prometeus metric collector on port {}", monitoringPort);
+            PrometheusMeterRegistry prometheusRegistry = new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);
+            HTTPServer server = new HTTPServer(
+                    new InetSocketAddress(monitoringPort),
+                    prometheusRegistry.getPrometheusRegistry(),
+                    true);
+            LOG.info("Started {}", server);
+            Metrics.addRegistry(prometheusRegistry);
+            String instance = xmlConfig.getString("monitoringName", "benchbase");
+            Metrics.globalRegistry.config().commonTags(Tags.of("instance", instance));
+        }
+
         // Create the Benchmark's Database
         if (isBooleanOptionSet(argsLine, "create")) {
             try {
diff --git a/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java b/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
index 3827d92b..ea460111 100644
--- a/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
+++ b/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
@@ -26,6 +26,9 @@
 import com.oltpbenchmark.util.SQLUtil;
 import com.oltpbenchmark.util.ScriptRunner;
 import com.oltpbenchmark.util.ThreadUtil;
+import io.micrometer.core.instrument.Gauge;
+import io.micrometer.core.instrument.Metrics;
+import io.micrometer.core.instrument.Timer;
 import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -35,7 +38,9 @@
 import java.sql.Connection;
 import java.sql.DriverManager;
 import java.sql.SQLException;
+import java.time.Duration;
 import java.util.concurrent.Semaphore;
+import java.util.concurrent.atomic.AtomicInteger;
 import java.util.*;
 
 /**
@@ -44,22 +49,48 @@
 public abstract class BenchmarkModule {
     private static final Logger LOG = LoggerFactory.getLogger(BenchmarkModule.class);
 
-    private static ComboPooledDataSource dataSource;
-
     // We use virtual threads. There is a limitted number of c3p0 provided connections.
     // When c3p0 runs out of connections, it will block until one is available. Block in a way
     // that carrier threads are blocked. Same time other virtual threads holding connections
     // might be parked waiting for a carrier thread to be available. This will cause a deadlock.
     // To avoid this, we use a semaphore to wait for a connection without blocking the carrier thread.
-    //
-    // TODO: currently this breaks all non TPC-C benchmarks,
-    // because they have to call returnConnection() now
-    private static Semaphore connectionSemaphore;
+    private static Semaphore connectionSemaphore = new Semaphore(0);
+
+    private static final Gauge SESSIONS_USED = Gauge.builder("sessions", BenchmarkModule::getUsedConnectionCount)
+            .tag("state", "used")
+            .register(Metrics.globalRegistry);
+
+    private static final Gauge SESSIONS_QUEUE = Gauge.builder("session_queue_length", connectionSemaphore, Semaphore::getQueueLength)
+            .register(Metrics.globalRegistry);
+
+    private static final Timer.Builder GET_SESSION_DURATION = Timer.builder("get_session")
+            .serviceLevelObjectives(
+                    Duration.ofMillis(1),
+                    Duration.ofMillis(2),
+                    Duration.ofMillis(4),
+                    Duration.ofMillis(8),
+                    Duration.ofMillis(16),
+                    Duration.ofMillis(32),
+                    Duration.ofMillis(64),
+                    Duration.ofMillis(128),
+                    Duration.ofMillis(256),
+                    Duration.ofMillis(512),
+                    Duration.ofMillis(1024),
+                    Duration.ofMillis(2048),
+                    Duration.ofMillis(4096),
+                    Duration.ofMillis(8192),
+                    Duration.ofMillis(16384),
+                    Duration.ofMillis(32768),
+                    Duration.ofMillis(65536)
+            )
+            .publishPercentiles();
+
+    private static ComboPooledDataSource dataSource;
 
     /**
      * The workload configuration for this benchmark invocation
      */
-    protected final WorkloadConfiguration workConf;
+    protected static WorkloadConfiguration workConf;
 
     /**
      * These are the variations of the Procedure's Statement SQL
@@ -101,7 +132,7 @@ public BenchmarkModule(WorkloadConfiguration workConf) {
                 dataSource.setMaxPoolSize(workConf.getMaxConnections());
                 dataSource.setMaxStatements(workConf.getMaxConnections());
 
-                connectionSemaphore = new Semaphore(workConf.getMaxConnections());
+                connectionSemaphore.release(workConf.getMaxConnections());
 
                 Runtime.getRuntime().addShutdownHook(new Thread(() -> {
                     dataSource.close();
@@ -118,6 +149,7 @@ public BenchmarkModule(WorkloadConfiguration workConf) {
     // --------------------------------------------------------------------------
 
     public final Connection makeConnection() throws SQLException {
+        long start = System.nanoTime();
         try {
             connectionSemaphore.acquire();
             return dataSource.getConnection();
@@ -127,6 +159,9 @@ public final Connection makeConnection() throws SQLException {
         } catch (InterruptedException e) {
             connectionSemaphore.release();
             throw new SQLException(e);
+        } finally {
+            long end = System.nanoTime();
+            GET_SESSION_DURATION.register(Metrics.globalRegistry).record(Duration.ofNanos(end - start));
         }
     }
 
@@ -134,6 +169,10 @@ public final void returnConnection() {
         connectionSemaphore.release();
     }
 
+    public final static double getUsedConnectionCount() {
+        return workConf.getMaxConnections() - connectionSemaphore.availablePermits();
+    }
+
     // --------------------------------------------------------------------------
     // IMPLEMENTING CLASS INTERFACE
     // --------------------------------------------------------------------------
diff --git a/src/main/java/com/oltpbenchmark/api/Worker.java b/src/main/java/com/oltpbenchmark/api/Worker.java
index 1938869b..9dafcbe4 100644
--- a/src/main/java/com/oltpbenchmark/api/Worker.java
+++ b/src/main/java/com/oltpbenchmark/api/Worker.java
@@ -22,11 +22,16 @@
 import com.oltpbenchmark.types.DatabaseType;
 import com.oltpbenchmark.types.TransactionStatus;
 import com.oltpbenchmark.util.Histogram;
+import io.micrometer.core.instrument.Gauge;
+import io.micrometer.core.instrument.Counter;
+import io.micrometer.core.instrument.Metrics;
+import io.micrometer.core.instrument.Timer;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import java.sql.Connection;
 import java.sql.SQLException;
+import java.time.Duration;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Map.Entry;
@@ -38,6 +43,65 @@ public abstract class Worker<T extends BenchmarkModule> implements Runnable {
     private static final Logger LOG = LoggerFactory.getLogger(Worker.class);
     private static final Logger ABORT_LOG = LoggerFactory.getLogger("com.oltpbenchmark.api.ABORT_LOG");
 
+    private static final AtomicInteger WORKERS_SLEEPING = new AtomicInteger(0);
+    private static final AtomicInteger WORKERS_WORKING = new AtomicInteger(0);
+
+    private static final Gauge WORKERS_SLEEPING_GAUGE = Gauge.builder("workers", WORKERS_SLEEPING, AtomicInteger::get)
+            .tag("state", "sleeping")
+            .register(Metrics.globalRegistry);
+
+    private static final Gauge WORKERS_WORKING_GAUGE = Gauge.builder("workers", WORKERS_WORKING, AtomicInteger::get)
+            .tag("state", "working")
+            .register(Metrics.globalRegistry);
+
+    private static final Counter.Builder TRANSACTIONS = Counter.builder("transactions");
+    private static final Counter.Builder EXECUTIONS = Counter.builder("executions");
+    private static final Counter.Builder ERRORS = Counter.builder("errors");
+
+    private static final Timer.Builder TRANSACTION_DURATION = Timer.builder("transaction")
+            .serviceLevelObjectives(
+                    Duration.ofMillis(1),
+                    Duration.ofMillis(2),
+                    Duration.ofMillis(4),
+                    Duration.ofMillis(8),
+                    Duration.ofMillis(16),
+                    Duration.ofMillis(32),
+                    Duration.ofMillis(64),
+                    Duration.ofMillis(128),
+                    Duration.ofMillis(256),
+                    Duration.ofMillis(512),
+                    Duration.ofMillis(1024),
+                    Duration.ofMillis(2048),
+                    Duration.ofMillis(4096),
+                    Duration.ofMillis(8192),
+                    Duration.ofMillis(16384),
+                    Duration.ofMillis(32768),
+                    Duration.ofMillis(65536)
+            )
+            .publishPercentiles();
+
+    private static final Timer.Builder EXECUTION_DURATION = Timer.builder("execution")
+            .serviceLevelObjectives(
+                    Duration.ofMillis(1),
+                    Duration.ofMillis(2),
+                    Duration.ofMillis(4),
+                    Duration.ofMillis(8),
+                    Duration.ofMillis(16),
+                    Duration.ofMillis(32),
+                    Duration.ofMillis(64),
+                    Duration.ofMillis(128),
+                    Duration.ofMillis(256),
+                    Duration.ofMillis(512),
+                    Duration.ofMillis(1024),
+                    Duration.ofMillis(2048),
+                    Duration.ofMillis(4096),
+                    Duration.ofMillis(8192),
+                    Duration.ofMillis(16384),
+                    Duration.ofMillis(32768),
+                    Duration.ofMillis(65536)
+            )
+            .publishPercentiles();
+
     private ResultStats resultStats;
 
     // Interval requests used by the monitor
@@ -226,16 +290,29 @@ public final void run() {
                     LOG.debug("Worker {}: {} will sleep for {} ms before executing",
                         id, transactionType.getName(), preExecutionWaitInMillis);
 
+                    WORKERS_SLEEPING.incrementAndGet();
                     Thread.sleep(preExecutionWaitInMillis);
+                    WORKERS_SLEEPING.decrementAndGet();
                     LOG.debug("Worker {} woke up to execute {}", id, transactionType.getName());
                 } catch (InterruptedException e) {
                     LOG.error("Worker {} pre-execution sleep interrupted", id, e);
                 }
             }
 
+            WORKERS_WORKING.incrementAndGet();
             long start = System.nanoTime();
+
             TransactionStatus status = doWork(configuration.getDatabaseType(), transactionType);
+
             long end = System.nanoTime();
+            WORKERS_WORKING.decrementAndGet();
+
+            TRANSACTIONS.tag("type", "any").register(Metrics.globalRegistry).increment();
+            TRANSACTIONS.tag("type", transactionType.getName()).register(Metrics.globalRegistry).increment();
+            TRANSACTION_DURATION.tag("type", "any").register(Metrics.globalRegistry)
+                    .record(Duration.ofNanos(end - start));
+            TRANSACTION_DURATION.tag("type", transactionType.getName()).register(Metrics.globalRegistry)
+                    .record(Duration.ofNanos(end - start));
 
             if (benchmarkState.isMeasuring()) {
                 boolean isSuccess = status == TransactionStatus.SUCCESS ||
@@ -254,7 +331,9 @@ public final void run() {
                     LOG.debug("Worker {} {} will sleep for {} ms after executing",
                         id, transactionType.getName(), postExecutionWaitInMillis);
 
+                    WORKERS_SLEEPING.incrementAndGet();
                     Thread.sleep(postExecutionWaitInMillis);
+                    WORKERS_SLEEPING.decrementAndGet();
                 } catch (InterruptedException e) {
                     LOG.error("Worker {} post-execution sleep interrupted", id, e);
                 }
@@ -300,6 +379,7 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                     }
                 }
 
+                long start = System.nanoTime();
                 try {
                     LOG.debug("Worker {} is attempting {}", id, transactionType);
 
@@ -327,6 +407,13 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
 
                     break;
                 } catch (SQLException ex) {
+                    int errorCode = ex.getErrorCode();
+
+                    ERRORS.tag("type", "any")
+                            .register(Metrics.globalRegistry).increment();
+                    ERRORS.tag("type", String.valueOf(errorCode))
+                            .register(Metrics.globalRegistry).increment();
+
                     try {
                         LOG.debug("Worker {} rolled back transaction {}", id, transactionType);
                         conn.rollback();
@@ -366,6 +453,16 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                         }
                     }
 
+                    long end = System.nanoTime();
+
+                    EXECUTION_DURATION.tag("type", "any").register(Metrics.globalRegistry)
+                            .record(Duration.ofNanos(end - start));
+                    EXECUTION_DURATION.tag("type", status.toString()).register(Metrics.globalRegistry)
+                            .record(Duration.ofNanos(end - start));
+
+                    EXECUTIONS.tag("type", "any").register(Metrics.globalRegistry).increment();
+                    EXECUTIONS.tag("type", status.toString()).register(Metrics.globalRegistry).increment();
+
                     switch (status) {
                         case UNKNOWN -> this.txnUnknown.put(transactionType);
                         case SUCCESS -> this.txnSuccess.put(transactionType);

From 61bc251abfe98bc3685e0da52ac331ed2cbf746e Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Sat, 10 Feb 2024 16:53:33 +0100
Subject: [PATCH 24/32] option to disable connection pooling

---
 src/main/java/com/oltpbenchmark/DBWorkload.java |  1 +
 .../oltpbenchmark/WorkloadConfiguration.java    | 10 ++++++++++
 .../com/oltpbenchmark/api/BenchmarkModule.java  | 17 +++++++++++++----
 3 files changed, 24 insertions(+), 4 deletions(-)

diff --git a/src/main/java/com/oltpbenchmark/DBWorkload.java b/src/main/java/com/oltpbenchmark/DBWorkload.java
index 204bdc41..fcf8878d 100644
--- a/src/main/java/com/oltpbenchmark/DBWorkload.java
+++ b/src/main/java/com/oltpbenchmark/DBWorkload.java
@@ -159,6 +159,7 @@ public static void main(String[] args) throws Exception {
         wrkld.setMaxRetries(xmlConfig.getInt("retries", 3));
         wrkld.setMaxConnections(xmlConfig.getInt("maxConnections", wrkld.getMaxConnections()));
         wrkld.setNewConnectionPerTxn(xmlConfig.getBoolean("newConnectionPerTxn", false));
+        wrkld.setDisableConnectionPool(xmlConfig.getBoolean("disableConnectionPool", false));
 
         int terminals = xmlConfig.getInt("terminals[not(@bench)]", 0);
         terminals = xmlConfig.getInt("terminals" + pluginTest, terminals);
diff --git a/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java b/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
index 1bac7699..cee3b75c 100644
--- a/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
+++ b/src/main/java/com/oltpbenchmark/WorkloadConfiguration.java
@@ -58,6 +58,8 @@ public class WorkloadConfiguration {
      */
     private boolean newConnectionPerTxn = false;
 
+    private boolean disableConnectionPooling = false;
+
     public String getBenchmarkName() {
         return benchmarkName;
     }
@@ -147,6 +149,14 @@ public void setNewConnectionPerTxn(boolean newConnectionPerTxn) {
         this.newConnectionPerTxn = newConnectionPerTxn;
     }
 
+    public boolean getDisableConnectionPool() {
+        return disableConnectionPooling;
+    }
+
+    public void setDisableConnectionPool(boolean disableConnectionPooling) {
+        this.disableConnectionPooling = disableConnectionPooling;
+    }
+
     public void setPhase(int id, int time, int warmup, List<Double> weights, boolean timed, int active_terminals, Phase.Arrival arrival) {
         this.phase = new Phase(benchmarkName, id, time, warmup, weights, timed, active_terminals, arrival);
     }
diff --git a/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java b/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
index ea460111..cb7ac887 100644
--- a/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
+++ b/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
@@ -117,7 +117,7 @@ public BenchmarkModule(WorkloadConfiguration workConf) {
         this.workConf = workConf;
         this.dialects = new StatementDialects(workConf);
 
-        if (dataSource == null) {
+        if (!workConf.getDisableConnectionPool() && dataSource == null) {
             try {
                 dataSource = new ComboPooledDataSource();
                 dataSource.setDriverClass("org.postgresql.Driver");
@@ -132,8 +132,6 @@ public BenchmarkModule(WorkloadConfiguration workConf) {
                 dataSource.setMaxPoolSize(workConf.getMaxConnections());
                 dataSource.setMaxStatements(workConf.getMaxConnections());
 
-                connectionSemaphore.release(workConf.getMaxConnections());
-
                 Runtime.getRuntime().addShutdownHook(new Thread(() -> {
                     dataSource.close();
                 }));
@@ -142,6 +140,7 @@ public BenchmarkModule(WorkloadConfiguration workConf) {
                 throw new RuntimeException("Unable to initialize DataSource", e);
             }
         }
+        connectionSemaphore.release(workConf.getMaxConnections());
     }
 
     // --------------------------------------------------------------------------
@@ -152,7 +151,17 @@ public final Connection makeConnection() throws SQLException {
         long start = System.nanoTime();
         try {
             connectionSemaphore.acquire();
-            return dataSource.getConnection();
+            if (dataSource != null) {
+                return dataSource.getConnection();
+            }
+            if (StringUtils.isEmpty(workConf.getUsername())) {
+                return DriverManager.getConnection(workConf.getUrl());
+            } else {
+                return DriverManager.getConnection(
+                        workConf.getUrl(),
+                        workConf.getUsername(),
+                        workConf.getPassword());
+            }
         } catch (SQLException e) {
             connectionSemaphore.release();
             throw e;

From 257c864a0069043cfc42a616eaee27242028a349 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Sat, 10 Feb 2024 17:34:46 +0100
Subject: [PATCH 25/32] add connection error metric

---
 src/main/java/com/oltpbenchmark/api/Worker.java | 7 +++++++
 1 file changed, 7 insertions(+)

diff --git a/src/main/java/com/oltpbenchmark/api/Worker.java b/src/main/java/com/oltpbenchmark/api/Worker.java
index 9dafcbe4..7cdeb34a 100644
--- a/src/main/java/com/oltpbenchmark/api/Worker.java
+++ b/src/main/java/com/oltpbenchmark/api/Worker.java
@@ -57,6 +57,7 @@ public abstract class Worker<T extends BenchmarkModule> implements Runnable {
     private static final Counter.Builder TRANSACTIONS = Counter.builder("transactions");
     private static final Counter.Builder EXECUTIONS = Counter.builder("executions");
     private static final Counter.Builder ERRORS = Counter.builder("errors");
+    private static final Counter.Builder CONNECTION_ERRORS = Counter.builder("connection_errors");
 
     private static final Timer.Builder TRANSACTION_DURATION = Timer.builder("transaction")
             .serviceLevelObjectives(
@@ -375,6 +376,12 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
                     } catch (SQLException ex) {
                         LOG.debug("Worker {} failed to open a connection: {}", id, ex);
                         retryCount++;
+
+                        CONNECTION_ERRORS.tag("type", "any")
+                                .register(Metrics.globalRegistry).increment();
+                        CONNECTION_ERRORS.tag("type", String.valueOf(ex.getErrorCode()))
+                                .register(Metrics.globalRegistry).increment();
+
                         continue;
                     }
                 }

From 056d2177a24049b37996e3ffcf1d4c3cef0e90a4 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Sat, 10 Feb 2024 19:14:55 +0100
Subject: [PATCH 26/32] Switch to Hikari

---
 pom.xml                                       |  6 +++---
 .../oltpbenchmark/api/BenchmarkModule.java    | 21 +++++++++----------
 2 files changed, 13 insertions(+), 14 deletions(-)

diff --git a/pom.xml b/pom.xml
index a11aa39b..60269c6a 100644
--- a/pom.xml
+++ b/pom.xml
@@ -74,9 +74,9 @@
                     <version>42.6.0</version>
                 </dependency>
                 <dependency>
-                    <groupId>com.mchange</groupId>
-                    <artifactId>c3p0</artifactId>
-                    <version>0.9.5.5</version>
+                    <groupId>com.zaxxer</groupId>
+                    <artifactId>HikariCP</artifactId>
+                    <version>5.1.0</version>
                 </dependency>
             </dependencies>
         </profile>
diff --git a/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java b/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
index cb7ac887..de73ed4d 100644
--- a/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
+++ b/src/main/java/com/oltpbenchmark/api/BenchmarkModule.java
@@ -18,7 +18,6 @@
 
 package com.oltpbenchmark.api;
 
-import com.mchange.v2.c3p0.ComboPooledDataSource;
 import com.oltpbenchmark.WorkloadConfiguration;
 import com.oltpbenchmark.catalog.AbstractCatalog;
 import com.oltpbenchmark.types.DatabaseType;
@@ -26,9 +25,13 @@
 import com.oltpbenchmark.util.SQLUtil;
 import com.oltpbenchmark.util.ScriptRunner;
 import com.oltpbenchmark.util.ThreadUtil;
+import com.zaxxer.hikari.HikariConfig;
+import com.zaxxer.hikari.HikariDataSource;
 import io.micrometer.core.instrument.Gauge;
 import io.micrometer.core.instrument.Metrics;
 import io.micrometer.core.instrument.Timer;
+import io.micrometer.core.instrument.simple.SimpleMeterRegistry;
+
 import org.apache.commons.lang3.StringUtils;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -85,7 +88,7 @@ public abstract class BenchmarkModule {
             )
             .publishPercentiles();
 
-    private static ComboPooledDataSource dataSource;
+    private static HikariDataSource dataSource;
 
     /**
      * The workload configuration for this benchmark invocation
@@ -119,18 +122,14 @@ public BenchmarkModule(WorkloadConfiguration workConf) {
 
         if (!workConf.getDisableConnectionPool() && dataSource == null) {
             try {
-                dataSource = new ComboPooledDataSource();
-                dataSource.setDriverClass("org.postgresql.Driver");
+                dataSource = new HikariDataSource();
                 dataSource.setJdbcUrl(workConf.getUrl());
-                dataSource.setUser(workConf.getUsername());
+                dataSource.setUsername(workConf.getUsername());
                 dataSource.setPassword(workConf.getPassword());
 
-                // Optional Settings
-                dataSource.setMinPoolSize(10);
-                dataSource.setInitialPoolSize(10);
-                dataSource.setAcquireIncrement(10);
-                dataSource.setMaxPoolSize(workConf.getMaxConnections());
-                dataSource.setMaxStatements(workConf.getMaxConnections());
+                dataSource.setMaximumPoolSize(workConf.getMaxConnections());
+
+                dataSource.setMetricRegistry(Metrics.globalRegistry);
 
                 Runtime.getRuntime().addShutdownHook(new Thread(() -> {
                     dataSource.close();

From d6ef227489994e39a5dba03ba5f94178ef45dc89 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Sun, 18 Feb 2024 18:09:56 +0100
Subject: [PATCH 27/32] load items only in first loader instance

---
 .../benchmarks/tpcc/TPCCLoader.java           | 22 ++++++++++---------
 1 file changed, 12 insertions(+), 10 deletions(-)

diff --git a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java
index d1453ece..0cee9d7e 100644
--- a/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java
+++ b/src/main/java/com/oltpbenchmark/benchmarks/tpcc/TPCCLoader.java
@@ -52,17 +52,19 @@ public List<LoaderThread> createLoaderThreads() {
 
         // ITEM
         // This will be invoked first and executed in a single thread.
-        threads.add(new LoaderThread(this.benchmark) {
-            @Override
-            public void load(Connection conn) {
-                loadItems(conn, TPCCConfig.configItemCount);
-            }
+        if (this.startFromId == 1) {
+            threads.add(new LoaderThread(this.benchmark) {
+                @Override
+                public void load(Connection conn) {
+                    loadItems(conn, TPCCConfig.configItemCount);
+                }
 
-            @Override
-            public void afterLoad() {
-                itemLatch.countDown();
-            }
-        });
+                @Override
+                public void afterLoad() {
+                    itemLatch.countDown();
+                }
+            });
+        }
 
         // WAREHOUSES
         // We use a separate thread per warehouse. Each thread will load

From 8be052a4aad76b1e53f6ecc8338a29e9fefcf094 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Wed, 28 Feb 2024 12:17:35 +0100
Subject: [PATCH 28/32] make histrogram more granular

---
 src/main/java/com/oltpbenchmark/ResultStats.java | 8 +++++++-
 1 file changed, 7 insertions(+), 1 deletion(-)

diff --git a/src/main/java/com/oltpbenchmark/ResultStats.java b/src/main/java/com/oltpbenchmark/ResultStats.java
index af4b9b9a..cb39eb35 100644
--- a/src/main/java/com/oltpbenchmark/ResultStats.java
+++ b/src/main/java/com/oltpbenchmark/ResultStats.java
@@ -115,7 +115,13 @@ public static class Histogram {
         public Histogram() {
             // note, that because 5000 is here, we can calculate precisely number of transactions below
             // this value.
-            this(new int[]{1, 5, 10, 50, 100, 500, 1000, 2000, 3000, 4000, 4500, 5000, 6000, 10000});
+            this(new int[]{
+                1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
+                16, 32, 64, 128, 256, 512,
+                1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000,
+                7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000,
+                20000
+            });
         }
 
         public Histogram(int[] bucketlist) {

From 71b137a03f921479de2d0a8a241dca782be9b5a2 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Thu, 9 May 2024 10:43:47 +0200
Subject: [PATCH 29/32] proper number of retries

---
 src/main/java/com/oltpbenchmark/api/Worker.java | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/src/main/java/com/oltpbenchmark/api/Worker.java b/src/main/java/com/oltpbenchmark/api/Worker.java
index 7cdeb34a..45918b7e 100644
--- a/src/main/java/com/oltpbenchmark/api/Worker.java
+++ b/src/main/java/com/oltpbenchmark/api/Worker.java
@@ -364,7 +364,7 @@ protected final TransactionStatus doWork(DatabaseType databaseType, TransactionT
             int retryCount = 0;
             int maxRetryCount = configuration.getMaxRetries();
 
-            while (retryCount < maxRetryCount && this.benchmarkState.isWorkingOrMeasuring()) {
+            while (retryCount <= maxRetryCount && this.benchmarkState.isWorkingOrMeasuring()) {
                 status = TransactionStatus.UNKNOWN;
 
                 if (this.conn == null) {

From b23bc4527911494db36fe35fa4f0461ff1c125a9 Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Thu, 9 May 2024 10:52:38 +0200
Subject: [PATCH 30/32] remove dependabo and workflows

---
 .github/dependabot.yml      |  31 ---
 .github/workflows/maven.yml | 525 ------------------------------------
 2 files changed, 556 deletions(-)
 delete mode 100644 .github/dependabot.yml
 delete mode 100644 .github/workflows/maven.yml

diff --git a/.github/dependabot.yml b/.github/dependabot.yml
deleted file mode 100644
index 2279377b..00000000
--- a/.github/dependabot.yml
+++ /dev/null
@@ -1,31 +0,0 @@
-# To get started with Dependabot version updates, you'll need to specify which
-# package ecosystems to update and where the package manifests are located.
-# Please see the documentation for all configuration options:
-# https://help.github.com/github/administering-a-repository/configuration-options-for-dependency-updates
-
-version: 2
-updates:
-  - package-ecosystem: "maven"
-    directory: "/"
-    schedule:
-      interval: "daily"
-    assignees:
-      - "apavlo"
-  - package-ecosystem: "github-actions"
-    directory: "/.github/workflows"
-    schedule:
-      interval: "daily"
-    assignees:
-      - "bpkroth"
-  - package-ecosystem: "docker"
-    directory: "/docker/benchbase/devcontainer/"
-    schedule:
-      interval: "daily"
-    assignees:
-      - "bpkroth"
-  - package-ecosystem: "docker"
-    directory: "/docker/benchbase/fullimage/"
-    schedule:
-      interval: "daily"
-    assignees:
-      - "bpkroth"
diff --git a/.github/workflows/maven.yml b/.github/workflows/maven.yml
deleted file mode 100644
index a2639341..00000000
--- a/.github/workflows/maven.yml
+++ /dev/null
@@ -1,525 +0,0 @@
-# Template: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven
-#
-# Useful links
-# - GitHub Actions: https://docs.github.com/en/actions/learn-github-actions/introduction-to-github-actions
-# - Service containers: https://docs.github.com/en/actions/guides/creating-postgresql-service-containers
-#
-# The CI jobs are set up as follows:
-# - One job to build and upload artifacts.
-# - One job per DBMS test suite.
-# - One job to build/test the docker images.
-# - One job to publish the docker image.
-
-name: BenchBase (Java with Maven)
-
-on:
-  push:
-    branches: [ main ]
-    # Generate new docker images on release tags.
-    tags:
-      - 'v*'
-  pull_request:
-    branches: [ main ]
-  # Run these workflows on a schedule so that docker images are regularly updated for security patches.
-  schedule:
-    - cron: "1 0 * * *"
-  # Give us a button to allow running the workflow on demand for testing.
-  workflow_dispatch:
-    inputs:
-      tags:
-        description: 'Manual Workflow Run'
-        required: false
-        type: string
-
-env:
-  POM_VERSION: 2021-SNAPSHOT
-  JAVA_VERSION: 17
-  ERRORS_THRESHOLD: 0.01
-
-jobs:
-  compile-and-test:
-    runs-on: ubuntu-latest
-    steps:
-      - name: Checkout repo
-        uses: actions/checkout@v3
-
-      - name: Set up JDK
-        uses: actions/setup-java@v3
-        with:
-          java-version: ${{env.JAVA_VERSION}}
-          cache: 'maven'
-          distribution: 'temurin'
-
-      - name: Test with Maven
-        run: mvn -B test --file pom.xml
-
-  package-and-upload:
-    needs: compile-and-test
-    runs-on: ubuntu-latest
-    strategy:
-      matrix:
-        profile: [ 'cockroachdb', 'mariadb', 'mysql', 'postgres', 'spanner', 'phoenix', 'sqlserver', 'sqlite' ]
-    steps:
-    - name: Checkout repo
-      uses: actions/checkout@v3
-
-    - name: Set up JDK
-      uses: actions/setup-java@v3
-      with:
-        java-version: ${{env.JAVA_VERSION}}
-        cache: 'maven'
-        distribution: 'temurin'
-
-    - name: Package with Maven
-      run: mvn -B package -P ${{matrix.profile}} --file pom.xml -DskipTests -D descriptors=src/main/assembly/tgz.xml
-
-    - name: Upload TGZ artifact
-      uses: actions/upload-artifact@v3
-      with:
-        name: benchbase-${{matrix.profile}}
-        path: target/benchbase-${{matrix.profile}}.tgz
-
-  ## ----------------------------------------------------------------------------------
-  ## SQLITE
-  ## ----------------------------------------------------------------------------------
-  sqlite:
-    needs: package-and-upload
-    runs-on: ubuntu-latest
-    strategy:
-      fail-fast: false
-      matrix:
-        # BROKEN: tpch
-        benchmark: [ 'epinions', 'hyadapt', 'noop', 'otmetrics', 'resourcestresser', 'seats', 'sibench', 'smallbank', 'tatp', 'tpcc', 'twitter', 'voter', 'wikipedia', 'ycsb' ]
-    steps:
-      - name: Download artifact
-        uses: actions/download-artifact@v3
-        with:
-          name: benchbase-sqlite
-
-      - name: Extract artifact
-        run: |
-          tar xvzf benchbase-sqlite.tgz --strip-components=1
-
-      - name: Delete artifact
-        run: |
-          rm -rf benchbase-sqlite.tgz
-
-      - name: Set up JDK
-        uses: actions/setup-java@v3
-        with:
-          java-version: ${{env.JAVA_VERSION}}
-          distribution: 'temurin'
-
-      - name: Run benchmark
-        run: |
-          java -jar benchbase.jar -b ${{matrix.benchmark}} -c config/sqlite/sample_${{matrix.benchmark}}_config.xml --create=true --load=true --execute=true --json-histograms results/histograms.json
-          # FIXME: Reduce the error rate so we don't need these overrides.
-          if [ ${{matrix.benchmark}} == auctionmark ]; then
-              ERRORS_THRESHOLD=0.02
-          elif [ ${{matrix.benchmark}} == resourcestresser ]; then
-              ERRORS_THRESHOLD=0.05
-          elif [ ${{matrix.benchmark}} == smallbank ]; then
-              ERRORS_THRESHOLD=0.03
-          elif [ ${{matrix.benchmark}} == tatp ]; then
-              ERRORS_THRESHOLD=0.05
-          fi
-          ./scripts/check_histogram_results.sh results/histograms.json $ERRORS_THRESHOLD
-
-  ## ----------------------------------------------------------------------------------
-  ## MARIADB
-  ## ----------------------------------------------------------------------------------
-  mariadb:
-    needs: package-and-upload
-    runs-on: ubuntu-latest
-    strategy:
-      fail-fast: false
-      matrix:
-        benchmark: [ 'auctionmark', 'epinions', 'hyadapt', 'noop', 'otmetrics', 'resourcestresser', 'seats', 'sibench', 'smallbank', 'tatp', 'tpcc', 'tpch', 'twitter', 'voter', 'wikipedia', 'ycsb' ]
-    services:
-      mariadb: # https://hub.docker.com/_/mariadb
-        image: mariadb:latest
-        env:
-          MARIADB_ROOT_PASSWORD: rootyMcRooty
-          MARIADB_DATABASE: benchbase
-          MARIADB_USER: admin
-          MARIADB_PASSWORD: password
-        options: >-
-          --health-cmd "mysqladmin ping"
-          --health-interval 10s
-          --health-timeout 5s
-          --health-retries 5
-        ports:
-          - 3306:3306
-    steps:
-      - name: Download artifact
-        uses: actions/download-artifact@v3
-        with:
-          name: benchbase-mariadb
-
-      - name: Extract artifact
-        run: |
-          tar xvzf benchbase-mariadb.tgz --strip-components=1
-
-      - name: Delete artifact
-        run: |
-          rm -rf benchbase-mariadb.tgz
-
-      - name: Set up JDK
-        uses: actions/setup-java@v3
-        with:
-          java-version: ${{env.JAVA_VERSION}}
-          distribution: 'temurin'
-
-      - name: Run benchmark
-        env:
-          MARIADB_PORT: ${{ job.services.mariadb.ports[3306] }}
-        run: |
-          mysql -h127.0.0.1 -P$MARIADB_PORT -uadmin -ppassword -e "DROP DATABASE IF EXISTS benchbase; CREATE DATABASE benchbase"
-          java -jar benchbase.jar -b ${{matrix.benchmark}} -c config/mariadb/sample_${{matrix.benchmark}}_config.xml --create=true --load=true --execute=true --json-histograms results/histograms.json
-          # FIXME: Reduce the error rate so we don't need these overrides.
-          if [ ${{matrix.benchmark}} == auctionmark ]; then
-              ERRORS_THRESHOLD=0.02
-          elif [ ${{matrix.benchmark}} == tatp ]; then
-              ERRORS_THRESHOLD=0.05
-          fi
-          ./scripts/check_histogram_results.sh results/histograms.json $ERRORS_THRESHOLD
-
-  ## ----------------------------------------------------------------------------------
-  ## MYSQL
-  ## ----------------------------------------------------------------------------------
-  mysql:
-    needs: package-and-upload
-    runs-on: ubuntu-latest
-    strategy:
-      fail-fast: false
-      matrix:
-        benchmark: [ 'auctionmark', 'epinions', 'hyadapt', 'noop', 'otmetrics', 'resourcestresser', 'seats', 'sibench', 'smallbank', 'tatp', 'tpcc', 'twitter', 'voter', 'wikipedia', 'ycsb' ]
-    services:
-      mysql: # https://hub.docker.com/_/mysql
-        image: mysql:latest
-        env:
-          MYSQL_ROOT_PASSWORD: rootyMcRooty
-          MYSQL_DATABASE: benchbase
-          MYSQL_USER: admin
-          MYSQL_PASSWORD: password
-        options: >-
-          --health-cmd "mysqladmin ping"
-          --health-interval 10s
-          --health-timeout 5s
-          --health-retries 5
-        ports:
-          - 3306:3306
-    steps:
-      - name: Download artifact
-        uses: actions/download-artifact@v3
-        with:
-          name: benchbase-mysql
-
-      - name: Extract artifact
-        run: |
-          tar xvzf benchbase-mysql.tgz --strip-components=1
-
-      - name: Delete artifact
-        run: |
-          rm -rf benchbase-mysql.tgz
-
-      - name: Set up JDK
-        uses: actions/setup-java@v3
-        with:
-          java-version: ${{env.JAVA_VERSION}}
-          distribution: 'temurin'
-
-      - name: Run benchmark
-        env:
-          MYSQL_PORT: ${{ job.services.mysql.ports[3306] }}
-        run: |
-          mysql -h127.0.0.1 -P$MYSQL_PORT -uadmin -ppassword -e "DROP DATABASE IF EXISTS benchbase; CREATE DATABASE benchbase"
-          java -jar benchbase.jar -b ${{matrix.benchmark}} -c config/mysql/sample_${{matrix.benchmark}}_config.xml --create=true --load=true --execute=true --json-histograms results/histograms.json
-          # FIXME: Reduce the error rate so we don't need these overrides.
-          if [ ${{matrix.benchmark}} == auctionmark ]; then
-              ERRORS_THRESHOLD=0.02
-          elif [ ${{matrix.benchmark}} == tatp ]; then
-              ERRORS_THRESHOLD=0.05
-          fi
-          ./scripts/check_histogram_results.sh results/histograms.json $ERRORS_THRESHOLD
-
-  ## ----------------------------------------------------------------------------------
-  ## POSTGRESQL
-  ## ----------------------------------------------------------------------------------
-  postgresql:
-    needs: package-and-upload
-    runs-on: ubuntu-latest
-    strategy:
-      fail-fast: false
-      matrix:
-        benchmark: [ 'auctionmark', 'epinions', 'hyadapt', 'noop', 'otmetrics', 'resourcestresser', 'seats', 'sibench', 'smallbank', 'tatp', 'tpcc', 'tpch', 'twitter', 'voter', 'wikipedia', 'ycsb' ]
-    services:
-      postgres: # https://hub.docker.com/_/postgres
-        image: postgres:latest
-        env:
-          POSTGRES_DB: benchbase
-          POSTGRES_USER: admin
-          POSTGRES_PASSWORD: password
-        options: >-
-          --health-cmd pg_isready
-          --health-interval 10s
-          --health-timeout 5s
-          --health-retries 5
-        ports:
-          - 5432:5432
-    steps:
-      - name: Download artifact
-        uses: actions/download-artifact@v3
-        with:
-          name: benchbase-postgres
-
-      - name: Extract artifact
-        run: |
-          tar xvzf benchbase-postgres.tgz --strip-components=1
-
-      - name: Delete artifact
-        run: |
-          rm -rf benchbase-postgres.tgz
-
-      - name: Set up JDK
-        uses: actions/setup-java@v3
-        with:
-          java-version: ${{env.JAVA_VERSION}}
-          distribution: 'temurin'
-
-      - name: Run benchmark
-        run: |
-          PGPASSWORD=password dropdb -h localhost -U admin benchbase --if-exists
-          PGPASSWORD=password createdb -h localhost -U admin benchbase
-          java -jar benchbase.jar -b ${{matrix.benchmark}} -c config/postgres/sample_${{matrix.benchmark}}_config.xml --create=true --load=true --execute=true --json-histograms results/histograms.json
-          # FIXME: Reduce the error rate so we don't need these overrides.
-          if [ ${{matrix.benchmark}} == auctionmark ]; then
-              ERRORS_THRESHOLD=0.02
-          elif [ ${{matrix.benchmark}} == tatp ]; then
-              ERRORS_THRESHOLD=0.05
-          fi
-          ./scripts/check_histogram_results.sh results/histograms.json $ERRORS_THRESHOLD
-
-  ## ----------------------------------------------------------------------------------
-  ## COCKROACHDB
-  ## ----------------------------------------------------------------------------------
-  cockroachdb:
-    needs: package-and-upload
-    runs-on: ubuntu-latest
-    strategy:
-      fail-fast: false
-      matrix:
-        benchmark: [ 'auctionmark', 'epinions', 'hyadapt', 'noop', 'otmetrics', 'resourcestresser', 'seats', 'sibench', 'smallbank', 'tatp', 'tpcc', 'tpch', 'twitter', 'voter', 'wikipedia', 'ycsb' ]
-    services:
-      cockroach: # https://hub.docker.com/repository/docker/timveil/cockroachdb-single-node
-        image: timveil/cockroachdb-single-node:latest
-        env:
-          DATABASE_NAME: benchbase
-          MEMORY_SIZE: .75
-        ports:
-          - 26257:26257
-    steps:
-      - name: Download artifact
-        uses: actions/download-artifact@v3
-        with:
-          name: benchbase-cockroachdb
-
-      - name: Extract artifact
-        run: |
-          tar xvzf benchbase-cockroachdb.tgz --strip-components=1
-
-      - name: Delete artifact
-        run: |
-          rm -rf benchbase-cockroachdb.tgz
-
-      - name: Set up JDK
-        uses: actions/setup-java@v3
-        with:
-          java-version: ${{env.JAVA_VERSION}}
-          distribution: 'temurin'
-
-      - name: Run benchmark
-        run: |
-          java -jar benchbase.jar -b ${{matrix.benchmark}} -c config/cockroachdb/sample_${{matrix.benchmark}}_config.xml --create=true --load=true --execute=true --json-histograms results/histograms.json
-          # FIXME: Reduce the error rate so we don't need these overrides.
-          # FIXME: Reduce the error rate so we don't need these overrides.
-          if [ ${{matrix.benchmark}} == auctionmark ]; then
-              ERRORS_THRESHOLD=0.02
-          elif [ ${{matrix.benchmark}} == tatp ]; then
-              ERRORS_THRESHOLD=0.05
-          fi
-          ./scripts/check_histogram_results.sh results/histograms.json $ERRORS_THRESHOLD
-
-  ## ----------------------------------------------------------------------------------
-  ## MSSQL
-  ## ----------------------------------------------------------------------------------
-  sqlserver:
-    needs: package-and-upload
-    runs-on: ubuntu-latest
-    strategy:
-      fail-fast: false
-      matrix:
-        # TODO: add more benchmarks
-        #benchmark: [ 'auctionmark', 'epinions', 'hyadapt', 'noop', 'otmetrics', 'resourcestresser', 'seats', 'sibench', 'smallbank', 'tatp', 'tpcc', 'tpch', 'twitter', 'voter', 'wikipedia', 'ycsb' ]
-        benchmark: [ 'epinions', 'hyadapt', 'noop', 'otmetrics', 'resourcestresser', 'sibench', 'smallbank', 'tatp', 'tpcc', 'tpch', 'twitter', 'voter', 'wikipedia', 'ycsb' ]
-    services:
-      sqlserver:
-        image: mcr.microsoft.com/mssql/server:latest
-        env:
-          ACCEPT_EULA: Y
-          SA_PASSWORD: SApassword1
-        options: >-
-          --health-cmd "/opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P SApassword1 -b -Q 'SELECT 1;'"
-          --health-interval 10s
-          --health-timeout 5s
-          --health-retries 5
-        ports:
-          - 1433:1433
-    steps:
-      - name: Download artifact
-        uses: actions/download-artifact@v3
-        with:
-          name: benchbase-sqlserver
-
-      - name: Extract artifact
-        run: |
-          tar xvzf benchbase-sqlserver.tgz --strip-components=1
-
-      - name: Delete artifact
-        run: |
-          rm -rf benchbase-sqlserver.tgz
-
-      - name: Set up JDK
-        uses: actions/setup-java@v3
-        with:
-          java-version: ${{env.JAVA_VERSION}}
-          distribution: 'temurin'
-
-      - name: Cleanup database
-        uses: docker://mcr.microsoft.com/mssql-tools:latest
-        with:
-          entrypoint: /opt/mssql-tools/bin/sqlcmd
-          args: -U sa -P SApassword1 -S sqlserver -b -Q "DROP DATABASE IF EXISTS benchbase;"
-
-      - name: Setup database
-        uses: docker://mcr.microsoft.com/mssql-tools:latest
-        with:
-          entrypoint: /opt/mssql-tools/bin/sqlcmd
-          args: -U sa -P SApassword1 -S sqlserver -b -Q "CREATE DATABASE benchbase;"
-
-      - name: Setup login
-        uses: docker://mcr.microsoft.com/mssql-tools:latest
-        with:
-          entrypoint: /opt/mssql-tools/bin/sqlcmd
-          args: -U sa -P SApassword1 -S sqlserver -Q "CREATE LOGIN benchuser01 WITH PASSWORD='P@ssw0rd';"
-
-      - name: Setup access
-        uses: docker://mcr.microsoft.com/mssql-tools:latest
-        with:
-          entrypoint: /opt/mssql-tools/bin/sqlcmd
-          args: -U sa -P SApassword1 -S sqlserver -b -Q "USE benchbase; CREATE USER benchuser01 FROM LOGIN benchuser01; EXEC sp_addrolemember 'db_owner', 'benchuser01';"
-
-      - name: Run benchmark
-        # Note: user/pass should match those used in sample configs.
-        run: |
-          java -jar benchbase.jar -b ${{matrix.benchmark}} -c config/sqlserver/sample_${{matrix.benchmark}}_config.xml --create=true --load=true --execute=true --json-histograms results/histograms.json
-          # FIXME: Reduce the error rate so we don't need these overrides.
-          if [ ${{matrix.benchmark}} == tatp ]; then
-              ERRORS_THRESHOLD=0.05
-          fi
-          ./scripts/check_histogram_results.sh results/histograms.json $ERRORS_THRESHOLD
-
-  ## ----------------------------------------------------------------------------------
-  ## Docker Build Test Publish
-  ## ----------------------------------------------------------------------------------
-  docker-build-test-publish:
-    runs-on: ubuntu-latest
-    env:
-      DOCKER_BUILDKIT: 1
-      BENCHBASE_PROFILES: 'cockroachdb mariadb mysql postgres spanner phoenix sqlserver sqlite'
-      CONTAINER_REGISTRY_NAME: ${{ secrets.ACR_LOGINURL }}
-    services:
-      postgres: # https://hub.docker.com/_/postgres
-        image: postgres:latest
-        env:
-          POSTGRES_DB: benchbase
-          POSTGRES_USER: admin
-          POSTGRES_PASSWORD: password
-        options: >-
-          --health-cmd pg_isready
-          --health-interval 10s
-          --health-timeout 5s
-          --health-retries 5
-        ports:
-          - 5432:5432
-    steps:
-      - name: Setup postgres test DB
-        run: |
-          PGPASSWORD=password dropdb -h localhost -U admin benchbase --if-exists
-          PGPASSWORD=password createdb -h localhost -U admin benchbase
-      - name: Checkout repo
-        uses: actions/checkout@v3
-      # https://github.com/actions/cache/blob/master/examples.md#java---maven
-      - name: Cache local Maven repository
-        uses: actions/cache@v3
-        with:
-          path: ~/.m2/repository
-          key: setup-java-${{ runner.os }}-docker-maven-${{ hashFiles('**/pom.xml') }}
-          restore-keys: |
-            setup-java-${{ runner.os }}-docker-maven-
-      - name: Pull base image caches for PR builds
-        if: ${{ github.ref != 'refs/heads/main' }}
-        run: |
-          docker pull benchbase.azurecr.io/benchbase-dev:latest || true
-          docker pull benchbase.azurecr.io/benchbase:latest || true
-      - name: Set NO_CACHE env var for main branch builds
-        if: ${{ github.ref == 'refs/heads/main' }}
-        run: |
-          echo "NO_CACHE=true" >> $GITHUB_ENV
-      - name: Build benchbase-dev image
-        run: |
-          ./docker/benchbase/build-dev-image.sh
-      # Note: this script maps the local .m2 cache into the container.
-      - name: Build the benchbase docker image with all profiles using the dev image
-        env:
-          SKIP_TESTS: 'false'
-        run: |
-          ./docker/benchbase/build-full-image.sh
-      - name: Run a basic test from the docker image against postgres test DB
-        env:
-            benchmark: noop
-        run: |
-          for image in benchbase benchbase-postgres; do
-            # Adjust the sample config to talk to the container service instead of localhost.
-            cat "config/postgres/sample_${benchmark}_config.xml" | sed -e 's/localhost:5432/postgres:5432/g' > /tmp/config.xml
-            # Lookup the service container's docker network so we can place the benchbase container in it too.
-            docker_network="$(docker ps --filter expose=5432 --format '{{.Networks}}')"
-            # Map the adjusted config into the container and use it to run the test.
-            rm -rf results
-            mkdir -p results
-            docker run --rm --name benchbase-postgres --network "$docker_network" \
-              --env BENCHBASE_PROFILE=postgres -v /tmp/config.xml:/tmp/config.xml -v "$PWD/results:/benchbase/results" \
-              "$image" -b "$benchmark" -c /tmp/config.xml --create=true --load=true --execute=true --json-histograms results/histograms.json
-            # Test that the results files were produced.
-            ls results/${benchmark}_*.csv
-            ./scripts/check_histogram_results.sh results/histograms.json $ERRORS_THRESHOLD
-          done
-      # Publish the docker image if the build/test was successful.
-      # Only do this with approved PRs and if the login secrets are available.
-      # Typically we expect to publish to benchbase.azurecr.io,
-      # but setting ACR_LOGINURL to something else allows us to do testing on forks.
-      - name: Log in to Docker Hub
-        if: ${{ (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v')) && env.CONTAINER_REGISTRY_NAME != '' }}
-        uses: docker/login-action@v2
-        with:
-          registry: ${{ secrets.ACR_LOGINURL }}
-          username: ${{ secrets.ACR_USERNAME }}
-          password: ${{ secrets.ACR_PASSWORD }}
-      - name: Push Docker image
-        if: ${{ (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/v')) && env.CONTAINER_REGISTRY_NAME != '' }}
-        run: |
-          docker push -a ${{ secrets.ACR_LOGINURL}}/benchbase-dev
-          docker push -a ${{ secrets.ACR_LOGINURL}}/benchbase
-          for profile in $BENCHBASE_PROFILES; do
-            docker push -a ${{ secrets.ACR_LOGINURL }}/benchbase-$profile
-          done

From 5e76396e933addf9dc371246f88e9de648939c02 Mon Sep 17 00:00:00 2001
From: Maksim Zinal <zinal@ydb.tech>
Date: Mon, 17 Feb 2025 12:30:26 +0300
Subject: [PATCH 31/32] Update pom.xml

Java version should be 21, not 1
---
 pom.xml | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/pom.xml b/pom.xml
index 60269c6a..878f9eb3 100644
--- a/pom.xml
+++ b/pom.xml
@@ -12,7 +12,7 @@
 
     <properties>
         <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
-        <java.version>1</java.version>
+        <java.version>21</java.version>
         <maven.compiler.source>21</maven.compiler.source>
         <maven.compiler.target>21</maven.compiler.target>
         <buildDirectory>${project.basedir}/target</buildDirectory>

From 0927c44d8810c7052136692d50ddce6f9a29f70b Mon Sep 17 00:00:00 2001
From: Evgeniy Ivanov <i@eivanov.com>
Date: Wed, 19 Feb 2025 14:03:46 +0100
Subject: [PATCH 32/32] Update README.md

c3p0 -> Hikari
---
 README.md | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/README.md b/README.md
index bc38702b..cbf4ba29 100644
--- a/README.md
+++ b/README.md
@@ -4,7 +4,7 @@ This is a fork of [BenchBase](https://github.com/cmu-db/benchbase) done to enhan
 1. Fixed some performance issues in the original benchbase to speed up the benchmark.
 2. To address issues with running high number of warehouses, we added support for virtual threads (requires Java >= 21).
 3. Significantly reduced the memory footprint of the benchmark.
-4. Added c3p0 as a connection pool for PostgreSQL
+4. Added Hikari as a connection pool for PostgreSQL.
 
 Please, note that this is for PostgreSQL only.
 
